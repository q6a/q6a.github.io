[{"categories":["Localization Industry","Internationalization Industry","Transcription","Translation","Managed Service","Enterprise","Case Study"],"contents":"Halo semuanya!\nBeberapa minggu yang lalu, kita baru aja ngebahas tentang penerjemah bertenaga kecerdasan buatan. Kali ini, kita bakalan ngebahas tentang terjemahan video.\nKebanyakan dari kalian pasti udah akrab dengan istilah penerjemah tulisan, misalnya penerjemah buku. Tapi, kebanyakan dari kalian mungkin belum tau tentang istilah penerjemah video. Jadi, apa sih penerjemah video itu?\n Terjemahan Video adalah proses menerjemahkan konten video, umumnya dalam bahasa Inggris, ke bahasa lain.\n Proses ini bisa melibatkan hal-hal berikut:\nProses menerjemahkan video  \n Transkripsi Video Terjemahan Video Video Dubbing (opsional)  Proses Dalam Menerjemahkan Video 1. Transkripsi Video Transkripsi video  \n Transkripsi video adalah proses mengubah suara (lisan) menjadi teks (tulisan).\n Ada dua cara untuk mengubah bentuk lisan menjadi tulisan:\n  Memanfaatkan teknologi kecerdasan buatan\nSalah satu cara yang paling gampang untuk mengubah bentuk lisan menjadi tulisan adalah dengan menggunakan teknologi kecerdasan buatan. Teknologi ini bisa mengubah bentuk lisan menjadi tulisan secara otomatis sehingga mempermudah proses transkripsi, tapi kekurangannya hasil yang dihasilkan nggak akurat. Oleh karena itu, teknologi ini masih membutuhkan campur tangan manusia untuk memastikan bahwa tulisan yang dihasilkan sudah akurat.\n  Menulis transkripsi secara manual\nCara ini merupakan cara yang paling akurat dalam mengubah bentuk lisan menjadi tulisan, tapi memakan banyak waktu dan energi. Cara ini mengandalkan manusia untuk melakukan proses transkripsi. Hasil akhir dari metode ini akan sangat akurat.\n  Manfaat Dari Transkripsi Video: Transkripsi video punya beragam manfaat, teman-teman. Salah satunya adalah agar bisa dicari oleh mesin pencari (search engine).\nMesin pencari seperti Google, Yahoo atau Bing nggak bisa memahami konten audio atau video karena mereka mengandalkan tulisan untuk berfungsi.\nJadi, gimana dong caranya supaya konten kalian bisa dicari oleh mesin pencari? Ya, kalian harus menggunakan transkripsi video. Setelah konten video memiliki transkripsi, mesin pencari baru bisa menampilkan konten kalian.\nSelain digunakan oleh mesin pencari, transkripsi video juga digunakan untuk memberi orang-orang lebih banyak akses. Menambahkan transkrip bakalan membuat perbedaan yang besar untuk orang-orang yang:\nMembaca menggunakan media digital  \n Punya gangguan pendenggaran Lagi di ruangan berisik Lagi di ruangan dimana suara tidak boleh terdengar, misalnya seorang ibu yang nggak pengen ngebangunin anaknya.  Yang terakhir, transkripsi video digunakan untuk memulai proses menerjemah video. Tanpa transkripsi, video kalian nggak bisa diterjemahkan oleh orang lain yang nggak ngerti bahasa kalian. Video tersebut juga nggak bisa diterjemahkan secara otomatis oleh penerjemah bertenaga kecerdasan buatan.\nMenulis teks  \nVideo transkripsi itu penting banget, kan, teman-teman?!\n2. Terjemahan Video Setelah memiliki transkripsi, video tersebut sekarang bisa diterjemahkan. Sama seperti proses mengubah bentuk lisan menjadi tulisan, terjemahan video juga bisa dilakukan dengan menggunakan teknologi kecerdasan buatan atau dengan memperkerjakan penerjemah profesional. Kelebihan dan kekurangan metode-metode tersebut juga kurang lebih sama.\nContoh:\nSeandainya kalian punya akun YouTube, nih. Kalian punya video tentang cara memasak nasi goreng. Video kalian kan dalam Bahasa Indonesia, jadi gimana caranya supaya orang-orang yang nggak bisa Bahasa Indonesia bisa ngerti konten kalian? Nah, itulah fungsi terjemahan video. Jadi, kalian harus mengubah suara menjadi teks. Dalam kasus YouTube, kalian bisa mengupload subtitle. Kalau kalian memiliki subtitle, YouTube bisa secara otomatis menerjemahkan video kalian ke bahasa lain dengan menggunaka Google Translate.\nJadi, oke banget kan kalau kalian menerjemahkan video kalian?!\n3. Video Dubbing Kartun Doraemon  \nKalian pasti sering nonton kartun-kartun di RCTI atau Global TV seperti Doraemon, Ninja Hatori, Hamtaro, Crayon SinChan, Naruto dan lain-lain. Kartun-kartun tersebut merupakan salah satu contoh dari video dubbing.\n Video dubbing adalah proses menggantikan suara asli ke bahasa lain.\n Sama seperti proses mengubah bentuk lisan menjadi tulisan, video dubbing juga bisa dilakukan dengan menggunakan teknologi kecerdasan buatan atau dengan memperkerjakan pengisi suara. Tentunya, suara yang dihasilkan oleh teknologi kecerdasan buatan bakalan nggak natural atau kedengaran seperti robot. Sedangkan suara yang dihasilkan oleh pengisi suara bakalan lebih natural. Tetapi, teknologi kecerdasan buatan tidak membutuhkan biaya dan waktu yang banyak.\nSeperti yang kalian tau, bahasa asli dari kartun-kartun yang kita nonton di TV kebanyakan adalah antara Bahasa Inggris atau Bahasa Jepang.\nAda beberapa alasan kenapa video dubbing banyak dipilih orang:\n Nggak semua orang gemar membaca Beberapa orang berada di lokasi yang tidak nyaman untuk membaca Banyak anak balita yang belum bisa membaca Banyak orang lansia yang kesulitan untuk membaca  Maka oleh itu, video dubbing disukai banyak orang, terutama di Indonesia.\nKenapa Transkripsi Video, Terjemahan Video dan Video Dubbing Itu Penting? Kenapa Transkripsi Video, Terjemahan Video dan Video Dubbing Itu Penting?  \n1. Eksport Pembesaran market itu penting. Salah satu cara supaya sebuah perusahaan bisa mengekspansikan bisnisnya adalah dengan melakukan 3 hal diatas.\n2. Kesehatan Ketika Virus Corona pertama kali menyerang Australia, pemerintah Australia mengeluarkan brosur-brosur tentang cara mencegah virus tersebut dalam bentuk video yang disebarluaskan diberbagai media, serperti rumah sakit, TV, internet dan tempat-tempat umum lainnya. Video-video tersebut juga diterjemahlan ke berbagai macam bahasa, salah satunya Bahasa Indonesia.\nOrang Indonesia merupakan salah satu komunitas terbesar di Australia. Banyak imigran dari Indonesia membawa orangtuanya ketika mereka pindah ke Australia. Namun, banyak dari mereka yang tidak begitu mengerti Bahasa Inggris. Oleh karena itu, terjemahan video itu penting banget. Pasien dan keluarganya bakalan ngerasa lebih tenang ketika mereka bisa mengakses informasi dalam bahasa yang mereka mengerti.\n3. Edukasi Kalian pernah nggak sih ketemu video yang penting banget buat tugas sekolah atau kuliah kalian, tapi videonya dibahasa yang kurang kalian mengerti. Aduh, pasti nyebelin banget.\nNah, dengan adanya terjemahan video, video yang pengen kalian nonton tentunya bisa diakses oleh lebih banyak orang. Jadi, bahasa bukan lagi batasan untuk belajar.\nAsik!\nKerjasama Dengan Perusahaan Penerjemah Video Itu Seperti Apa? Nah, kan kalian sekarang udah tau penerjemah video itu seperti apa. Terus, kerjasama dengan perusahaan penerjemah video itu kayak gimana, sih?\nContoh yang bakalan kita pakai kali ini adalah kerjasama antara Video Translator dan Dandelions. Dandelions adalah perusahaan luar angkasa dan Internet untuk Segala (Internet of Things) yang berbasis di Sydney, Australia. Video Translator dipercayakan oleh mereka untuk memproduksi konten-konten video mereka, teman-teman.\nYuk, kita cari tau apa aja yang kami lakuin buat Dandelions!\n1. Produksi Video Produksi Video  \nKetika ada konten video yang mau disebar oleh Dandelions, tim dari Video Translator yang ngeditnya. Jadi, video mentah atau video yang belum diedit dari mereka, kami yang olah. Hasilnya tentu saja harus memiliki kualitas yang tinggi.\n2. Transkripsi Video Transkripsi Video  \nSeperti yang sudah kita bahas tadi, proses dalam menerjemah video yang pertama adalah membuat transkrip. Setelah videonya selesai diedit, kami menggunakan teknologi kecerdasan buatan untuk menyalin suara secara otomatis. Setelah hasilnya jadi, kami baru mengedit hasil salinan tersebut untuk memastikan bahwa salinannya akurat.\n3. Terjemahan Video Terjemahan Video  \nVideo yang digunakan oleh Dandelions sebagai perusahaan dari Australia tentunya merupakan Bahasa Inggris. Karena Dandelions ingin menjangkau orang-orang yang nggak bisa Bahasa Inggris, mereka mau konten mereka diterjemahkan ke berbagai macam bahasa.\n4. Video Dubbing Video Dubbing  \nBeberapa macam kultur lebih memilih buat mendengarkan pengisi suara dibandingkan buat membaca. Maka dari itu, kami juga menyediakan dubbing dalam versi teknologi kecerdasan buatan dan juga suara manuasia.\nKombinasi dari keempat elemen tersebut bakalan membuat konten yang bisa membuat dampak yang besar bagi penonton multibahasa.\nKenapa Perusahaan Luar Angkasa Butuh Terjemahan Video? Konten video dalam bahasa lain sering dipakai oleh berbagai macam perusahaan, tapi jarang banget dipakai oleh perusahaan luar angkasa. Jadi, kenapa perusahaan luar angkasa seperti Dandelions mau menerjemahkan konten video mereka?\n1. Untuk Membuat Industri Luar Angkasa Lebih Mudah Diakses Membuat Industri Luar Angkasa Lebih Mudah Diakses  \nSelama ini, perusahaan luar angkasa selalu punya konotasi sebagai perusahaan milik negara, seperti NASA atau perusahaan milik pengusaha dengan penhasilan trilliunan seperti Tesla. Baru akhir-akhir ini pemerintah dan berbagai macam perusahaan lain mau membuat perusahan luar angkasa supaya bisa lebih muda dijangkau.\nNah, dengan menerjemahkan konten-konten ke dalam berbagai bahasa, harapannya adalah untuk membuka pintu industri luar angkasa bagi orang lain di seluruh dunia.\n2. E-learning E-Learning  \nUntuk membuat industri luar angkasa lebih mudah diakses, Dandelion mau menyediakan video pendidikan untuk penonton mereka. Banyak penelitian yang menunjukkan kalau orang-orang biasanya bisa belajar lebih muda kalau bahasa yang digunakan adalah bahasa sehari-hari mereka.\nPandemi COVID-19 memaksakan orang-orang untuk belajar lewat internet, oleh karena itu permintaan untuk e-learning terus meningkat. Nah, karena semua orang sekarang belajarnya lewat internet, maka Dandelions juga mau mengakomodasikan video pendidikan dalam berbagai bahasa.\n3. Komunikasi Antar Perusahaan Komunikasi Antar Perusahaan  \nAustralia merupakan negara yang sangat multikultural. Hal ini berarti bahwa Dandelions bakalan punya pekerja-pekerja dari mancanegara.\nOleh karena itu, Dandelions ingin meminimalisirkan kesalahpahaman karena bahasa. Konten video yang diterjemahkan bakalan membuat komunikasi yang lebih efektif dan hubungan yang lebih kuat antara tim multikultural.\n4. Kampanye Pemasaran Multibahasa Kampanye Pemasaran Multibahasa  \nKetika kalian membuat konten pemasaran (marketing content), kalian pastinya pengen dong supaya kampanye kalian bisa dicari orang.\nGimana caranya supaya kalian bisa menggunakan konten yang sama buat target yang berbeda?\nCaranya adalah dengan menerjemahkan konten pemasaran kalian. Kampanye pemasaran yang diterjemahkan akan memungkinkan Dandelions untuk menciptakan interaksi dan koneksi otentik dengan penonton mereka.\nYay! Sekarang kalian udah tau apa itu terjemahan video dan seperti apa kerjasama dengan perusahaan penerjemah video.\nKalau kalian sekarang juga sedang mencari kerjasama dengan perusahaan penerjemah video, jangan segan untuk menghubungi kita di hello@videotranslator.ai !\nSampai jumpa!\n","permalink":"https://videotranslator.ai/news/seperti-apa-kerjasama-dengan-perusahaan-penerjemah-video/","tags":["Indonesian"],"title":"Seperti Apa Kerjasama Dengan Perusahaan Penerjemah Video?"},{"categories":["Case Study","Enterprise","Managed Service","Translation","Transcription","Localization Industry","Internationalization Industry"],"contents":"Many people are wondering about video translation. What is it, how to use it, where it may be useful, and what do agreements involving video translation look like?\nWhat Is Video Translation? Video Translation is the process of translating video content, generally in English, to a different language. It can involve the below steps:\n Video Transcription Video Translation Video Dubbing (optional)  \nTo learn how video translation actually works, please look at this article.\nHow To Use Video Translation? There are a number of different ways to use video translation. Some of the general benefits are:\n\n  Video SEO\nSearch engines do not understand an audio or video content as they are primarily text-based. To make your audio or video content indexable by search engines is the primary reason to use Speech-To-Text Transcription AI\u0026rsquo;s.\n  Accessibility\nFor people who have vision or hearing disabilities, adding the transcript makes all the difference!\n  Scale\nHow will someone who does not speak, read or think in English buy your product? Adding in the transcriptions in different languages means that they can now buy your product or service!\n  Those are the basic reasons, but depending on your market, your budget, and your objectives a lot can change.\nWhere Video Transcription, Translation or Dubbing may be important? Simply put, there are a few use cases:\n  Exporters\nIn a world where clients are reluctant to spend money, you need to find new clients. Using video to reach these clients is a good strategy. Read a case study involving a high tech exporter!\n  Healthcare\nReducing the load of your healthcare professionals with video translation  \nHow do you reduce the load on your healthcare professionals? You give patients and their families access to information in a language they understand.\n  Education\nVideo translation to accomodate people with ESL backgrounds  \nWorking with children is hard, but when the parent has a different background - in Australia, we call these people with these backgrounds ESL (English as a Second Language) - this can be even more challenging. Read about how you can educate adults in this case study!\n  Obviously, there are many other use cases. But these are the big use cases we see.\nWhat Does A Video Translation Partnership Look Like? We have been trusted by Dandelions, a space/IoT company based in Sydney, to produce high-quality videos that can cater to different audiences.\nThere are 4 things that we do:\n  Video Production\nConverting raw videos into a high-quality video  \nWe convert raw videos provided by the Dandelions team and create a high-quality video.\n  Video Transcription\nTranscribing video  \nOnce the video is ready, we provide text transcription by utilizing our AI software. Video transcription is especially useful for SEO and more accessible for people with vision or hearing disabilities.\n  Video Translation\nTranslating video  \nWe take the transcripted text and translate it to ensure the delivery of one consistent message across the globe. This way, the same video content can be accessed by any viewer, especially in a multicultural community.\n  Video Dubbing\nDubbing video  \nSome communities prefer to watch videos with voice layover compared to reading subtitles. We provide Dandelions with both human and AI dubbing as a solution.\n  The combination of all 4 elements will create impactful content for multilingual audiences.\nWhy Does A Space Company Need Video Translation? Video translation is common in many industries, but not in the space industry. So, why did a space company like Dandelions choose to get their videos translated?\n  To Make The Space Industry More Accessible\nMake the space industry more accessible  \nFor the longest time, the space industry has been the exclusive domain of governments and gazillionaire entrepreneurs. It is only recently that governments and companies around the world begin to democratize the space industry.\nWith contents translated into different languages, the hope is to open the space industry doors for other people around the world.\n  E-learning\nIncrease demand in e-learning  \nTo make the space industry more accessible, Dandelions want to provide educational videos for their viewers. Researches show that individuals learn better in their native language.\nAs the demand for e-learning keeps on increasing, especially with the need for online learning during the COVID-19 pandemic, figuring out how to adjust your video content for multilingual learners is crucial.\n  Internal Communications\nInternal communications in multicultural team  \nAlthough Dandelions is an Australian-based company, there is no doubt that the company will have multicultural employees. There are also potentials that the company will grow into a global company.\nWith this in mind, the company wants to minimize the language barrier. The translated video contents will ensure more effective communication and a stronger relationship between multicultural teams.\n  Multilingual Marketing Campaign\nCreating a multilingual marketing campaign  \nHaving your marketing content searchable in different languages is very effective. Translated marketing campaigns will allow Dandelions to create an authentic interaction and connection with their audiences.\n  Are you also currently looking for a video translation partnership? Please contact us at hello@videotranslator.ai for collaboration or partnership opportunities!\n","permalink":"https://videotranslator.ai/news/what-does-a-video-translation-partnership-look-like/","tags":["English"],"title":"What Does A Video Translation Partnership Look Like?"},{"categories":["Users","Support","Retail","Best Practices"],"contents":"Short videos are the hot trends these days. Everywhere you scroll on your social media, you will always be able to find these short videos.\nSo, what are the top video editor apps iOS have to offer for you in 2021 to make the next viral video?\n  Instagram\nVideo editing app number 1: Instagram  \nInstagram has 4.7 stars from its 1.3 million reviewers. This app remains number one on Apple\u0026rsquo;s photo and video chart. Instagram currently has these unique features for you to edit your videos:\n  Reels\nFollowing TikTok, Instagram now offers short video clips with a maximum length of 30 seconds. Trim and editing tools are also added on reels. Reels is currently available in more than 50 countries in response to TikTok bans.\n  Instagram effects gallery\nCreate Augmented Reality effects that alter photos and videos from the camera roll.\n    TikTok\nVideo editing app number 2: TIkTok  \nTikTok is a social video app that allows you to create and share short video clips of up to 60 seconds. You can trim, edit, clip and merge multiple videos, as well as add music, sound, filters, and stickers.\nTikTok currently has these features:\n  Effects gallery\nAdd different effects to upgrade your videos.\n  Duets\nCreate duet videos where you can reply, comment or react to other videos.\n  Read more about TikTok content ideas here.\n  WOMBO\nVideo editing app number 3: Wombo  \nWombo is an AI-powered lip-sync app. All you have to do is take a selfie, pick music and let Wombo do its magic.\nHere is how Wombo works:\n Take a selfie or choose your picture from your gallery. Wombo works best when you are using a photo where you are not smiling. The app also provides you with an outline for you to match your face up to have the best results. Choose a song. The song that you choose will also determine the face mimicking (lip-syncing). It currently has limited songs to choose from. The end result is a short video of you lipsyncing to a song.  The cool thing about Wombo is that you can also animate non-human faces. For example: bread, sinks, emoticons.\n  FaceApp\nVideo editing app number 4: FaceApp  \nFaceApp is a mobile app for AI photo and video editing. You can use their AI filters, backgrounds, effects and other tools to produce photorealistic edit.\nSimilar to Womba, you can take a picture/video from your camera or load a photo/video from your gallery. Then, choose the filter that you like. Some filter options that they have:\n Impression Smiles Beards Hair colours Hairstyles  The app was trending for their young or old filter that can transform you into your younger or older self.\n  CapCut\nVideo editing app number 5: CapCut  \nCapCut is a free video editing app that allows you to edit your videos, add filters, effects, music, stickers, and texts. CapCut is owned by ByteDance, a company that also owns TikTok, making it so popular with TikTok users.\n  PicsArt\nVideo editing app number 6: PicsArt  \nPicsArt is an online photo and video editing applications with a social creative community. There is a free and paid version of the app. The paid version allows you to use more filters and functions to edit your photos and videos to make trendier Instagram reels and TikTok videos.\nSome of the video editor functions are:\n Basic video editing, such as trimming and merging videos. Add music from its music library AI Music generator that creates royalty-free music just for you Crop videos or add video backgrounds    Splice\nVideo editing app number 7: Splice  \nSplice is a free video editing app from the creators of GoPro.\nThe app allows you to:\n Trim, cut, crop video clips Adjust the video speed Overlay videos and apply masks Remove video backgrounds Apply filters and effects on the videos Add titles, text overlays and outro Create video slideshows    Canva\nVideo editing app number 8: Canva  \nWho does not know Canva? With Canva, suddenly everyone is a professional graphic designer!\nLately, Canva has a new feature where you are able to create videos. It provides a library with thousands of templates, free stock videos, animated graphics, and music tracks for you to create a short video to post online quickly.\nEditing your videos with Canva can be done in 5 simple steps:\n Start a new project Explore templates Discover features Customise your video Save and Share    iMovie\nVideo editing app number 9: iMovie  \nOf course, you can always use Apple\u0026rsquo;s own developed video editor tool. The iMovie has multiple templates that allow you to make Hollywood-style trailers and movies.\nThe iMovie allows you to:\n Modify and enhance video colour settings Crop and rotate video clips Stabilise shaky videos Add video transitions Change the speed of clips    The wide range of short video apps available for iOS means there is likely an app catering to your unique videography needs.\nNow that you have ideas on what video editors you can use to enhance your videos, why don’t you try Video Translator?\nHere at Video Translator, we provide AI Transcription, Translation, Hard Coded Captions and dubbing.\nBy using Video Translator, you can :\n  Transcribe or create closed captions easily\nTranscribe your videos  \nClosed caption is crucial because it:\n Helps deaf and hard of hearing individuals watch videos; Helps people to focus on and remember the information more easily; Lets people watch it in sound-sensitive environments; and Allows you to optimise your SEO    Translate your videos so you can reach a wider target audience\nTranslate your videos  \nYou may have video contents in English, but what if it turns out most of your viewers are in Spain? The solution is by translating your videos.\nTranslating your contents allow you to:\n Reach a wider target audience Gain more views Expand your market Attract more viewers    Dub your videos in your target language\nDub your videos  \nIf your viewers like contents that are dubbed in their language preference, this method is perfect for you. You can get contents spoken in their language on top of the closed captions.\nSo, are you ready to make the next viral videos?!\nFor more information regarding Video Translator, please send us an email at hello@videotranslator.ai.\n  ","permalink":"https://videotranslator.ai/news/top-performing-ios-video-editor-2021/","tags":["English"],"title":"9 of IOS Top Video Editing Apps 2021"},{"categories":["Translation services","Translation professionals","Translation","Managed Service","Languages","Dialects","Best Practices"],"contents":"Here at Video Translator, we love your questions. Receiving your questions mean that you are interested in the services we are offering.\nNot long ago, we received an enquiry from a customer.\nHow do you know which dialect would work when transcribing videos  \n \u0026ldquo;Hello, there are YouTube videos in Arabic News. I would like to have them transcribed, translated and dubbed into the English language so that I can understand them. Would you all be able to do this?\u0026rdquo;\n Of course, we said yes! That is precisely why we are here.\nWe offered him a quote that ranges between 10-25 USD per minute depending on the content\u0026rsquo;s complexity and whether he wanted an AI or Human dubbing.\nThe cost is relatively higher than the .15 cents per minute along with the $10 monthly fee and .30 per minute with no monthly fee with the AI usage. The high cost is, of course, if we do it for him as a managed service.\nThere is a complex process when it comes to managed service. We need to hire professional translators, manually add the baked-in captions and adjust the voice dubbing. We want to make sure that the end result will give you the best value.\nVideo Translator\u0026#39;s managed services  \nYou can find an example of how we did a managed service here.\nIn the end, Marcus decided to do it by himself because he wanted to have the videos translated regularly. So, he asked us how he can use the Video Translator app to translate his choice\u0026rsquo;s video contents.\nWe referred him to this link for help and documentation.\nWithin our conversation, Marcus asked a great question: How does he know which dialect would work for his choice videos?\nwhich dialect would work for his choice videos  \nThere are multiple ways for you to find out the language dialect:\n  Knowing or hiring a native speaker\nKnowing or hiring a native speaker  \nIt is the best way to determine which dialect a person in a video is speaking. Native speakers will know exactly what dialect is being spoken.\n  Having a basic understanding of the language\nHaving a basic understanding of the language  \nThis will help you determine the language dialect. For example, it would be relatively easier to distinguish between British and American English because almost everyone is familiar with it.\n  Find the source of the video.\nFinding video source  \nFor example, if your video is from YouTube, you can find out where the person is from. If the person is, let\u0026rsquo;s say, from Mexico, then the dialect the person is speaking is most probably Mexican Spanish.\n  If you do not know a native speaker, do not speak the language and cannot find the video source, the only alternative is to pick any of the available language dialects. Most of the time, there won\u0026rsquo;t be much difference between different dialects.\nThere are probably some vocabulary differences. For example, Americans would say college. Meanwhile, the British would call it university.\nFor now, knowing which dialect a person is speaking is still a very complex thing for Artificial Intelligence to do. Of course, with the rapid development in technology, AI will soon be able to automatically determine a language\u0026rsquo;s dialect.\nConclusion There are three ways in which you can find out which dialect a person is speaking in the video you want to translate:\n Know or hire a native speaker Have a basic understanding of the target language Find the video source  Your feedback matters!  \nWe are also glad to have these kinds of questions. If you have more questions or feedback, do not hesitate to contact us at hello@videotranslator.ai!\n","permalink":"https://videotranslator.ai/news/which-dialect-to-choose/","tags":["English","Arabic"],"title":"Transcribing A Video: How Do I Know Which Dialect To Choose?"},{"categories":["Video transcription","Video translation","Video translator","Localization Industry","Internationalization Industry"],"contents":"We know that you\u0026rsquo;ve been guilty of spending hours and hours scrolling through your ForYou page on TikTok.\nThe microblogging app called Tik Tok is the trend these days. Most of the viral videos online come from this platform.\nYou know as well as we do that TikTok can bring you a lot of traction. So, you also want to make TikTok videos. However, you don’t know what contents you should post.\nWell, we’ve got you covered!\nWe have gathered 10 TikTok content ideas for you to try. Let’s check them out!\n10 TIKTOK CONTENT IDEAS FOR YOU TO TRY 1. DIY DIY or do it yourself is content where you show people how to do things themselves. Instead of hiring a professional to do it, you can do it yourself with no help from others.\nMany people enjoy DIY videos because it provides an opportunity to express their creativity, gives a form of occupational therapy, brings a leisure activity or a way to save money.\nBusiness type perfect for this: handmade crafts such as jewellery, soaps, candles, bath bombs, lipsticks\n5minutecrafts on TikTok  \n2. Dance Dancing videos coupled with trending music are so popular these days. Some of the trending TikTok dance videos are ‘Renegade’, ‘Say So’, ‘Savage’, ‘Number One, ‘Get Up’ and many more.\nThe thing about dancing is, everyone can do it, including you!\nA vet from Arlington, Texas, called Dr Hunter Finn, creates dancing videos on TikTok to give pet tips.\nDr Hunter Finn on TikTok  \nYou could also make dancing videos to educate your viewers about your business!\nBusiness types perfect for this: dance studio, dancers, choreographers\n3. Meme People really love meme. Followers who have a good experience with a meme are more likely to share it. The more people who see your meme increases the chances of it going viral.\nAn example of a brand that is currently investing heavily in memes is Up and Go, a health food company. They are even hiring interns to make memes!\nUpAndGoNz on TikTok  \nYou could follow Up and Go’s strategy in creating memes related to their products on TikTok, which is a great way to engage with your viewers!\nBusiness type perfect for this: all businesses should try this!\n4. Duet Duet videos on TikTok allow you to collaborate with your viewers. By doing a duet on TikTok, you can make clips featured similarly with an original one as a comment or reply, with both videos appearing side by side.\nOne of the most popular duet videos is by Gordon Ramsay.\nGordonRamsayOfficial on TikTok  \nCreating duet contents on TikTok means that you will be able to reach more people quickly.\nSome duet ideas: duet me, reaction video, comment video.\n5. Cooking Food. Who does not love food?!\nSuppose you own a restaurant or a food and beverage business in general. In that case, this is a great way to showcase your business.\nBy creating cooking contents, you can show your viewers what you don’t usually let people see when they eat a restaurant. You can also give ‘secret menu hacks’ for your customers to tell them a secret recipe for them to order at your restaurant.\nBusiness type perfect for this: restaurants, bars, food trucks, fast food chains.\nTheKoreanVegan on TikTok  \n6. Pet Videos If you are in the vet or pet grooming business, you should definitely try this out.\nYou can show your customers how you take care of the cute fluff buns. You can also use this opportunity to educate people on how to take care of their pets.\nSome pet videos content ideas are: how to train your pet, how to groom your pet, why you should foster animals, how to groom your pet, pet food ideas.\nGirlWitheDogs on TikTok  \n7. A Day In A Life Of This idea is perfect for showing your viewers what a day in your life looks like, whether you are a student, stay-at-home parent, business owner, technician, etc.\nMany teenagers who are currently looking for ideas on what university major they choose would love these contents. You can also debunk stereotypes about your occupation!\nMr_Mayonnaise_ on TikTok  \n8. Music If you are a musician, making music content is one of the best ways to popularize your songs. There are many musicians these days that gain a recording contract with music labels through TikTok.\nSome of the trending TikTok musicians are Salem Ilese, Olivia Rodrigo, Mia Rodriguez, Conan Gray, Marvin Rose.\nConanConanGray on TikTok  \n9. Small Business Being a small business owner is not easy. That is why creating TikTok videos can give authenticity to your small business.\nYour viewers can know the measures that you take to provide and deliver the best products and services to them.\nMany times, small business owners will put extra efforts to give the best services to their customers.\nShowing your viewers what you do is a great way to bring traction and attract potential customers.\nDianeKVeganBeauty on TikTok  \n10. Tutorials By creating tutorial videos, you are able to teach your viewers how to do certain things. You can make quick tutorial videos ranging from 15 to 60 seconds.\nWith the help of TikTok, you can create contents that are useful for other fellow TikTokers.\nSome tutorial ideas: How to change your car oil, how to get a scholarship, how to answer interview questions.\nTeachMeExcel on TikTok  \nNow that you have ideas on what contents to put on your TikTok account, why don\u0026rsquo;t you try Video Translator?\nHere at Video Translator, we provide AI Transcription, Translation, Hard Coded Captions and dubbing.\nBy using Video Translator, you can :\n1. Transcribe or create closed captions easily Transcribe your videos  \nClosed caption is crucial because it:\n Helps deaf and hard of hearing individuals watch videos; Helps people to focus on and remember the information more easily; Lets people watch it in sound-sensitive environments; and Allows you to optimize your SEO  2. Translate your video contents so you can reach a wider target audience Translate your videos  \nYou may have video contents in English, but what if turns out most of your viewers are in Spain? The solution is by translating your videos.\nTranslating your contents allow you to:\n Reach a wider target audience Gain more views Expand your market Attract more viewers  3. Dub your video in your target language Dub your videos  \nIf your viewers like contents that are dubbed in their language preference, this method is perfect for you. You can get contents spoken in their language on top of the closed captions.\nSo, are you ready to share your contents on TikTok?!\nFor more information regarding Video Translator, send us an email at hello@videotranslator.ai.\n","permalink":"https://videotranslator.ai/news/10-tiktok-content-ideas/","tags":["English"],"title":"10 TikTok Content Ideas "},{"categories":["Video translation","Translation","Languages","Artificial Intelligence"],"contents":"Learning a new language is not easy, but it does not mean that it should be hard.\nIf you have given up the idea of being bilingual (or trilingual? Maybe multilingual?), you should definitely read this article!\nLet\u0026rsquo;s begin!\nHere are 10 tips for you if you want to learn a new language:\n1. Find your motivation Find your motivation  \nFinding your motivation is the most fundamental tip to learn a new language. You want your learning experience to be fun and exciting, not dull and exhausting.\nSo, how do you find your motivation?\nYou can find it everywhere!\nWhen I was a kid, my motivation to learn English was to understand what the celebrities said when they were interviewed on TV.\nCelebrity  \nIt is corny, I know, but it worked!\nYour motivation can be to reconnect to your culture, build new connections or explore other cultures.\nFinding your motivation will help you stay committed to your journey of learning a new language.\n2. Set a goal When I was studying for my Bachelor\u0026rsquo;s degree, I discovered this cool goal-setting acronym called SMAART.\nThe SMAART goal stands for Specific, Measurable, Aggressive yet Achievable, Relevant, and Time-bound.\nSMART goal  \nWhen goals are set with this acronym, greater outcomes can be reached since you know exactly what you want.\nAn example of a SMAART goal could be:\n I want to be able to watch Korean Drama without subtitles in six months. To reach this goal, I am going to learn 20 new phrases every day.\n In 6 months, you would have learnt 18,000 new phrases!\nHaving a SMAART goal will help you achieve your goal quicker.\n3. Watch foreign shows Watching foreign shows  \nThis tip is my favourite.\nSure, learning your target language\u0026rsquo;s grammar is important. However, the native speakers don\u0026rsquo;t speak as to how the textbooks teach you.\nThe textbook language is way too formal.\nSo, what\u0026rsquo;s the best way to speak a language the way the natives do? Watch foreign shows.\nBy watching English TV Series, I was able to learn new slangs. I learn slangs such as \u0026ldquo;ditch\u0026rdquo;, \u0026ldquo;chill\u0026rdquo;, \u0026ldquo;slay\u0026rdquo;, \u0026ldquo;stan\u0026rdquo;, \u0026ldquo;spill the tea\u0026rdquo; by watching TV.\nIt is also easier to pick up new phrases by watching foreign shows.\nFor example, when I was watching a Korean Drama, these phrases are constantly repeated:\n  가지마/ga-ji-ma (don’t go)\nK-drama: don\u0026#39;t go  \n  보고싶어/bo-go-sip-eo (I miss you)\nK-drama: i miss you  \n  괜찮아/gwaenchanh-a (Ok or are you ok?)\nK-drama: are you ok?  \n  미안해/mian-hae (I\u0026rsquo;m sorry)\nK-drama: i\u0026#39;m sorry  \n  어떻게/eo-tteoh-ge (how?)\nK-drama: how  \n  So, now when I\u0026rsquo;m talking with my Korean friends, I will randomly insert those phrases in my sentence!\n4. Converse with others Converse with others  \nOne of the challenges of learning a new language is not having anyone to practise with.\nI could not master Mandarin when I was still in school because I had no one to practise with.\nMy parents do not speak Mandarin, and my classmates were just as terrible as I did.\nWhen I started my part-time job, I had many Chinese friends. I learnt so much more new Mandarin phrases than I did for my 12-year Mandarin lessons back in school.\nIf you can\u0026rsquo;t find anyone to converse with, you can always find someone who is willing to on the internet. You can do it from Twitter, Reddit or even by playing online games!\nI made so many good friends on Twitter, and I have met most of them in different countries!\n5. Leave your comfort zone leave your comfort zone  \nI know some people from school who have lived most of their lives in Indonesia but cannot converse in Bahasa Indonesia. They went to a school with English as a medium, lived in a neighbourhood full of expatriates and made friends with foreigners. They did not have a reason to learn Bahasa Indonesia.\nIf you really want to learn a new language, you need to leave your bubble and expand your network. Go make friends with people who speak your target language.\nAnother important aspect of leaving your comfort zone is to be confident in speaking your target language.\nI struggled a lot to learn Mandarin because I was afraid of pronouncing the words wrong. Mandarin has different tones, and different tones have different meanings.\nI was always made fun of when I pronounced the wrong words. It crushed my confidence.\nWhen I conversed with my colleague during my part-time job, they never made fun of my \u0026lsquo;broken Mandarin\u0026rsquo;. They helped me pronounce the words correctly and boosted my confidence.\nLeaving your comfort zone will be scary, but trust me, it is worth it!\n6. Listen to podcasts listen to podcasts  \nIf you do not have time to watch movies, tv-series, or videos, you can always listen to podcasts. Nowadays, there are many language programs on Spotify or Apple Podcasts.\nYou can download the podcasts or stream them on the way to work.\nListening to podcasts will help you familiarize yourself with the words.\nYou can also increase the audio speed if you think that the speakers are speaking too slow or decrease the speed if you feel that they are talking too fast.\n7. Make flashcards Make flashcards  \nFlashcard is an effective tool to study.\nWhen you learn a new language by reading a textbook, you can get overwhelmed by the number of words that you see.\nFlashcards allow you to learn new words without cluttering your mind.\n \u0026ldquo;Flashcards give your brain a very quick way to check if you got the answer correct. They also help you engage in active recall, which teaches your brain to remember a term, concept or process without context clues. They allow you to repeat the act of learning and memorizing until you are an expert on the information,\u0026rdquo; said the Marketing Director of Peterson\u0026rsquo;s, Elizabeth Barry.\n 8. Write Writing  \nAccording to experts, writing by hand appears to improve our ability to remember things.\nFor this reason, you should definitely practise writing in your target language.\nIt does not have to be an essay. You can simply rewrite a text, poem, or short story.\nThe whole point of practise writing is to help you familiarize yourself with the words and help you remember the things.\n9. Read Reading  \nReading a text in your target language will help you practise your pronunciation.\nTry reading a book aloud.\nYou can stop when you find an unfamiliar word, write it down, find the meaning and resume.\nIf you keep on doing it, you will definitely be able to master your target language!\n10. Practise every day \nYes, you heard me right.\nPractise every day!!!\nDaily habits easily eliminate distractions because you are focused only on those things that need to be done.\nIf you want to learn a new language, don\u0026rsquo;t just do it every other day. You will most likely forget what you have learnt or lose your motivation.\nMake a daily schedule that can accommodate your SMAART goal.\nPractising can come in different forms, as I have said in the previous tips. Here is an example\u0026hellip;\nIf you want to learn Spanish, you can do this:\nMonday: watch a Spanish movie after work or school\nTuesday: Have a zoom call with your online Spanish friend\nWednesday: Spend your evening with people from the Spanish community\nThursday: Listen to Spanish podcasts on the way to work\nFriday: Read a Spanish news article in the morning\nSaturday: Write Spanish poems before doing your chores\nSunday: Read a Spanish book before going to bed\nPractising every day does not have to be dull and boring. You can do different things as long as you keep on doing it regularly.\nNow that you are ready to master a new language, why don\u0026rsquo;t you try our tool that can help you translate video contents quickly and efficiently?\nHere at Video Translator, we use Artificial Intelligence to translate your videos conveniently.\nFind out why you should use AI-powered translators here or contact us at hello@videotranslator.ai for more information.\n","permalink":"https://videotranslator.ai/news/10-tips-to-learn-a-new-language/","tags":["English"],"title":"10 Tips That Actually Work If You Want To Learn A New Language"},{"categories":["Users","Video translation","Translation","Languages","Dialects","Artificial Intelligence"],"contents":"I was born in Indonesia, a country with over 250 million population scattered across its 17,000 islands. When I came to Australia four years ago, I noticed that most Australians with Indonesian background or mixed raced Indonesians do not know how to speak Indonesian.\nIndonesia, the land with 17,000 islands  \nSo, I began to question myself: how important it is to learn a foreign language? I came up with few answers…\nLearning a foreign language allows you to build connections If you didn’t know, Indonesia is a country with over 300 native languages. Growing up here, you would think that my mother tongue would be Bahasa Indonesia. However, my first language is a dialect from the South Sumatera province called Palembang.\nAmpera Bridge in Palembang, South Sumatera, Indonesia  \n According to Asian Languages and Literature from the University of Washington, “While Bahasa Indonesia is spoken as a mother tongue by only 7% of the total population, it is the national language and is used by 200 million people as their second language.”\n If my mother tongue were not my local dialect, I would have struggled to communicate with my relatives. The locals take pride in speaking their local dialects.\nFun fact, if you travel to Indonesia, you will most probably get a discount if you can speak in their local dialect.\nAlthough our local dialect is our mother tongue, most Indonesians can speak Bahasa Indonesia as it is our official language.\nBahasa Indonesia is commonly used for business and administrative purposes as well as by education institutions and mass media throughout the country to facilitate communication among the Indonesians.\nMy mind began to wander to the times when my family would travel to different provinces. We would visit some local shops to buy some souvenirs. Although the staffs would generally speak in a local dialect, they would immediately switch to Bahasa Indonesia when they talk to customers.\nAn Indonesian lady holding local street food  \nIf I hadn’t been able to speak Bahasa Indonesia, I would be stuck in my tiny little bubble in South Sumatera and struggle to communicate with everyone else across the country.\nLearning a foreign language will help you see the world When I was in primary school, my parents sent me to study in a school that uses English as the medium of instruction. I struggled a lot in the beginning as none of my parents speaks English.\nLittle girl going to school  \nAs a kid, I was timid to speak English in front of anyone. I thought my English was terrible, and I didn’t know enough vocabularies to express how I feel.\nI think it took me about six years to finally have the confidence in speaking English.\nIt was not until I was in middle school that I realized how blessed I am to understand English. That day, I wanted to share an online article with my parents. Since they do not speak English, I needed to find the translated version. However, I couldn’t find any!\nSearching the internet  \nThere is limited information that you can have when you do not know how to speak a foreign language. By learning English, I was able to gain so much more information about everything I want to know.\nLearning a foreign language deepen your connection to other cultures If there were one language that I regret not learning, it would be Mandarin. As an Indonesian with a Chinese background, my parents wanted me to know Mandarin. Their generation lost touch with their mother tongue because its use was banned in the country.\nChinese lantern  \nAs a young kid, I hated learning Mandarin. I would be sent to after-school Mandarin class and hated every bit of it. I was not good at it. I felt embarrassed when I speak the language because my friends would laugh at me.\nTruth be told, I was proud to say to people that I was terrible in Mandarin. I boasted of my inability to speak a foreign language.\nLooking back, I feel so silly. I wish I hadn’t done what I did.\nWhen I moved to Australia, I had a part-time job in a café where I worked with many Chinese people. That’s the moment that I realized that I should have taken my Mandarin classes seriously.\nAs a 21-year-old third-generation Chinese Indonesian, I know nothing about my history. I did not know even know the name of my great grandparents. Even if I did, I won’t be able to read their names because they would be written in Mandarin. This also means that I won’t be able to look for their names in the Chinese registry database.\nChinese calligraphy  \nSure, learning a foreign language gives you various advantages in life. However, you cannot possibly know all 7,000 languages.\nSo, what is the solution?\nArtificial Intelligence Translator Yes, you heard me right. Artificial Intelligence Translator.\nTo translate an English article into Indonesian, I would need to think about how I can translate the article sentence by sentence. With the help of AI Translator, it can automatically translate the article, and I just have to make minor changes to make sure that the translation is accurate.\nAI translator saves me so much time.\nYou might wonder, who provides AI translation services?\nYou are at the right place!\nHere at Video Translator, we provide AI transcription, translation and dubbing services. Whatever your use case is – whether you want to manage a diverse client base, expand to the international market, support multilingual stakeholders – we are here to optimize your businesses.\nVideo Translator provides AI transcription, translation and dubbing services  \nLearn more about how we can help your businesses here or contact us at hello@videotranslator.ai.\nAlso read how we helped Jeff Dormish to create a long-lasting legacy.\n","permalink":"https://videotranslator.ai/news/the-importance-of-learning-a-foreign-language/","tags":["Indonesian","English"],"title":"The Importance Of Learning A Foreign Language"},{"categories":["Video translator","Video translation","Video transcription","Support","Transcription","Translation services","Translation","Subtitles","Languages","Enterprise","Case Study"],"contents":"I believe everyone wants to leave a legacy.\nMany people choose to pass on their homes, investments and possessions.\nFor Jeff Dormish, leaving a legacy means so much more than that. He does not just want to leave possessions; he wants to pass on his history.\nFor many Americans, most of their ancestors came from Europe in the great emigration wave before the First World War. Jeff Dormish’s ancestors also came from Europe, Slovenia, to be exact.\nSlovenia  \nIn 2016, he began on a journey to discover his past.\nAlong with 49 other Americans, Jeff participated in an international genealogy conference organized by the Slovenian Genealogy Society.\nSlovenian Genealogy Society International, Inc.  \nOn this trip, he directly saw and experienced the place where his ancestors had once resided. At that moment, the things that he had seen in pictures have come to life. Lucky for Jeff, the life-changing trip that he had undertaken was covered by a Slovenian TV station.\n5 years later, Jeff has become the President of the Slovenian Genealogy Society International based in Cleveland, Ohio. He wanted to put the 12-minute video from the Slovenian TV coverage in the archive of the genealogy group, hoping that it could help and inspire others in a similar situation. However, it was primarily spoken in Slovenian, a language that he could neither speak nor understand.\nJeff wanted the video to be translated into English. That is when he contacted VideoTranslator. Equipped with the video and Jeff’s parent’s family picture, I began to do my work.\nTranscribing The Video Before translating the video, I used VideoTranslator\u0026rsquo;s application that can automatically transcribe videos by using the AI system that is embedded in the app.\n\nTranslating The Video I understand that things can easily get lost in translation. That is why a professional translator was hired. The transcription from Video Translator\u0026rsquo;s app was transferred into a txt file and sent to a translator. The translator then came back with the translated subtitles of the video.\nCreating Burnt-In Subtitles The original video has burnt-in subtitles in Slovenian. I wanted to make sure that the new burnt-in subtitles would match the current one.\nFirst, I synced the translated subtitles to the video by using Adobe Premiere Pro. I shifted the timing a little bit to match the dialogues.\nEditing Caption Timing on Adobe Photoshop  I also added a black background behind the text with 90% transparency to make it easier for people to read and match the style of the original video.\nEditing Caption on Adobe Photoshop  After editing it, I saved the file with the burnt-in subtitles in the video.\nAfter I sent the video with the burnt-in subtitles to Jeff, he asked me to fix some name spelling errors. I realized that the spelling errors were mainly from the original video, not from the translation.\nJeff Dormish Name Typo  So, how can I fix this problem?\nI figured that I can fix this by adding a text overlay on top of the original one. I used matching font style and size and corrected the spelling errors.\nEditing Jeff Dormish\u0026#39;s Name  In the end, it looks like it was not edited at all!\nFixing Up Damaged Photo Jeff had sent us a picture of his parent’s family photo. However, the image is damaged with discolouration on the right side.\nDormish Family, Meyersdale, PA, 1928 Before Editing | Image Credit: Jeff Dormish  I know how much it would mean for him to have the picture fixed up, so I did.\nI used Adobe Photoshop to fix the image. I replaced the damaged area with pixels from the undamaged picture by using the patch tool.\nThis is the end result.\nDormish Family, Meyersdale, PA, 1928 After Editing | Image Credit: Jeff Dormish  \nWhat I Learnt Jeff’s story resonated with me. As an Indonesian of Chinese ancestry, I too often find myself wondering about my own families story.\nWhere were they from?\nWhy did they move?\nWho were the important people in their lives?\nI was born and raised in Indonesia.\nMy family does not speak mandarin, and my grandparents did not teach the Chinese dialect to me. Just like Jeff, language is a big challenge in discovering my own story.\nSeeing how far Jeff has come and what he wanted to pass along to his children has inspired me. Someday I would also like to see the places where my people had lived, how they spent their lives, who their partners and children were, and untangle the mysteries of my past.\nConclusion Helping Jeff, who wants to leave a long-lasting legacy for his family, is one reason why we do what we do. We hope to help more people build legacies and find answers to their biggest questions in the future.\nIf you need our help in translating your videos, do not hesitate to contact us at hello@videotranslator.ai.\n","permalink":"https://videotranslator.ai/news/leaving-a-long-lasting-legacy-by-curating-your-familys-history/","tags":["English"],"title":"Leaving A Long-Lasting Legacy: Curating Your Family’s History"},{"categories":["Video translation","Translation","Languages","Artificial Intelligence"],"contents":"Pada kesempatan kali ini, kita bakalan ngebahas 3 alasan kenapa kalian harus mencoba penerjemah bertenaga kecerdasan buatan.\nBuat kalian yang nggak tau apa itu kecerdasan buatan atau artificial intelligence, yuk kita cari tau!\nSejarah Kecerdasan Buatan Percaya atau nggak, kecerdasan buatan dipopulerkan oleh cerita anak-anak yang berjudul The Wizard of Oz. Ceritanya dimulai dengan manusia kaleng dari Wizard of Oz yang bercita-cita untuk memiliki hati. Kemudian dilanjutkan oleh robot manusia yang menyamar sebagai Maria di Metropolis.\nKiri: Wizard of Oz | Kanan: Alan Turing Umur 16 Tahun (Image credit: Alan Turing Archive)  \nPada tahun 1950, seorang ilmuwan yang genius dari Britania Raya bernama Alan Turing menulis makalah tentang Mesin Komputasi dan Intelijen dimana dia membahas tentang pembuatan mesin cerdas dan menguji kecerdasan mereka. Buat kalian yang penasaran tentang Alan Turing, coba nonton filmnya yang berjudul The Imitation Game.\nWalaupun dongen-dongen dan ilmuwan seperti Alan Turing udah menginspirasi kelahiran dari kecerdasan buatan, konsep tentang kecerdasan buatan baru dimulai pada tahun 1956. Program kecerdasan buatan pertama dibuat berdasarkan konsep Logic Theorist oleh Allen Newell, Cliff Shaw, dan Herbert Simon.\nSemenjak itu, kecerdasan buatan berkembang pesat sampai saat ini.\nKenapa Penerjemah Bertenaga Kecerdasan Buatan Itu Penting? Kecerdasan Buatan Menciptakan Pekerjaan Baru Banyak orang mikir kalau teknologi itu bakalan menghilangkan banyak pekerjaan. Forum Ekonomi Dunia memperkirakan bahwa otomasi bisa menyebabkan hilangnya 75 juta pekerjaan. Namun, mereka juga memprediksi bahwa otomasi bisa menciptakan 133 juta lapangan pekerjaan baru pada tahun 2022.\nInovasi seperti software penerjemah yang didukung oleh tenaga kecerdasan buatan tidak menghilangkan pekerjaan. Kenyataannya adalah industri seperti kami membuka lapangan pekerjaan baru. Penerjemah bertenaga kecerdasan buatan masih membutuhkan campur tangan manusia untuk memastikan bahwa perangkat lunak yang dipasang dapat berjalan dengan lancar. Selain itu, berbagai macam perbaikan baik dari sisi perangkat lunak maupun pengguna harus terus-menerus dilakukan. Penerjemah bertenaga kecerdasan buatan akan membutuhkan insinyur perangkat lunak, disainer, ahli informasi teknologi, dan banyak lagi.\nTerjemahan yang Didukung Kecerdasan Buatan Bisa Menjangkau Lebih Banyak Orang Bahasa Inggris adalah bahasa yang paling banyak digunakan di dunia. Penggunaan bahasa Inggris sangat dipengaruhi oleh kolonialisme Inggris. Inggris memperkenalkan bahasa Inggris di wilayah jajahan mereka di seluruh dunia. Hal ini membuat Bahasa Ingrris menjadi bahasa yang paling banyak digunakan di seluruh dunia dengan 1,35 miliar penutur.\nJangkau Lebih Banyak Orang Dengan Penerjemah Bertenaga Kecerdasan Buatan  \nMenariknya, dari sekian banyak penutur bahasa Inggris, hanya ada sekitar 30% dari mereka yang Bahasa ibunya adalah Bahasa Ingris. Selain Bahasa Inggris, 30% dari populasi di dunia berbicara Bahasa Mandarin, Hindi, Spanyol dan Perancis.\nJika kalian menggunakan penerjemah yang didukung kecerdasan buatan, kalian bisa menerjemahkan dokumen dan konten secara otomatis. Bayangin kalau kalian menerjemahkan dokumen dan konten kalian ke empat bahasa lain yang paling banyak digunakan, sekarang kalian bisa menjangkau jauh lebih banyak orang.\nTerjemahan Yang Didukung Kecerdasan Buatan Meningkatkan Upaya Manusia Waktu itu berharga. Kami ngerti kalau penerjemah yang didukung AI nggak bisa menggantikan penerjemah manusia. Kurangnya sentuhan manusia adalah hal yang hilang dari penerjemah yang didukung kecerdasan buatan. Oleh karena itu, kami hadir untuk membantu para profesional tersebut.\nDengan penerjemah yang didukung kecerdasan buatan, kami bisa membantu penerjemah profesional untuk menerjemahkan dokumen mereka secara otomatis. Proses ini bakalan bermanfaat banget untuk menerjemahkan video. Sebelum ada penerjemah yang didukung kecerdasan buatan, penerjemah profesional harus mengetik subtitle secara manual dan menyesuaikan waktu subtitle agar sesuai dengan video. Semua tugas ini sekarang dapat dilakukan oleh perangkat lunak AI.\nSingkatnya, perangkat lunak kami meningkatkan kecepatan, ketepatan, dan efektivitas upaya manusia.\nTunggu apa lagi? Ayo, coba penerjemah bertenaga kecerdasan buatan sekarang! Hubungi kami sekarang di hello@videotranslator.ai .\n","permalink":"https://videotranslator.ai/news/3-alasan-untuk-mencoba-penerjemah-bertenaga-kecerdasan-buatan/","tags":["Indonesian"],"title":"3 Alasan Kenapa Kalian Harus Mencoba Penerjemah Bertenaga Kecerdasan Buatan (AI-Powered Translator)"},{"categories":["Translation professionals","Translation","Artificial Intelligence"],"contents":"In this article, we are going to give you 3 reasons why you should use AI-Powered translators.\nTo begin with, let us jump into the history of AI.\nHistory of Artificial Intelligence Believe it or not, artificial intelligence was familiarized by a children’s story called The Wizard of Oz. It began with the “heartless” Tin man from the Wizard of Oz and continued with the humanoid robot that impersonated Maria in Metropolis.\nHistory of Artificial Intelligence  \nIn the 1950s, a young British polymath called Alan Turing wrote a paper about Computing Machinery and Intelligence where he discussed building intelligent machines and testing their intelligence.\nIt wasn’t until 1956 that the concept of artificial intelligence was initialized. The first artificial intelligence program was presented based on the concept of Logic Theorist by Allen Newell, Cliff Shaw, and Herbert Simon.\nSince then, artificial intelligence flourished and went on a roller coaster journey of successes and setbacks.\nWhy Is AI-Powered Translator Important? AI Technology Is Creating New Jobs Many people think that technology is taking away jobs. The World Economic Forum estimated that automation may cause a loss of 75 million jobs. However, it also noted that 133 million new jobs will emerge by 2022.\nThe truth is, technological innovations such as AI-powered translation software like us do not take away jobs. In fact, we are making new pools of jobs. AI-powered translators still need human touches to ensure that the software runs smoothly. In addition, updates both from the software and user interface sides are constantly needed. AI-based companies will need software engineers, designers, IT professionals, and many more.\nAI-Powered Translation Helps You Reach A Wider Audience English is the most spoken language in the world. The widespread use of the English language is heavily influenced by British colonialism. The United Kingdom imposed English on their territories around the world, hence making it the most spoken language worldwide with 1.35 billion speakers.\nReach Wider Audience With AI-Powered Translastor  \nInterestingly, out of the billion English speakers, only about 30% of them are native speakers. About 30% of the world speak Mandarin, Hindi, Spanish and French.\nIf you use an AI-powered translator, you can automatically translate documents and contents. Imagine if you translate your documents and contents to four other most spoken languages, you can now reach 30% more of the world population.\nAI-Powered Translation Enhances Human Efforts Time is valuable. We understand that AI-powered translators cannot beat human translators. The lack of human touch is what AI-powered translators are missing. Therefore, we are here to help these professionals.\nWith AI-powered translators, we can help professional translators to automatically transcribe their documents. This process is especially beneficial in translating videos. Before the existence of AI-powered translators, professionals need to manually type down the scripts and adjust the script time to match the video. All of these tasks can now be done by AI software.\nIn short, our software enhances the speed, precision and effectiveness of human efforts\nConclusion The world is changing. AI is already changing and affecting a big part of our everyday lives. You should use an AI-powered translator because it is creating new jobs, help you reach wider markets and enhance your human efforts.\nIf you want to use AI-powered translator but do not know where to start, we are here to help you. Do not hesitate to contact us at hello@videotranslator.ai .\n","permalink":"https://videotranslator.ai/news/why-you-should-use-ai-powered-translator/","tags":["English"],"title":"Why You Should Use AI Powered Translator?"},{"categories":["Video translator","Video translation","Video transcription","Translation","Transcription","Subtitles","Languages","Dubbing","Case Study"],"contents":"Many of you would have heard about translation. According to Kristen Malmkjær, translation is an activity that aims to convey meaning or meanings of a given linguistic discourse from one language to another.\nWhat are the difficulties in translation? As a multilingual speaker, I have frequently asked to translate different languages. My family would ask me to translate files such as reports, articles and legal documents. However, translation also comes with its challenges.\nFirst, there are so many languages out there, and I cannot possibly learn everything. Currently, there are about 7,000 available languages around the world. Meanwhile, I only know four.\nSecond, it is easier to translate texts than videos. When there is a text available, I can retype the text and instantly translate the text. However, with a video, you need to transcribe the texts manually. It is even more challenging when you are trying to translate a video in a language that you do not speak.\nHow to easily translate your videos Video Translator wants to ease the difficulties in translating videos by offering three simple steps.\nVideo Transcription Transcribing your video  \nTranscription is the processing and transferring speech sounds into timed-text displayed on video. Video Translator uses artificial intelligence software to transcribe your videos automatically. Automatic video transcription can help you save your time by instantly converts your speech into timed text. This way, you don’t have to type the text and adjust the timing manually. Having automatic transcription is also beneficial when you are trying to transcribe speech from a language that you do not speak\nVideo Translation Translating Your Video  \nVideo translation is the process of turning your footage into a video that is suitable for multilingual audiences. As I have said before, translating a video can be challenging, especially with the massive number of available languages out there. Video Translator offers translation in over 60 languages and 150 dialects. It can easily translate texts derived from the video transcription into these languages.\nVideo Dubbing When it comes to captions, not everyone is a fan. Some people dislike reading them, while some struggle to read captions. That is why video dubbing comes in handy. Video Translator’s artificial intelligence can convert text to speech. You don’t have to be afraid of mispronouncing the texts because we can dub your video.\nCase Study By having your videos translated, you can now reach a broader range of audience. Let me give you an example. Let’s say that you are the manager of a global company. Your employees come from different countries and speak various languages. Some of your employees only know English as a second language, while some do not speak English at all. Meanwhile, you have a training video that you want to share, but it is spoken in English.\nYou can easily solve this problem by using Video Translator’s services. You can first transcribe your video. The video transcription helps your employees who know English as a second language to follow along with the speech. After that, you can translate the text into your target languages. This way, you can have one video with multiple translated subtitles. Finally, you can dub your videos. With the text to speech tool, your training video is now spoken in the language that your employees understand.\nConclusion So, in conclusion, Video Translator eases your video translation difficulties by transcribing, translating and dubbing your videos.\nSo, what are you waiting for? Try out our service now!\n","permalink":"https://videotranslator.ai/news/how-to-conveniently-translate-your-videos/","tags":["English"],"title":"How To Conveniently Translate Your Videos "},{"categories":["Enterprise","Management","Support","Video translator"],"contents":"What Comes Next Things never go right in a startup.\nHonestly. Even when they go right, generally something odd happens and it all works out for the best, but things tend to not go to plan, so to speak.\nFirstly, for those of you who have recently joined our little community, welcome!\nWe are very glad to have you here, and hopefully the work of Team VideoTranslator and our community of friends, well wishers, prospects, and clients will help you achieve your goals.\nThis is a short post about what comes next.\nTurns And Roundabouts Renee moved on at the end of last year, to the far more important gig of being mum to her second child!\nWe wish her all the best! You\u0026rsquo;ll smash it for sure mate - best of luck.\nWe had a recent hire here at Team VideoTranslator, Tessa Joana, who takes the role previously held by Renee Dubé.\nTessa will be looking after our social media efforts, and also doing more besides in the video space.\nWelcome Tessa!\nWhat We Need To Fix Over the last few months, there have been numerous issues which need to be addressed in our Saas app. Putting together the feedbacks, the main issues are listed below.\nLack Of Documentation Our documentation is just not every good. So the plan is to redo a lot of the documentation.\nIn addition, we will be turning a lot of the documentation into video content. This will all get put onto our YouTube channel which is getting a bunch more content and will be better tended to going forward.\nLanguage / Dialect Mapping Issues While we have an comprehensive language dialect mapping which adds great value to our clients, we do a less than stellar job explaining this content.\nIt is also relatively hard to add/remove additional languages for a user in terms of the UX (user experience flow).\nGeneral UX Challenges Many of the workflows were developed a year or so ago, and large parts of the app are beginning to show their age.\n The material ui version needs to be patched. The core text editor experience needs to be enhanced significantly. Adding synthetic voices, that is the AI dubbing workflow, are simply terrible.  Forums We are looking at getting a forum up and running. This is where a lot of client correspondence will be put in, including where we are going with many of our projects.\nWhy?\nThe basic idea is to make a single source of truth which is searchable.\nWe have also added a search to our website, but we have not yet turned on tracking on the search, but it seems to work well.\nSearch function on VideoTranslator website  \nSummary Good things are happening, and much more is in the pipeline. Reach out to us at hello@videotranslator.ai - to let us know what you think and what we can do to make your user experience better!\nThank you for all your support,\nTat Banerjee\n","permalink":"https://videotranslator.ai/news/what-is-next-for-video-translator/","tags":["English"],"title":"What Is Next For VideoTranslator?"},{"categories":["Managed Service","Happy New Year","Localization Industry","Internationalization Industry","Welcome"],"contents":"Happy New Year 2020 is over. Thankfully.\nThis might be tempting the fates just a bit, but really, 2021 has got to be better right!\nTeam VideoTranslator: Happy New Year  \nJokes aside, the big learning from 2020 was to be more grateful. The strength shown by people worldwide was extraordinary, and we could not be more grateful for the kindness of strangers, friends, and family in what was a difficult time.\nTo our clients - thank you! You guys are amazing!\nHow We Did On Engagement We did alright.\nSorta, kinda. Would have been nicer to make more money though.\nClicks From Google Search Console Team VideoTranslator: About 32K people clicked on our value proposition  \nEngagement From Google Analytics Team VideoTranslator: March -\u0026gt; June was quarantine season for us!  \nWhere Did Our Customers Come From? Team VideoTranslator: We really like organic search  \nHow Many Sign Ups Did We Get? Team VideoTranslator: We picked up about 1600 signups last year.  \nThe conversion goals code was a bit dodgy at the start of the year. Also for context, our Alexa Rank was 870,350.\nGeneral Plans For 2021 Lots of exciting things are in the works for 2021. In no particular order, we plan to:\n Setup a forum for our clients. The help / tutorials are frequently out of date, because so much of the app is still in active development. Restart email marketing. Due to Covid-19, and part of the team being in lock-down and/or quarantine, we gave up on email marketing. The engagement was pretty poor, but this could have been because we were not adding value. We\u0026rsquo;d like to give this another shot. Move help over to being video based, as opposed to text. We think this will help keep our help content up to date, but we need to work out a nice way to do this. We are working on a super secret project, which may or may not involve launching a multilingual web series in 2021. Stay tuned for more\u0026hellip;  Tech Plans For 2021  We are looking to add a number of languages. Some have already been added, keep on the lookout for the news item describing this! The UI is getting a pretty comprehensive overhaul - this is happening at the moment. We\u0026rsquo;d be keen to launch a mobile version by the end of 2021. Large number of Quality-Of-Life (QOL) additions are slated for Feb/March. Let us know if there is something you really care about!  People News  Renee Dube s moving on, mostly because she is going back to being a full time mum - congratulations Renee! We have a new social media person joining in the new year - stay tuned for more\u0026hellip; Pranay Shah moved on mid last year - the middle of the year was pretty hard due to Covid-19. Thank you Pranay for all your work, and best of luck with everything you do going forward. Two new developers have started / are starting early this year. Looking forward to introducing them to all our clients during the course of 2021!  For Our Clients You guys (and gals!) are brilliant - thank you so much for your support over what has been a very challenging year.\nThank you so much for your patronage, your kind words, and putting up with it when our tech had problems - we would not be anywhere without you. You are champions and totally awesome.\nGod bless you all and thank you very much!\nTathagat Banerjee\n","permalink":"https://videotranslator.ai/news/year-in-review-2020-may-you-live-in-interesting-times/","tags":["Telugu","Tamil","Marathi","Malayalam","Kannada","Hindi","Bengali","Oriya","English"],"title":"Year In Review 2020"},{"categories":["Video translator","Welcome","Support"],"contents":"What a year it\u0026rsquo;s been! From getting locked down, to the great conjugation!\nObligatory Dancing Santa!   Merry Christmas 2020! Thank you for all the support!\n   Thank You Thank you everyone for all your support! We want to wish you and yours a Merry Christmas!\nEveryone who engaged with us, others that offered feedback, and folks who made a purchasing decision - thank you very much.\nThank you to everyone whose time, thoughts and work touched our lives.\nWe hope that your holiday season is joyful and surrounded by friends, family and good cheer, and next year is filled with wins virus free!\nThank you,\nTeam VideoTranslator\n","permalink":"https://videotranslator.ai/news/merry-christmas-2020-thank-you-from-video-translator/","tags":["English"],"title":"Merry Christmas 2020! Thank You From Video Translator"},{"categories":["Support","Subtitles","Captions","Case Study","Video translation","Video dubbing","Video transcription","Best Practices"],"contents":"At VideoTranslator we do a lot of work in the Internationalization And Localization industry.\nBut we are not transcribers, translators, or voice over artists. We use AI to do transcription, translation and synthetic (AI) dubbing.\nThis happens when a client is looking to try out tech and/or better understand the value proposition, or has their own reasons for us to provide this service.\nSometimes however, the most useful thing we can do is just have a conversation.\nThe email and discussion that follows is with Curt Jaimungal, an indie film maker from Toronto, who sent in an email.\nCurt is a very interesting entrepreneur, and you should totally check out his channel - Theories of Everything with Curt Jaimungal!\nThe below images are used with his permission.\nThe Use-Case Use Case: Translating Lectures  \nRight - so what is Curt asking about here?\nThe use case is quite straight forward to understand, \u0026ldquo;\u0026hellip; it would be great if I could simply drag and drop it into a program and it would output the lecturer speaking in English\u0026rdquo;\nIf we were to restate it, the use case here is that the client wants to:\n Upload a German video and have it transcribed. Translate the previously transcribed captions into English. Use an English speaking AI to synthetically dub the content into English and speak it out.  After which, he quite practically asks, \u0026ldquo;Is there an easy drag and drop interface to accomplish this?\u0026rdquo;\nThe ask is totally doable.\nIn fact, this is the exact service we provide managed service clients.\nBut the ask is can the app be used to do this? Absolutely.\nIts just \u0026hellip; not as nice as one would hope\u0026hellip;\nExample Of AI Voice Over, Or Synthetic Dubbing Have a look at this blog post - How QAChef Is Reaching Clients In A Tough Market - it covers the business side of such a process..\nThis is a more fleshed out version of what Curt is asking for - but the blog post looks at this from the point of view of ROI (Return On Investment) and how to use video translation to achieve specific marketing goals.\nYou should totally click on the link if you want to get a better handle on synthetic, or AI, dubbing.\nHow To Convert Your Video From English To German Have a look at this blog post - English To German Video Translation: What is a Babybündel?\nIt covers the mechanical aspects of how the process works, as in what to click within the app.\nThe process is a little ugly at the moment - and is an ongoing priority in our development schedule.\nSend us an email if there is a specific use-case you would like us to cater to for you\u0026rsquo;re preferred workflow.\nWhat do AI voices sound like? So lets say you are reading this blog post, but looking to translate into French or some other language?\nHave a look at this blog post - Samples From A Voice Over Robot: French, German and Dutch - it covers how we use different AI\u0026rsquo;s for different gender effect, age effects etc.\nBut what are the implications of an AI workflow? So we just pointed out how we can do what Curt wants, so why are we saying its messy?\nThree step process for video translation, (1) transcribe, (2) translate, and (3) synthetic voice over  \nTo fully translate a video from German to English, we would do the below.\nUpload the German video and use an AI to transcribe, resulting in a caption file (*.srt).\nAfter this, a human subject matter expert needs to clean up the captions.\nNow, the Text-To-Text translation AI can be used. Again, a human subject matter expert should be used to sanity check the translation.\nFinally, the third AI can be used to provide the synthetic voice over (*.mp4).\nWhat happens without human oversight? \nAs we move up information complexity, the quality of the AI\u0026rsquo;s output gets worse\u0026hellip; but why?\nHigh complexity information is valuable. You pay lots to go to a doctor or lawyer.\nThe information the doctor or lawyer has is scarce. This is why they are expensive - not many people have the skills that the doctor or lawyer has..\nThis scarcity means, there is less information on the internet, to train an AI with - this is why the quality falls a little bit.\nHow Do I Start With Video Translation? How Do I Start With Video Translation?  \nJust start with English (or in this case, German) transcripts - don\u0026rsquo;t translate to begin with\u0026hellip; Why?\nThe value add of captions is all about search.\nSearch engines don\u0026rsquo;t understand audio or video! They only understand text.\nWithout captions, search engines do not know what is in you\u0026rsquo;re video!\nThis is the whole point of VideoTranslator.\nWhen you (later) translate your captions - it means people searching for the video (in their words - i.e. in the other language) will find your video - even though it is still in English!\nEnglish captions only! Practically, use the VideoTranslator app and get the captions.\nMake any changes you\u0026rsquo;d like.\nDownload these as an *.srt file.\nUpload to multiple channels Upload the *.srt to YouTube.\nRead this blog post about how internationalisation can boost ROI, specifically the part about how duration impacts engagement by channel!\nWhat Should A Video Transcription And Translation Workflow Look Like? We can offer advice, or just a sympathetic ear - shout out to my translation friends :) - but this is the question!\nWhat level of ROI do you require, on a per video basis, to invest in the transcription and translation workflow?\nSo - general advice only - reach out and ask for specifics.\nMake small slices of the best bits of the video and use Captions + Auto-Overlay to measure engagement.\nHonestly, all you can do is try, measure, and refine.\nNo silver bullets (or snake oil) here sorry.\n\nThank you very much for the kind words Curt!\nPlease let the team know if we can help out in any other way.\n","permalink":"https://videotranslator.ai/news/why-you-should-translate-video-content-a-client-perspective/","tags":["English","German"],"title":"Why Should You Translate Video Content: A Client Perspective"},{"categories":["Accessibility","Video","Transcription","Translation","Video Translation","Video Transcription","Languages","Translation Services"],"contents":"AI is everywhere in the news these days. But something critical has changed recently.\nIn the near past, AI has gone from being super fancy to being, well... pedestrian.\nSay what now?\nWell - AI is becoming ordinary. And turning up in our office/productivity toolkits.\nIn recent days, Google has expanded its offering using AI, as has Microsoft, and so has Amazon.\nWhat does this mean for how we work, and how can you use this trend to advantage your business?\nNifty Live Transcription Features In Android Google is all over this space. I mean, why wouldn\u0026rsquo;t they be?\n Google Duo is working on messages transcription pic.twitter.com/kEltrIKULj\n— Jane Manchun Wong (@wongmjane) February 27, 2020   And there are all kinds of features.\n In a noisy place? No problem. Captions are now available on Google Duo, so you won’t miss a word of your video and voice messages. https://t.co/jqEvy9Vyn7 pic.twitter.com/gq5Z2ntn5P\n— Made by Google (@madebygoogle) August 19, 2020   Very cool.\nFull disclosure - videotranslator uses Google's AI Cloud offering for two parts of our value proposition. In video translation, the first step is a Speech-To-Text AI transcription, the second step is a Text-To-Text AI translation, and the thrid step is a Text-To-Speech AI dubbing.\nWe use Google AI Cloud offering for step 1 and step 3.\nHave a look at the ReviewGeek article about it too!\nMicrosoft Has No Intention Of Being Left Behind In this article - hot off the presses, all of 2 days ago - Microsoft talks about how to use transcription in its Office 365 offering.\n     Transcribe in Word is available today in Word for the web for all Microsoft 365 subscribers    Also very cool.\nSecond full disclosure - videotranslator uses Azure Cloud AI to manage the Text-To-Text AI translation in our application.\nAlso why we keep an eye on the Microsoft blog. Its actually very good, so maybe you should check it out too?\nAmazon Joins The Party Too This super interesting post - seriously, you should have a read - by Sheila McGee-Smith covers the approach Amazon is taking with its AI offering.\nWe don\u0026rsquo;t really use the Amazon AI suite, but its focus is enabling enterprise service delivery, so are not really experts on it. However, the below is a really good image which shows how certain Amazon partners are using the new capabilities.\n     AWS Acqueon AI integration model - source Sheila McGee-Smith    Very cool.\nSo it's cool because we are moving to looking at the innards of how this works, as opposed to hand waving about how awesome AI is. This is a critical point in the how AI is perceived, and hence used, in the real world.\nHow Can Your Business Make Use Of This Explosion In Capability So you probably have either GSuite, MS Office or some similar kind of productivity tool. Are you likely to use these capabilities?\nWell... maybe, I guess.\nI\u0026rsquo;m probably not, at least not immediately. So what is this article about?\nHow AI Can Actually Make A Difference To A Business AI needs to get you more clients. That is pretty much all there is to it.\nMaking cat videos is all good, and lots of exciting things are happening in TikTok type tools, but what can you actually do with it?\nIt's all about stackable marketing.\nThat\u0026rsquo;s it. That is the win. Not much more to it.\nHow Do I Make My Video Marketing Stack? So you make some kind of content. Blog post, video, LinkedIn article, podcast.\nTwo of these are not like the other two. Anything with text in it, can be searched.\nRead more about exactly how we can help you in the blog post below.\n     How to boost marketing ROI with your media assets    The actual utility of AI transcription, and translation - which videotranslator is all about - is to add text components to audio and video content for the explicit purpose of SEO.\nDoes AI Adoption In Productivity Suites Increase Audio/Video SEO? Yes, but... you still need to do the work to ensure the right content is targeted at the right channels.\nThe other big challenge is this - as we move up information complexity, AI accuracy reduces.\nDo NOT rely only on the AI - this is your business, and its reason for existence is to offer high complexity solutions to specific business problems. AI can help get you there, but is not a substitution for human subject matter experts.\nLet me repeat that - AI is not a substitute for human subject matter experts, and the industry is not remotely close to substituting AI for human judgement.\nConclusion Are you interested in our work? Reach out and say hello or get in touch some other way to start something\u0026hellip;\nPlease connect with us on LinkedIn, YouTube or Facebook for any comments, questions, or just to keep up to date with the work we do!\nIf you are interested in trying out our technology, please try our platform or drop us an email at hello@videotranslator.ai.\n","permalink":"https://videotranslator.ai/news/the-implications-of-ai-adoption-in-our-tools/","tags":["English"],"title":"The Implications Of AI Adoption In Our Tools"},{"categories":["Accessibility","Video","Transcription","Translation","Video Translation","Video Transcription","Languages","Translation Services","Case Study","Managed Service"],"contents":"One major challenge in diverse societies is the provision of healthcare services.\nIn western Sydney, this problem is directly tackled by the South-West Sydney Local Health District, which sits under New South Wales Health.\nOk - so obviously this is complicated stuff. But how does video translation help?\nIf you don't speak good English, specifically business English, finding information is very hard. The doctor is the only resource who can help, but what happens when they don't speak your language?\nIn this post, we look at how SWSLHD is trying to empower occupational therapists (OT\u0026rsquo;s) who work with developmentally challenged children.\nIt should be noted that the point of spending the money on these videos is the very long life they are expected to have - learn more about the ROI implications of video content here.\nHow To Reduce The Workload On Front Line Staff Doctors, nurses and medical professionals are clearly very busy people.\nAnd have gotten busier (!) due to Covid-19.\nBut the majority of work is around interfacing with parents.\nImagine you don't speak good English. You can get by, but that is kind of it. Now your child is sick. But your doctor does not know your language. Where do you get information from?\nThe simple answer is you spend time with doctors and nurses trying to get your concerns addressed in broken English.\nBut this is frustrating, and hard. And how do you know if you\u0026rsquo;re understanding is correct?\nFor SWSLHD, this is an enormously wasteful exercise in time (for front line staff) and money (for NSW Health), and introduces substantial risk to boot.\nThere must be a better way.\nGetting Resources Into The Hands Of Front Line Staff The specific test case SWSLHD was looking at was Occupational Therapists (OT\u0026rsquo;s) who were working with young mum's whose children have developmental difficulties.\nSpecifically, how to get information to the family unit - because if you can get the family to incorporate behavioural changes - that is the win, but across multiple languages.\nThe idea is to get information in different languages to the community - this allows families to educate themselves about the challenges, thus making time spent with doctors/nurses far more effective.\nThis is what the original English video is - OT\u0026rsquo;s show it to mum\u0026rsquo;s in the clinic.\n  How To Hold A Pencil - English\n   Online Resources To Help Patients Using Video Translation - Arabic This is the same video in Arabic.\n  How To Hold A Pencil - Arabic\n   Online Resources To Help Patients Using Video Translation - Vietnamese This is the same video in Vietnamese.\n  How To Hold A Pencil - Vietnamese\n   Conclusion We\u0026rsquo;d like to thank the staff at SWSLHD for being super easy to work with, and generally for the life altering work they do - you guys rock!\nAre you interested in our work? Reach out and say hello!\nPlease connect with us on LinkedIn, YouTube or Facebook for any comments, questions, or just to keep up to date with the work we do!\nIf you are interested in trying out our technology, please try our platform or drop us an email at hello@videotranslator.ai.\n","permalink":"https://videotranslator.ai/news/how-nsw-heath-is-using-video-translation-to-empower-occupational-therapists/","tags":["English","Arabic","Vietnamese"],"title":"How NSW Health Is Using Video Translation To Empower Occupational Therapists"},{"categories":["Accessibility","Video","Transcription","Translation","Video Translation","Video Transcription","Languages","Translation Services"],"contents":"Community captions are a function in YouTube. This function allows a YouTube content creator to crowd source captions for their video content.\nYouTube is shutting this down. Here is how it will affect you!\nChange To Community Contributions On YouTube     Notice about an upcoming change to community contributions on YouTube     Both creators and viewers have reported problems with the community contributions feature, including spam, abuse, and low quality submissions. As a result, the feature is rarely used with less than 0.001% of channels having published community captions (showing on less than 0.2% of watch time) in the last month.  Who Uses YouTube Community Captions Community captions emerged out of a cultural phenomenon known as fansubbing.\nBasically, practice of making fansubs is called fansubbing and is done by a fansubber. Fansubbers typically form groups and divide the work up. The first distribution media of fansubbed material was VHS and Betamax tapes.\nA major use case of fansubbing was translating Korean and Japanese anime for English speaking audiences.\nAre Community Captions Relevant Going Forward So there is clearly a requirement for adding captions/subtitles to video content. But are community captions the way forward?\nWe think the number speak for themselves - so no.\nThat being said, is the YouTube editor a great place to do fansubbing?\nProbably not. There are many creative techniques in fan-subbing which have no direct analogue to captions or subtitles as our client use the technique.\nVideoTranslator clients use subtitles for video SEO. Not as a creative curation (of sorts) of underlying content.\n    Should editors look for both video SEO and creative curation?    As an FYI - we are working on tools to make this happen right now - reach out to learn more!\nWhat You Should Do To Improve Your Own Video SEO Search Engines do not understand video, audio or images. They only understand text.\nThis is why you need captions and/or subtitles with any video content you produce.\n    Search engines cannot index video, audio or image, only text!    Use the Keyword Planner in Google Ads - its the easiest way to increase your content spend ROI!\nConclusion Are you interested in our work? Reach out and say hello!\nPlease connect with us on LinkedIn, YouTube or Facebook for any comments, questions, or just to keep up to date with the work we do!\nIf you are interested in trying out our technology, please try our platform or drop us an email at hello@videotranslator.ai.\n","permalink":"https://videotranslator.ai/news/why-youtube-stopped-community-caption-contributions/","tags":["English","Japanese","Korean"],"title":"Why YouTube Stopped Community Caption Contributions"},{"categories":["Best Practices","Video","Transcription","Translation","Dubbing","Video Translation","Video Transcription","Enterprise","Accessibility","Languages","Managed Service","Translation Services","Case Study"],"contents":"Vivekananda Yoga Anusandhana Samsthana or VYASA is a registered charitable institution (1986) working to make Yoga a socially relevant field of study.\nBased on the teachings of Swami Vivekananda, Vyasa University combines the four streams of Yoga with unity in their diversity, the key essence of Indian culture, applications of Yoga to bring health, harmony, peace the world over are now spread across the globe in nearly 30 countries.\n    Vyasa University: Using scientific research to bring Yoga into the modern world!    The mission of VYASA is to combine the best of the East (Yoga and Spiritual lore) with that of the West (modern scientific research).\nCovid-19 And Its Effects On India As of May 8th, 2020, 56,342 positive cases have been reported in India. India, with a population of more than 1.34 billion—the second largest population in the world—will have difficulty in controlling the transmission of severe acute respiratory syndrome Coronavirus 2 among its population.\nThe reaction of the Government Of India has been strong, as they realised that allowing the pandemic to run away would lead to serious loss of life given the limited per-capita medical facilities in India.\n    MoHFW: Working to reach stakeholders across India    The Ministry of Health and Family Welfare (MOHFW), India, has raised awareness about the recent outbreak and taken necessary action to control COVID-19. Besides, the MOHFW has created a 24/7 disease alert helplines and provided policy guidelines on surveillance, clinical management, infection prevention and control, sample collection, transportation, and discharging suspected or confirmed cases.\nVyasa Universities Contribution To The Fight Against Covid-19 Vyasa University was asked by GOI contacts within MOHFW and AYUSH to create content which raised awareness about Covid-19.\nBut how to get this out into various Indian languages, in a timely and cost effective fashion?\n    Vyasa University: Video Translation into 8 Indian languages    The outcome - have a look on their YouTube Channel!\nSample Vyasa University Video With Marathi Open Captions   ADULTS YOGA FOR COVID 19 WITH MARATHI SUBTITLES\n   Sample Vyasa University Video With Kannada Open Captions   ELDERLY PERSONS 2 YOGA FOR COVID WITH KANNADA SUBTITLES\n   Sample Vyasa University Video With Tamil Open Captions   YSRT YOGA FOR COVID 19 WITH TAMIL SUBTITLES\n   Conclusion It was a pleasure working the with staff and leadership at Vyasa University and we wish them the best of luck with their work going forward!\nPlease connect with us on LinkedIn, YouTube or Facebook for any comments, questions, or just to keep up to date with the work we do!\nIf you are interested in trying out our technology, please try our platform or drop us an email at hello@videotranslator.ai.\n","permalink":"https://videotranslator.ai/news/how-vyasa-university-is-fighting-covid-with-video-translation/","tags":["English","Marathi","Kannada","Hindi","Telugu","Tamil","Bengali","Oriya","Malayalam"],"title":"How Vyasa University Is Fighting Covid With Video Translation"},{"categories":["Best Practices","Video","Transcription","Translation","Dubbing","Video Translation","Video Transcription","Enterprise","Accessibility","Languages","Managed Service","Translation Services","Case Study"],"contents":"The hospitality business is in a hard place right now because of Covid 19.\nQAChef is a technology company which digitizes food safety compliance processes through a single handheld device, thus enabling unprecedented ingredient-to-customer food traceability and greater efficiency and productivity.\n    QAChef\u0026#39;s handheld device being used to measure temperature during cooking    So QAChef is in a fantastic position, a ready for market product which enhances traceability across large scale food production - perfect given the focus on food safety and associated health implications in the wake of the Covid-19 pandemic.\nBut its not likely to be that simple is it? QAChef\u0026rsquo;s clients are large scale caterers servicing industries like aviation, tourism and restaurant chains - all badly hurt by the slowdown in consumer confidence.\nHow do you convince a big prospect, in the face of a poor outlook, when business risk tolerance is at an all time low?\nIt's all about the relationship.\nWhy Choose AI Video Translation? In QAChef\u0026rsquo;s case, it was to demonstrate commitment to a relationship.\n\u0026quot;We understand you speak a different language from us, this is what we are doing to show you we will back our product in your market.\u0026quot;\nToo many companies from non-English speaking countries have been burnt by smooth talking salesmen who disappeared after making the sale.\nAI Dubbing sets the tone - a commitment to a new relationship.\nRedefine The Relationship Using Language - Service Internationalization/Localization QAChef\u0026rsquo;s clients are global players, and implementing new technology is always part of the context of successful internationalization.\nThere are three ways to implement service level internationalization.\n App Internationalization/Localization Website Internationalization/Localization Marketing Internationalization/Localization  QAChef has a intuitive handheld device, easy enough to use across languages. But the harder thing to internationalize is context.\n    Service Internationalization can include app i18n, website i18n and marketing i18n    What QAChef decided to do was internationalize their marketing efforts.\nFor this, they turned to VideoTranslator\u0026rsquo;s managed services.\nThe Marketing Internationalization/Localization Process Marketing internationalization means taking existing investments in marketing assets, internationalising these into another language and deploying to existing social channels with the appropriate metadata wrappers.\nIn the QAChef case, we worked to translate their existing video content.\nThis was done by (i) video transcription, (ii) video translation and finally (iii) video dubbing.\n    Video Translation is a three step process, transcription, translation and dubbing    This is the original video, and we will look at in Chinese and Arabic.\n  QAChef: CEO Message - Original\n   Video Translation In Chinese / Mandarin   QAChef: CEO Message - Chinese\n   The use case here was as part of a pitch to a global player with a significant mainland China footprint.\nVideo Translation In Arabic   QAChef: CEO Message - Arabic\n   The use case here was as part of a pitch to a major supplier to the aviation industry across the MENA region.\nNotes On Video Translation Its quite important to remember a few rules of thumb when you are doing a video translation.\n As you move up information complexity, the quality of AI gets worse. Why? Because higher complexity information is scarce - so its hard to train an AI on it. Hence you need human subject matter expert post editing. Don't sell the AI dubbed content as human. People are not silly, anyone can tell the difference between a human and a machine. Explain it is an AI - and no one will forget your pitch. If you put your video through a voice translator, the above will not be the output. There is a layer of diacritics being used prior to the AI dubbing.   Conclusion We hope you enjoyed the post, and stay tuned for more content!\nPlease connect with us on LinkedIn, YouTube or Facebook for any comments, questions, or just to keep up to date with the work we do!\nIf you are interested in trying out our technology, please try our platform or drop us an email at hello@videotranslator.ai.\n","permalink":"https://videotranslator.ai/news/how-qachef-is-reaching-clients-in-a-tough-market/","tags":["English","Chinese","Arabic"],"title":"How QAChef Is Reaching Clients In A Tough Market"},{"categories":["Best Practices","Video","Transcription","Translation","Subtitles","Video Translation","Video Transcription","Enterprise","Accessibility","Languages"],"contents":"A recent interview with FireTech Connect was really good fun, with Leigh Kelson hosting a free-wheeling discussion about crisis, technology and the future of AI in the internationalization and localization space.\nFireTech Connect The FireTech 2020 program is an initiative of the Peregian Digital Hub, a leading technology incubator based in Noosa on Queensland\u0026rsquo;s Sunshine Coast.\nFireTech Connect is funded by the Department of Industry, Science, Energy and Resources through the AusIndustry Entrepreneurs’ Programme; The Queensland State Government\u0026rsquo;s Advance Queensland Program; and Noosa Shire Council.\nLeigh Kelson is the Program Director of FireTech - he is a technology entrepreneur, cloud computing pioneer, and media tech veteran. He has founded ten ventures over the last 30 years and had a number of successful exits. Over his career, he’s been a CEO of publicly listed companies, involved in raising more than $100 million in funding and completed two successful IPO’s on the Australian stock exchange.\nLeigh is also an all-round good guy, and we are big fans of the work FireTech Connect is doing!\nConversation   In conversation with FireTech Connects Program Director Leigh Kelson\n   Highlights  coping with crisis, a end user experience of the the Covid-19 crisis 0:41; working in finance and hedge funds 3:41; how AI video translation tech can be applied to public fire / emergency communications to help the community understand vital information 8:28; a basic intro to AI / Machine Learning, Big Data, and Big Compute 18:55; and talks about what\u0026rsquo;s next for Videotranslator.ai 29:27;  Conclusion We hope you enjoyed the conversation, and stay tuned for more content!\nPlease connect with us on LinkedIn, YouTube or Facebook for any comments, questions, or just to keep up to date with the work we do!\nIf you are interested in trying out our technology, please try our platform or drop us an email at hello@videotranslator.ai.\n","permalink":"https://videotranslator.ai/news/video-translation-and-its-implications-for-firetech/","tags":["English"],"title":"Video Translation And Its Implications For FireTech"},{"categories":["Best Practices","Video","Transcription","Translation","Subtitles","Video Translation","Video Transcription","Enterprise","Accessibility","Languages","Visual Guides"],"contents":"Today we look at how to boost ROI or ROAS across your video production lifecycle, and how to make structural decisions which will pay off over a long time frame.\nROI or ROAS: Which One Should I Use? It\u0026rsquo;s actually a pretty messy question, but here are the basics.\nROI: Return on Investment Getting a definition is the starting point, and according to the smart folks at Investopia:\nReturn on Investment (ROI) is a performance measure used to evaluate the efficiency of an investment or compare the efficiency of a number of different investments. ROI tries to directly measure the amount of return on a particular investment, relative to the investment’s cost.\nWoo!\nROAS: Return on Ad Spend The good people at https://www.bigcommerce.com.au/ have taken a pretty good approach here:\nReturn On Advertising Spend, (ROAS), is a marketing metric that measures the efficacy of a digital advertising campaign ROAS helps online businesses evaluate which methods are working and how they can improve future advertising efforts.\nBigger Woo! But what does it mean? Essentially, Revenue/Cost or (Revenue-Cost)/Cost.\nNo biggie.\nSo ROI or ROAS? Simple rule of thumb, for total spend go with ROI, for campaign specific spend go with ROAS.\nIt can get a lot more complex. But this is good enough for right now.\nIf you want to know the additional complexity, do research on how to include:\n Partner/Vendor Costs Affiliate Commission Clicks/Impressions Costs  Simple Marketing Funnel vs Simple Business Funnel Okay - this is super basic, but important for the next bit. This is what a basic marketing funnel looks like, contrasted to a business funnel.\n    AI Internationalization: Marketing Funnel vs. Business Funnel    \u0026hellip; And It\u0026rsquo;s Implications For Video So what does it all mean?\n Video should be thought of through the prism of either ROI or ROAS. Thinking it terms of a generic \u0026lsquo;awareness\u0026rsquo; is not going to cut it. Unless if a for-fun project (and you should definitely make videos for fun too!), the big question is what is the expected return of the content spend?, followed up by how to measure this return accurately?  This is actually a pretty deep topic but the focus here is on using subtitling, or video transcription, to boost ROI - that is what you are hear to read about, isn't it!\nBoosting Your Return on Video Spend / Return on Content Spend So we wave our hands magically and assume you have a content spend plan and can measure its returns.\nOnce here, there are 3 ways to boost the return on video, in no particular order:\n Increase engagement frequency Increase engagement duration Increase audience size  Lets look at these in a bit of detail.\nIncrease Engagement Frequency for Video This is primarily applicable to video advertising: from short sub 5, 10, 20, 30 second videos up to maybe about 2 minutes.\nAs an example, these videos are rolled out in video campaign ads, and they play at the start, middle and end of your favourite YouTube videos.\nWithin YouTube there are three different types of ads; Bumper Ads, TrueView in-stream non-skippable ads and TrueView in-stream skippable ads.\nThese are also available in LinkedIn, Twitter and Instagram TV.\nHere, subtitles are best used as Open-Captions. Why? Engagement goes up heaps!\n    AI Internationalization: Boost Video Engagement With Open Captions    Research shows that 92% of consumers view videos with the sound off. So in social channels where video auto-plays muted, you really, really need open captions to engage with the viewer.\nIncrease Engagement Duration for Video So this is primarily for longer videos, 5 minutes to 10 minutes long which work on the principle of video SEO.\nThis means you expect your audience to search for specific terms in YouTube and your video comes up in the YouTube Search bar.\nThe first thing you can do is seed keywords into your title and description.\n    AI Internationalization: Seed YouTube specific keywords into the title and description    The second one, and this is a biggie - add subtitles in properly to get the coveted CC tag on your video!\n    AI Internationalization: Add subtitles using the \u0026#39;More Options\u0026#39; tab to boost video SEO!    To get the subtitles file for upload into YouTube, use the Download SRT button. For more advanced use-cases, use the Download VTT button.\nFor a more detailed description of the process, read this blog post or try the VideoTranslator App.\n    AI Internationalization: Download the SRT file for YouTube subtitles, or download the VTT file for more advanced uses cases.    The point is, with the SEO, people will find your content long after your initial campaign is complete.\nIncrease Audience Size Phew! This can be a lot of work. But we\u0026rsquo;re basically done!\nTo increase the audience size we are going after (1) accessibility, and (2) other languages.\nUse the Open Captions as described above to increase accessibility. Who is this aimed at?\nIncrease Audience Size - Accessibility People who are hearing impaired. Do you really care about deaf folk? After all how big of an audience are they?\nYou should care, because it\u0026rsquo;s the right thing to do.\nBut also, older people who may be is various stages of hearing loss - these people potentially have money to spare, so make it easy for them to spend it on your products!\nAdditionally - parents, especially parents of young babies.\nReally? Yes - lots of people use open captions when they have babies. See, if your child is asleep, you want to watch content without waking the baby up!\nThese parents get used to watching content with open captions as a result.\nGo on, be nice to parents everywhere\u0026hellip;\nIncrease Audience Size - Internationalization and Localization This is super useful if the majority of your non-English (as an example) audience is bilingual or multilingual.\nWhat you need to do here is add additional title, description and subtitles files into your video.\n    AI Internationalization: Add additional title, description and subtitle files for each language you want to target    How do you get these? Use the Action -\u0026gt; Translate and select your preferred language to translate to in the VideoTranslator App.\n    AI Internationalization: Pick the appropriate language and dialect    Conclusion We used the VideoTranslator to obtain (1) subtitles or transcripts, (2) an open-caption version, and (3) title, descriptions and subtitles in different languages, for our video content.\nThe key points are:\n  Boost engagement frequency for shorter video adverts, and engagement duration for longer bits of content using Video SEO tactics described above.\n  Distribute your content to a wider audience, and be nice to your parents!\n  Please connect with us on LinkedIn, YouTube or Facebook for any comments, questions, or just to keep up to date with the work we do!\nIf you are interested in trying out our technology, please try our platform or drop us an email at hello@videotranslator.ai.\n","permalink":"https://videotranslator.ai/news/ai-internationalization-how-subtitling-can-boost-roi/","tags":["English"],"title":"How Subtitling Can Boost ROI"},{"categories":["Retail","Video","Transcription","Translation","Accessibility","Languages"],"contents":"Today we look at AI localisation. Essentially, how to use AI to reach a broader market at scale.\nIts a really simple question. Does AI Localisation work at scale?\nAs always, the answer is yes and no, but mostly it depends on what you are trying to do.\nThe context is this: localisation project managers often burn themselves out by performing tons of routine operations every single day.\nSo the question becomes, how to use AI localisation at scale, and then, how to best use AI in localisation efforts at the process level?\nDoes AI Localisation Work At Scale? By at scale we mean if you need to translate content regularly and use translators. And we narrow our question to media translation specifically.\nGiven the sheer number of AI\u0026rsquo;s which can be used for translation, and the number of available languages, the answer is yes - AI does work at scale and its pretty good.\nWhat Challenges Does AI Localisation Face? Ok - not really.\nAssuming a standard Speech-To-Text AI (for the transcription), or a standard Text-To-Text AI (for the translation), this is how you want to think about it.\n    AI Localisation: As we move up information complexity the quality of AI translation gets worse    So (a) if the content is gossip, AI will probably be pretty good, (b) it'll be less good for say medical or legal content, (c) when it comes to quantum physics best of luck!\nThe higher the information complexity, the worse an AI will perform.\nThe reason is fairly simple. Complex information is inherently more valuable, and so less common on the Internet. Hence it is very hard to train an AI to work with the complex information.\nHow To Use AI On Your Projects With Confidence? Use AI to assist your people, not replace your people.\n    AI Localisation: A productivity tool, not a human replacement    The workflow you should be thinking about is:\n Upload your content and transcribe: Use AI to do the first pass transcription and a human subject matter expert to post-edit. Upload your content and translate: Use AI to do the first pass translation and a human subject matter expert to post-edit.  How Does VideoTranslator Simplify The Post-Editing Process?     AI Localisation: Tools to make your post-editing quicker!    So this is what you want to do:\n Pop out the video to PiP so you can easily scroll as you make edits. Try to make nice sentences - no one want to read a single word fragment. The way to think about Open Captions is like so - you want nice 4/5 word sentences which are easy to read, not single word like \u0026ldquo;on\u0026rdquo; as shown in the image. Time fragments should be a minimum of 1 second long, ideally 1.5 seconds or so, to make it easy to read quickly.  The number of edits you make is called the edit distance, or edit delta, and it refers to the number of changes post AI before a finished product is ready.\nConclusion We use the VideoTranslator to add transcripts to our video content.\nThe key points are:\n  Use the AI as a first pass before your subject matter expert to increase productivity.\n  AI's are best used to simplify and speed up workflow. They should not primarily be used to replace staff.\n  AI will fail in localisation without the use of subject matter experts, especially as your content moves up information complexity.\n  Please connect with us on LinkedIn, YouTube or Facebook for any comments, questions, or just to keep up to date with the work we do!\nIf you are interested in trying out our technology, please try our platform or drop us an email at hello@videotranslator.ai.\n","permalink":"https://videotranslator.ai/news/ai-localisation-help-me-help-you/","tags":["English"],"title":"AI Localisation: Help Me Help You"},{"categories":["Retail","Video","Transcription","Translation","Accessibility","Languages"],"contents":"This post is dedicated to simple rules to maximise your SEO (Search Engine Optimisation) impact with video content.\nThere are 4 things you need to do to maximise your video content\u0026rsquo;s SEO impact. They are, title, description, keywords and the transcript, we will look at each one of these in detail.\nWhy Do Video SEO? From this DeepCrawl article, search engines cannot index video content. This is because search engines can only index text content.\nEdit: Stop!\nAlso have a look at this newer article by the folks at Amplitude Agency about how search engines work for a high level overview of what search engines care about.\nSo we literally need to tell the search engine what our video content is about!\nThis is why we need to distribute video content optimised for SEO.\nHow To Optimise A Video Title? You have two goals in your video title - target keywords and maximising click through (CTR).\n Make sure your include your target keyword ONCE in the title. Create a compelling title!  Don't use a click bait title. YouTube will penalise you if you have low retention numbers!\nBonus Tip: Use eye-catching thumbnails with at least one human in them!\nHow To Optimise A Video Description?     Video SEO: YouTube displays the first 125 characters of your description in the search results.    Your first 125 characters should drive click through to your video!\nIn the above image you can see that the title, description and thumbnail are very important to CTR numbers.\nHow To Optimise Keywords? Ok - without getting into too much detail. The easiest way to work out keywords is to do the grunt work!\nWe can do this in Google, where you start typing the words you care about, and the auto-fill kicks in:\n    Video SEO: Google displays some suggestions    And you do this for YouTube also:\n    Video SEO: YouTube offers different suggestions    In both the above examples, we type in \u0026quot;amazing\u0026quot; as our first word, and then go \u0026quot;a\u0026quot;, \u0026quot;b\u0026quot;, \u0026quot;c\u0026quot; etc etc.\nWhy are the suggestions offered by Google different from the suggestions offered by YouTube?\nBecause people search for different things on Google vs. YouTube! This means depending on where you are putting out your content, optimising for different keywords is super important.\nHow To Optimise The Transcript There are two ways to optimise your transcript. We used QuickTranscribe to get the transcription.\n We use the VideoTranslator\u0026rsquo;s SRT download option to get the *.srt file which we use for subtitles.      Video SEO: Add the SRT downloaded from VideoTranslator to your YouTube video     We used the VideoTranslator\u0026rsquo;s Auto-Overlay feature to create a Open Captions version of our video. The below image is from Matija Squire, a good friend of VideoTranslator!      Video SEO: Use the Open Captions version as above for accessibility    When would we use Open-Captions?  We use open captions in social media channels where the video auto-plays muted, such as LinkedIn, Twitter or Facebook. We use open captions where accessibility is a concern.  Conclusion We use the VideoTranslator to add transcripts to our video content.\nThis helps us with Video SEO, and is best used with optimised titles, descriptions, keywords and a nice thumbnail!\nPlease connect with us on LinkedIn, YouTube or Facebook for any comments, questions, or just to keep up to date with the work we do!\nIf you are interested in trying out our technology, please try our platform or drop us an email at hello@videotranslator.ai.\n","permalink":"https://videotranslator.ai/news/video-seo-keywords-titles-descriptions-and-the-transcript/","tags":["English"],"title":"Video SEO: Keywords, Titles, Descriptions And The Transcript"},{"categories":["Retail","Video","Transcription","Translation","Accessibility","Languages"],"contents":"There are a large number of reasons as to why people create content. Here is the one thing all content creators have in common.\nThey need to market their content. And step one is thinking about Search Engine Optimisation (SEO).\nThis blog post covers what you need to know about making video content indexable, and hence searchable.\nRead on to understand what you need to do to make your video SEO friendly!\nDoes Video Help With SEO? Yes - video helps with SEO in two specific ways.\nVideo Content Signals High Value Content A search engine, or rather the web crawler associated with a search engine, is looking for evidence that your website has quality content.\nVideo is explicit evidence of content, and as part of a media mix on site, it helps send signals to search engines that your page or site contains rich media relevant to search requests.\nVideo Drives Text With Keywords, Titles, Descriptions And The Transcript A search engine\u0026rsquo;s web crawler cannot understand, or parse, video content. That is, a search engine has no idea what your video is about.\nWeb crawlers only understand text. The easiest way to improve your video SEO is to add text to your video content.\nWe can do this by, optimising keyword labels, site maps, file names, descriptions, and most importantly, transcripts.\n     How To Do Video SEO Right: Be sure to add keywords, titles, descriptions and, most importantly, the transcript!    The idea here is to add lots of text with your video which a search engine can understand. This makes your video content SEO friendly.\nVideo SEO Tips To Increase Your Search Engine Rankings Keeping the above in mind, these are some general tips to increase your search engine rankings.\n Know your audience Do keyword research Add keyword tags Optimise your video title Optimise your video description Optimise your video thumbnail Add a transcript Make it accessible  If you do the above with each video you post, irrespective of channel, you should start to see improvements in organic rankings due to the bump from video SEO.\nConclusion We use the VideoTranslator to add transcripts to our video content.\nWe are going to do a set of future blog posts covering the below. Stay tuned!\n How To Implement Captions/Subtitles Properly On Social Media How To Implement Accessibility Properly In Video How To Implement Video SEO Friendly Changes To Your Website  Please connect with us on LinkedIn, YouTube or Facebook for any comments, questions, or just to keep up to date with the work we do!\nIf you are interested in trying out our technology, please try our platform or drop us an email at hello@videotranslator.ai.\n","permalink":"https://videotranslator.ai/news/how-to-do-video-seo-right/","tags":["English"],"title":"How To Do Video SEO Right"},{"categories":["Retail","Video","Transcription","Translation","Visual Guides","Languages"],"contents":"The QuickTranscribe feature is our most used feature in the video transcription and translation process.\nOur easy how-to guide on using the Quick Transcribe feature. For more information on Quick Transcribe visit our written guide here.\n  How to quickly transcribe your video\n   We are very grateful for your support!\nPlease connect with us on LinkedIn, YouTube or Facebook for any comments, questions, or just to keep up to date with the work we do!\nIf you are interested in trying out our technology, please try our platform or drop us an email at hello@videotranslator.ai.\n","permalink":"https://videotranslator.ai/news/video-series-how-to-quickly-transcribe-your-video/","tags":["English"],"title":"Video Series: How to Quickly Transcribe Your Video"},{"categories":["Retail","Video","Transcription","Translation","Visual Guides","Languages"],"contents":"Having the ability to translate your video into a number of different languages and dialects puts your business a step ahead of the rest in means of reaching a larger audience and in turn, customers.\nBut getting your content translated and transcribed into another language seems expensive and time consuming, right?\nGood news, friend. You\u0026rsquo;re wrong!\nDubbing and/or subtitling your video is a quick and easy process if you\u0026rsquo;re using our app and we hope that\u0026rsquo;s why you\u0026rsquo;re here\u0026hellip; to find out how to do it. So without further ado, read on to learn how to translate your video and start reaching millions more people worldwide.\nHow To Transcribe And Translate Your First Video First off, we\u0026rsquo;ve logged into our videotranslator.ai account; if you don\u0026rsquo;t have an account yet, sign up here for a free trial. Once logged in, hit Quick Transcribe and follow the prompts to upload your video and to select the language and dialect that your video is originally in.\nQuickTranscribe: Click QuickTranscribe To Upload And Transcribe Your Video   Translating Your First Video: QuickTranscribe (Upload \u0026#43; Transcribe)\n   Post-Editing: Fix Up The AI Output To Maximise Conversions  Once the video has loaded, it\u0026rsquo;s time to edit the captions. Because people don't always speak the way they write, the AI can sometimes miss capitalisation, commas and full stops as well as misuse certain words; use the Picture-in-Picture popup to help you edit the timing and captions of the video in its original language.    Translating Your First Video: Edit Captions\n    Remember make time blocks a minimum of 1 second long, ideally 1.5 seconds to make it easier to read.  AI Translation: Use The AI To Translate Your Video  When you\u0026rsquo;re happy with the captions and timing, scroll up to Translate and choose the language you\u0026rsquo;d like your video to be translated into. To do this, select Translate from the Action menu and then select 'Automatic' for the AI translation as well as setting the language of your choice.    Translating Your First Video: QuickTranscribe \u0026#43; Transcribe \u0026#43; Translate\n    And that\u0026rsquo;s it! You\u0026rsquo;ve translated your first video! See below for the full video and step-by-step guide.    Translating Your First Video: Full Flow\n   Conclusion We are very grateful for your support!\nPlease connect with us on LinkedIn, YouTube or Facebook for any comments, questions, or just to keep up to date with the work we do!\nIf you are interested in trying out our technology, please try our platform or drop us an email at hello@videotranslator.ai.\n","permalink":"https://videotranslator.ai/news/a-step-by-step-guide-to-translating-your-first-video/","tags":["English","Thai"],"title":"A Step by Step Guide to Translating Your First Video"},{"categories":["Video Translation","Enterprise","Engineering"],"contents":"I\u0026rsquo;m not going to sugarcoat it, this pandemic sucks big time and if you\u0026rsquo;re anything like me, you\u0026rsquo;re overwhelmed with the horrifying statistics and negative news that surrounds this whole thing.\nSo we\u0026rsquo;re focusing on the good news today. As Fred Rogers famously said, \u0026ldquo;When I was a boy and I would see scary things in the news, my mother would say to me, \u0026lsquo;Look for the helpers. You will always find people who are helping.'\u0026rdquo; And he\u0026rsquo;s right, throughout all this devastation and chaos, there are people helping and trying to make the situation better in any way that they can.\n1. Peterborough City Council Procures Translation Videos to Keep Communities Safe in Coronavirus Pandemic Both Peterborough City and Cambridgeshire County Councils in the UK have released videos in almost 30 languages (with more to come) to help everyone in the community understand that staying home means saving lives.\n\u0026quot;\u0026lsquo;Working with our diverse communities to make sure they understand the very important \u0026lsquo;stay at home\u0026rsquo; message is a critical part of our work at the moment,\u0026rsquo; said Superintendent Laura Hunt, \u0026lsquo;\u0026hellip;our policing style is built on consent and having a positive relationship with the community\u0026hellip; so the translation videos produced by the city and county council will prove very useful for police officers when they come across people who struggle to understand the messages in English.'\u0026quot;\nRead the full story here\n2. College Student Makes Masks for the Deaf \u0026amp; Hard of Hearing     Image courtesy of LEX18 Lexington    Ashley Lawrence, a University student studying education for the deaf and hard of hearing has put all her newly found spare time to good use. The 21-year-old, along with her mother, is making face masks that allow the deaf and hard of hearing to still be able to use facial expressions when speaking ASL (American Sign Language). Being able to see and use facial expressions when communicating is extremely important in ASL and an extremely difficult thing to do if half of your face is covered due to a mask.\nSo, using her and her mum\u0026rsquo;s craftiness to good use, they have created masks with plastic windows that allow the users mouth to be seen.\n\u0026quot;\u0026lsquo;I felt like there was a huge population that was being looked over,\u0026quot; Lawrence said. \u0026lsquo;We\u0026rsquo;re all panicking right now and so a lot of people are just not being thought of. So, I felt like it was very important that, even at a time like this, people need to have that communication.'\u0026quot;\nRead the full story here\n3. How AI Can Determine Which Coronavirus Patients Require Hospitalisation A leading healthcare company in the US, Jvion is developing an AI project which is undertaking data to better understand how patients will or won\u0026rsquo;t react to treatment for COVID-19. The aim is to be able to determine which patients will need to be hospitalized and who can stay at home to safely recover. This will in turn could reduce the capacity of patients in hospitals and give the overworked nurses and doctors a little relief.\n\u0026ldquo;Jvion’s approach helps [to] determine individual risk levels while using minimal or no clinical data and using limited patient-level information that doesn’t require special medical equipment. This will make it possible to leverage the AI to study large populations and determine high-risk patients without flooding medical centers.\u0026quot;\nRead the full story here\n4. Student\u0026rsquo;s COVID-19 Explainer Video Becomes an Educational Tool in Thailand     Jessie Kanacharoen\u0026#39;s small video for family and friends went viral    Another student made our list, doing incredible work this time to give accurate information to those in her home country of Thailand. Jessie Kanacharoen first created a YouTube video to inform her friends and family about the risks of COVID-19 and to encourage them to stay at home as much as possible.\nJessie was aware that a lot of people she knew in Thailand were not being given the correct information regarding the virus and so she produced a video with Thai subtitles, to make it easy for them to understand.\n\u0026ldquo;In just seven minutes, \u0026ldquo;The Real Deal on Covid-19\u0026rdquo; explains, in simple language, many of the most pressing questions people have about the ongoing coronavirus outbreak, including what the pandemic designation means, how the disease is transmitted, what its symptoms are, how it affects the elderly and immunocompromised, what it means to be an asymptomatic carrier, and the effectiveness of social distancing techniques at slowing the spread.\u0026quot;\nThe video was a viral hit and was soon shared by the Thai Medical Society, it was shown on Thai television and was translated into local Thai dialects so that the information was even more readily available for those who need it.\nView the video here\nRead the full story here\n5. Global Cleveland Working to Provide Language Access During COVID-19 Pandemic Global Cleveland has been working tirelessly with translators to ensure that the city\u0026rsquo;s lifesaving approaches to combating the Coronavirus are being communicated correctly to everyone, no matter their level of ability in understanding English.\nGlobal Cleveland President, Joe Cimperman believes this is a vital process, (\u0026quot;\u0026lsquo;We immediately started translating the governor\u0026rsquo;s top five points every day into six, then eight and 15, now to 30 languages, he said, \u0026lsquo;We\u0026rsquo;re still one of the larger producers of the Spanish language translation and so we\u0026rsquo;re going to continue doing that. We\u0026rsquo;re also translating into Farsi and Arabic into Hindi and translated into Slovak, into Lithuanian, German and French.\u0026quot;)\nRead the full story here\nPlease connect with us on LinkedIn, YouTube or Facebook for any comments, questions, or just to keep up to date with the work we do!\nWe are very grateful for your support!\nIf you haven’t yet and are interested in trying out our technology, please try our platform, or drop us an email at hello@videotranslator.ai.\n","permalink":"https://videotranslator.ai/news/a-little-positivity/","tags":["English"],"title":"A Little Positivity: To Brighten Your Day, Week And Month!"},{"categories":["Video Translation","Video","Best Practices","Transcription","Translation","Accessibility","Artificial Intelligence"],"contents":"Are you a content creator? Or Are you a court reporter looking for an easy way to caption lots of content? This blog post might be for you.\nHaving captions is very useful these days. Its really good for engagement, and its also really good for accessibility - specifically hearing impaired folk.\nHowever, and there is no getting around this, it is painful to do.\nManual audio or video transcription takes ages. For a transcription professional it takes about 4x - so for a 15 minute video it takes 1 hour to transcribe.\nBut this is only really true when the complexity of the content is low or the transcriber has a high degree of familiarity with the content.\nWhat Is The Best Subtitling Software? It depends. Sorry. There is no simple answer.\nActually - its video translator - our product is the best subtitling software! Ok it probably isn\u0026rsquo;t, but it might be :)\nThe answer depends on a number of factors. Lets talk about them one by one.\nBudget - Free AI Transcription Software Free software exists such as the Google AI suite but you would not be here if that worked for you. Basically the answer varies with how much money you are willing to spend.\nThe bottom line - a hybrid solution of AI with human post-editing is rapidly becoming the preferred choice - but who does the post editing, how secure is it, and what kind of accuracy can you expect?\nBtw - here is a blog post about the kind of security concerns with online transcription.\nLike I said - budget.\nSo your options are:\n (1) manually transcribing with subject matter expert (really good + really expensive) (2) AI transcribing with human input (cheap but uncertain quality) (3) AI transcribing + your own people post-editing (cheap + really good but your own staff time)  Video translator (thats us!) is a option (3) play.\nWe think using AI + trusted staff or contractors is a really nice mix of both worlds. That way you get to bring your own subject matter experts, and use our tech in a cheap and scalable manner.\nAccuracy In AI Transcription - How Good Is AI Transcription Really? Its pretty good. The thing to understand is that as your content moves up in information complexity, the AI gets worse.\nPractically this means that if your content is about gossip - no worries. But given you are probably trying to sell stuff with content marketing this means that important stuff may be incorrect.\nSecond point. Generally subtitling software uses generic AI. At video translator we use a proprietary language-dialect mapping system to increase accuracy. We have several English, Spanish and Arabic dialects to help out.\n English dialect samples here Arabic dialect samples here  AI Accuracy And How To Think About What You Are Paying For\u0026hellip; We wrote an entire post about it - check it out for more details.\n     AI Transcription, Translation And Dubbing: How To Think About Accuracy    Time - How Long Does AI Transcription Take? With the majority of online transcription and online translation providers turn around time is a factor. Some are very quick.\nBut what are the chances that someone turning around on a deadline will aim for quality?\nUnlikely.\nShould you internalize with our AI tools? That is a hard question to answer, but if your value proposition is directly linked to your bottom line - yeah you probably should.\nVideo Translator is real time AI transcription, real time AI translation and real time AI dubbing. You do the work, when you want to.\nWhat does real time mean - practically seconds to minutes. That is if its a 2 GB file it'll take longer than if its a 20 mb file.\nShort files are the quickest (seconds). That being said, you probably want to use short videos because traction numbers show they work better.\n For YouTube ~10 minutes works best For LinkedIn average time a video is watched is 7 seconds  Different stuff works differently. Optimize for your preferred social channels.\nSEO - How To Optimize For SEO In Video Some simple rules. Use titles, descriptions, tags and other metadata options - very important!\nThis is the secret to why people use video translator - easily translating titles and descriptions gives you multi lingual SEO.\nAn ability to market to the billions of people who don't speak English!\nWant to market to China! What about India! The Middle East? Grow Your Audience\nUsing WebVtt For SEO Is this really a factor in deciding what subtitling software to use? It is the MOST IMPORTANT FACTOR EVAH!\nDepending on your platform you may really really want to use WebVTT. Read more here but a simple way to think about it is so.\nWebVTT allows search engines to understand what your video is all about. It makes your content indexable, and therefore search worth!\nBoom!\nFrom the CSS-Tricks website here are two images.\n    What Is The Best Subtitling Software Available: What a WebVtt file looks like        What Is The Best Subtitling Software Available: How to include w WebVtt file on your website    Its all about search.\nALL. ABOUT. SEARCH.\nConclusion We really hope you found this blog post useful, and are able to increase your target audience using our technology.\nPlease connect with us on LinkedIn, YouTube or Facebook for any comments, questions, or just to keep up to date with the work we do!\nWe are very grateful for your support!\nIf you are interested in trying out our technology, please try our platform or drop us an email at hello@videotranslator.ai.\n","permalink":"https://videotranslator.ai/news/what-is-the-best-subtitling-software-available/","tags":["English"],"title":"What Is The Best Subtitling Software Available?"},{"categories":["Video Translation","Video","Best Practices","Transcription","Translation","Accessibility","Artificial Intelligence"],"contents":"You are a content creator who uses AI.\nBut how safe is the AI you use, whether for transcription, translation or dubbing. Also some tips on how to use AI better in your journey into expanding your market.\nThere was a great article on this recently at How-To-Geek.\nOk - so why do you use AI? As a content creator you care about engagement. AI Transcription combined with Open Captions is fantastic for engagement.\nPractically what does this mean and how can you protect yourself better?\nAI Transcription Models There are three basic models for AI transcription.\n Automated - Google, IBM, MS, Amazon; basically all the tech majors plus a number of smalled startups like Otter Manual - Rev, Upwork, Fivver etc Hybrid - These use a combination of both AI and Human. video translator falls into this category.  In all of these, the idea is you use an AI translator app or an AI voice transcriber and translator app to add (a) open captions to your video for engagement, or (b) translate your video to reach a wider audience.\nThe Challenge     How Safe Is AI Transcription: AI, human or hybrid - which model is best?    Essentially Automated is not that good, and Human carries privacy and security risks.\nThis story by GigaOm and this story by cyber security journalist Brian Krebs highlight the risks involved.\nIn the first story freelance workers in Pakistan did not get paid and so started messing with the transcripts, and in the second a number of medical records were leaked. Note: this was sourced from Matt Hughes story in How-To-Geek, you should read it.\nSo what can you do?\nThe VideoTranslator Model We think that hybrid is best, and ideally you should do it yourself. Why?\nThe simple answer is this - as we move up information complexity AI transcription gets worse.\nMore valuable information, such as your value proposition is by definition scarce on the Internet. Hence the best person to get it right is the subject matter expert, i.e. you.\nWe recommend you use your own people to do high value tasks.\nUse AI as a tool to enhance productivity, and not as a cost saving only!\nRead More About The Challenges With Using AI      How AI Transcription Fails And What To Do About It    Conclusion We really hope you found this blog post useful, and are able to increase your target audience using our technology.\nPlease connect with us on LinkedIn, YouTube or Facebook for any comments, questions, or just to keep up to date with the work we do!\nWe are very grateful for your support!\nIf you are interested in trying out our technology, please try our platform or drop us an email at hello@videotranslator.ai.\n","permalink":"https://videotranslator.ai/news/how-safe-is-ai-transcription-what-you-need-to-know/","tags":["English"],"title":"How Safe Is AI Transcription: What You Need To Know"},{"categories":["Video Translation","Video","Best Practices","Transcription","Translation","Accessibility","Artificial Intelligence","Visual Guides","Case Study"],"contents":"Business today relies on content creation. How do you expand your market? We show you how to add open captions for accessibility wins, and translate your video content into Tagalog and Chinese to expand your target client base!\nMatija Squire is a LinkedIn coach, all round nice person plus a good friend. And she is doing something really cool!\nWe all know Covid-19 has distrupted all our lives. Some of us are lucky enough to be able to earn an income by working from home online. This is Matija doing something that helps people who now need to make money from home!\n\nIn this blog post we talk about how to do this with your video content, and for fun we\u0026rsquo;ll translate this video into Filipino/Tagalog and Chinese!\nIf you like Matija\u0026rsquo;s work be sure to follow her on linkedIn! We are big fans!\nCan You Translate Your Video In To Filipino And Chinese Languages? The first thing is to check if you have Filipino and Chinese in your account. Go to the VideoTranslator App and then click on Finances in the dropdown.\n    Translate Your English Video Into Filipino And Chinese: Add Filipino and Chinese to your avilable languages    Then in Language Settings make sure you have the Filipino and Chinese. We will be translating from English -\u0026gt; Filipino and English -\u0026gt; Chinese today. You can use the same process to go from Filipino video to Chinese video etc.\n    Translate Your English Video Into Filipino And Chinese: Add Filipino and Chinese to your avilable languages    Do not use Tagalog, this is for special situations where you want your own translator. Contact hello@videotranslator.ai for more information.\nTranscribe Video To English SubTitles Online Ok - so what we are trying to do transcribe this English video. For this we use the VideoTranslator desktop app.\nSimply it is a three step process which we will quickly cover.\nFirst we click the QuickTranscribe button and upload our video. Here we choose Australian English as that is how Matija speaks, but if it was a Filipino video or Mandarin video we would choose those languages.\n    Translate Your English Video Into Filipino And Chinese: Select the language and dialect    Then we make edits to the captions. This is called Post-Editing. Because AI is generally not perfect, this process makes our captions better.\n    Translate Your English Video Into Filipino And Chinese: Do Post-Editing and then we used the Auto-Overlay    Also shown above was the Auto-Overlay where we bake-in the captions into the video. Note you are looking at images of the Video Translator desktop app.\nNow Lets Translate This English Video Into Filipino Or Tagalog How do we translate the English video into Filipino? Or if it was the other way around, how would we translate a Filipino video into English?\nIt is basically the same process. We take out original language captions / subtitles, basically the real time editable .srt file, and translate it into the target language, in this case Filipino or Tagalog.\n    Translate Your English Video Into Filipino And Chinese: Action -\u0026gt; Translate and select the asset    Click Action -\u0026gt; Translate as shown above, and we get a familar output. You should also do Post-Editing of the Filipino output, and below we have added our familiar Auto-Overlay.\n  Translate Your English Video Into Filipino And Chinese: Auto-Overlay with Filipino Open Captions\n   Translate Your English Video Into Mandarin We do the exact same thing from our English video into Mandarin. Make sure you select the correct dialect as Simplified Chinese as shown below.\n    Translate Your English Video Into Filipino And Chinese: Action -\u0026gt; Translate and in this case we pick Chinese and dialect Simplified Chinese    Which gives us the below video!\n  Translate Your English Video Into Filipino And Chinese: Auto-Overlay with Chinese Open Captions\n   Conclusion We really hope you found this blog post useful, and are able to increase your target audience using our technology.\nPlease connect with us on LinkedIn or YouTube for any comments, questions, or just to keep up to date with the work we do!\nWe are very grateful for your support!\nIf you are interested in trying out our technology, please try our platform or drop us an email at hello@videotranslator.ai.\n","permalink":"https://videotranslator.ai/news/translate-your-english-video-to-filipino-and-chinese/","tags":["English","Filipino","Chinese"],"title":"Translate Your English Video Into Filipino And Chinese"},{"categories":["Video Translation","Video","Best Practices","Transcription","Translation","Accessibility","Artificial Intelligence","Visual Guides"],"contents":"The basic steps to translate a YouTube video are:\n Download the video to your computer. Upload the video into an AI transcription service. Get the transcript in an .srt file. Translate the transcript using an AI translation service. Embed the translation into your video.  You should only translate videos that you expect a good Return On Investment from - so you have a good feeling this video will work in a different language.\nFirst, and this goes without saying, please translate your own YouTube videos. Why? Because of copyright. If its not your property, please do not steal from other content creators. Fair use is of couse good, but this blog post is for content creators who are looking to translate their own videos in YouTube.\nIn this blog post we cover how to download a video from YouTube, then we add a transcript, and then we translate the video. This is done so you can try this at home yourself.\nPick The Video (From YouTube) That You Want To Translate First we need to find a video to download. We will use a video from the VideoTranslator YouTube Channel, specifically this video shown below.\n  Fighting The Coronavirus And E-Coli With Machine Learning\n   Note: This video does not have any speech - the idea is we will add some as part of this tutuorial.\nDownload The Video From YouTube Ok - now we have a video, we can download it. Obviously we already have the files, as its our own channel, but this step is shown so you can follow along in this tutorial.\nGo to this website - https://ytmp3.cc. We like it because it is nice and simple but be warned it is spammy! If you Google around, there are many other options too.\n    How To Translate YouTube Videos And Dominate SEO: Download the video from YouTube    Download the video and now you have the asset.\nUpload The Video Into An AI Transcription Platform We are using video translator for this. Create a new item and upload the video as below.\n    How To Translate YouTube Videos And Dominate SEO: Upload the video to VideoTranslator    Add A Transcript To The Video Or Export The Transcript From Youtube As this video did not have any narration we did not use the AI transciber. Instead we manually added in the captions into an *.srt file. This is shown below.\n    How To Translate YouTube Videos And Dominate SEO: Add a transcript using an AI or do so manually    You can see we are simply typing in the text and it can be seen on the video - this is visible on the last line \u0026quot;As before the scanners...\u0026quot;.\nOnce complete, you can download the *.srt, which is provided here so you can see what it looks like.\nWith the subtitles file a *.srt we can upload this into YouTube as shown below and the video will now have subtitles.\n    How To Translate YouTube Videos And Dominate SEO: Add the subtitles    Note: If you used a video with narration, after the AI transcription process please click the \u0026quot;Download SRT\u0026quot; button to export the transcript from the Youtube video.\nTranslate The YouTube Video Into Hindi Now we want to translate the video into Hindi. How can we do this? Click Action -\u0026gt; Translate and select Hindi\n    How To Translate YouTube Videos And Dominate SEO: Translate the video into Hindi    Here we are translating the subtitles file using the AI. Once the AI has finished it will look like below.\n    How To Translate YouTube Videos And Dominate SEO: Subtitle is translated into Hindi    Hard Code The Hindi Subtitles Into The Finished Asset Using Auto-Overlay Click Action -\u0026gt; Auto-Overlay and we chose black text with a yellow background for the below video.\n  Fighting The Coronavirus And E-Coli With Machine Learning\n   Conclusion To really get the value of SEO, you should make sure that Titles, Description, Open Captions and Closed Captions are all in place! If you are using social channels outside YouTubr you may also want to use WebVTT properly.\nBest of luck and I am sure you will do amazing! Connect with us on LinkedIn, or if you are interested in trying out our technology, please try our platform or drop us an email at hello@videotranslator.ai.\n","permalink":"https://videotranslator.ai/news/how-to-translate-youtube-videos-and-dominate-seo/","tags":["English","Hindi"],"title":"How To Translate YouTube Videos And Dominate SEO"},{"categories":["Video Translator","Enterprise","Weekly Roundup","Accessibility","Languages"],"contents":"It was International Women\u0026rsquo;s Day this past Sunday 8 March and in honour of the day we\u0026rsquo;re looking at some incredible females who are doing all they can for their native languages.\n  The Girls and Women Revitalising Canada\u0026#39;s Indigenous Languages\n   Celebrating Indigenous Women Who Are Reclaiming and Revitalising Their Languages     Image courtesy of Marion Konwanénhon Delaronde and Karihwiióstha Callie Montour    In light of International Women\u0026rsquo;s Day which was this past Sunday, March 8, CBC News in Canada put together an article celebrating a number of Indigenous women and their plight to preserve and revitalise their traditional languages.\n\u0026ldquo;Indigenous women are often regarded as traditional keepers of language and culture. CBC News speaks with seven women who are making changes, both big and small, in their lives, communities, and nations when it comes to the reclamation, revitalization, and preservation of Indigenous languages.\u0026quot;\n    Image courtesy of Belinda Daniels    These inspiring women are coming at their language and culture from all walks of life, but have one main goal in mind; to ensure their culture, and in turn languages are celebrated, recognised and continued on for generations to come.\nRead more here\nLake Research Video Translate into Ojibway to Help Promote Language As Well As Science     Image courtesy of Emma Bruyere    A year 9 student in Ontario, Canada has narrated an environmental science video into Ojibway, its creators are hoping this will help to create more interest in the language amongst young people.\nFunded by the Canadian Heritage Fund, the Ojibway narrated video details the work of the International Institute for Sustainable Developments (IISD) and their research into \u0026ldquo;mercury contamination in freshwater ecosystems.\u0026quot;\nPauline Gerrard, deputy director of IISD believes that producing videos in native, local languages will help to promote the culture and language of Canada\u0026rsquo;s First Nation\u0026rsquo;s people.\nWatch the video here\nEmma Bruyere, the voice behind the narration is from the Couchiching First Nation is \u0026ldquo;happy to know that there are efforts being made to preserve the Ojibway language.\u0026quot;\nRead more here\nConclusion Please connect with us on LinkedIn, YouTube or Facebook for any comments, questions, or just to keep up to date with the work we do!\nWe are very grateful for your support!\nIf you are interested in trying out our technology, please try our platform or drop us an email at hello@videotranslator.ai.\n","permalink":"https://videotranslator.ai/news/the-girls-and-women-revitalising-canadas-indigenous-languages/","tags":["English"],"title":"The Girls and Women Revitalising Canada's Indigenous Languages"},{"categories":["Video Translation","Video","Best Practices","Transcription","Translation","Accessibility","Artificial Intelligence","Visual Guides"],"contents":"One very common use case of video translator is as a Chinese clipping app. What is a Chinese clipping app?\nThis term is used by content creators to mean how to translate a video from English to Chinese, and they generally mean a short video for various social media channels.\nIn this blog post we are going to look at how to translate a small video from English to Mandarin (Simplified Chinese).\n First we look at how video SEO works with WebVTT files Then we transcribe and translate a small video into Chinese Lastly we download two assets, (a) a mp4 with embedded, or Open Captions, and (b) a WebVTT file for our video SEO  Why Use A Chinese Clipping App/Chinese Video Maker App? China is a very large market for online video. So if you are spending money on video marketing, it makes sense to translate this into Chinese to reach the Chinese market.\nThis makes the most sense for e-commerce type plays, people selling online digital goods, or people building an audience in China.\nHow To Optimise Your Video SEO with WebVTT? So video translator can be considered a chinese clipping app, or realistically an any language clipping app. Why are we doing this?\nThe short answer is SEO. It all starts with the humble *.vtt, or Web Video Text Tracks (WebVTT) format file. From the fantastic Mozilla Developer website, we see the below.\n    Clipping Chinese App: Web Video Text Tracks Format (WebVTT) is where it is at!    What are we looking at? The HTML5 video tag is how video content is displayed on every web page.\nThe key thing to look at is the track tag, this is how video transcripts (the vtt files) are embedded into websites.\nFar more importantly, this is how search engines understand what it inside video's, and without it your video SEO is ... not reliably happening.\nSo we want to use a Chinese clipping app to translate our video so we can reach the large Chinese market. It all starts with the humble WebVTT file.\nAre You Looking To Translate Your Video Into Filipino Instead? To read a case study where we translate video into Filipino and Chinese - with samples - click here.\n     Translate Your English Video Into Filipino And Chinese: How to translate your video into Filipino and Mandarin Chinese with AI    Otherwise read on about clipping!\nHow To Translate Your Video To Chinese? First we transcribe with AI, then we translate with AI!\n(1) Click QuickTranscribe, upload your video and select your preferred language and dialect. We used Australian English below.\n    Clipping Chinese App: Click quick transcribe and pick your preferred language and dialect!    Its super important that you check your captions, and add commas and full-stops in the English captions. Otherwise the next AI will not work!\n(2) Click Translate then pick Chinese and Simplified Chinese as the dialect.\n    Clipping Chinese App: Click quick transcribe and pick your preferred language and dialect!    (3) Use Auto Overlay to add the Open Captions into your video! Then download and publish to your social channels.\n    Clipping Chinese App: Add the Open Captions and publish to your social channels!    How Do I Get The WebVTT File For Proper SEO? Now, depending on where you deploy, the specific channel may or may not have the ability to handle WebVTT, in that it may need SRT or just the Open Captions.\nOn your own website though this is something that is easy to do. You really want this so you can pick up the multilingual SEO. Hardly anyone does this, so it is pretty easy to do!\n    Clipping Chinese App: In the QuickTranscribe generated item, look for the SRT and VTT buttons to download the assets    Make sure to follow the MDN guide and use it properly. Your SEO will then work wonders!\nConclusion Super important points to remember.\n(1) AI gets worse as you move up information complexity. So if your video is about complicated content, get a Chinese friend to do post-editing to make sure the AI does not do anything silly.\n(2) Give the Free-Trial a go!\nIf you are interested in trying out our technology, please try our platform or drop us an email at hello@videotranslator.ai.\nPlease connect with us on LinkedIn, YouTube or Facebook for any comments, questions, or just to keep up to date with the work we do!\n","permalink":"https://videotranslator.ai/news/clipping-chinese-app-how-to-translate-video-into-mandarin-chinese-with-ai/","tags":["English","Chinese"],"title":"Clipping Chinese App: How To Translate Video Into Mandarin Chinese With AI"},{"categories":["Video Translation","Enterprise","Weekly Roundup","Accessibility","Artificial Intelligence"],"contents":"When it comes to combating superbugs and viruses, the human raced needs all the help it can get. Artificial Intelligence is being implemented to find treatments to fight bacteria that was formally resistant to all forms of antibiotics. China is also using AI to quickly determine if a person is showing symptoms of the coronavirus, which could be a great win against getting a handle on the respiratory disease.\n  Fighting The Coronavirus And E-Coli With Machine Learning\n   How Artificial Intelligence Outsmarted the Superbugs     E. coli was the focus bacteria in the study    A team of MIT and Harvard researchers have put together a machine learning neural network \u0026ldquo;and trained it to spot molecules that inhibit the growth of the Escherichia coli bacterium using a dataset of 2,335 molecules for which the antibacterial activity was known – including a library of 300 existing approved antibiotics and 800 natural products from plant, animal and microbial sources.\u0026quot; The team then asked the network to suggest the best ways to combat the bacteria but were different from the usual antibiotics.\u0026ldquo;This produced a hundred candidates for physical testing and led to one (which they named “halicin” after the HAL 9000 computer from 2001: A Space Odyssey) that was active against a wide spectrum of pathogens – notably including two that are totally resistant to current antibiotics and are therefore a looming nightmare for hospitals worldwide.\u0026quot; This outcome is an extraordinary achievement for modern medicine.\nRead more here\nHere\u0026rsquo;s hoping that the same method can be used towards finding a cure for the coronavirus. Speaking of which\u0026hellip;\nHow China Is Using AI and Big Data to Fight the Coronavirus     AI thermal scanners are detecting whether commuters in China are showing symptoms of the coronavirus    The Chinese Government have installed AI operated thermal scanners that automatically show a person\u0026rsquo;s temperature. The scanners are the newest installations at train stations in the country\u0026rsquo;s major cities. If it is determined that a person has a fever (one of the first symptoms of the coronavirus), station employees will alert health officials and take the commuter into an isolation room at the train station for monitoring.\nStation staff are saying that the technology is a great help, as before the scanners, they were having to manually take each and every commuter\u0026rsquo;s temperature.\n    Vaccines for the disease are being developed but could still be months away until they\u0026#39;re ready for use    \u0026ldquo;Now, some companies in China are planning to upgrade the temperature detection system to include facial recognition technology. On February 7, AI company Megvii said it was working on a solution that \u0026ldquo;integrates body detection, face detection and dual sensing via infrared cameras and visible light\u0026rdquo; to help staff working at airports and train stations \u0026ldquo;to swiftly identify people who have elevated body temperatures\u0026rdquo;.\u0026quot;\nRead more here\nConclusion If you are interested in trying out our technology, please try our platform or drop us an email at hello@videotranslator.ai.\n","permalink":"https://videotranslator.ai/news/fighting-the-coronavirus-and-e-coli-with-machine-learning/","tags":["English"],"title":"Fighting the Coronavirus and E. Coli with Machine Learning"},{"categories":["Video Translation","Enterprise","Transcription","Translation","Healthcare","Dialects","Accessibility","Languages","Translation Services","Case Study","Visual Guides"],"contents":"There is a very interesting piece of content we are looking at today. A team from IIIT-H (Indian Institute of Information Technology - Hyderabad) has build an AI which translates and lip-syncs a video from one language to another.\nThis originally came to our attention in this article from the folks at TNW. The paper this article is based on is here, and if you are interested in AI/Language you should absolutely have a look.\nHere at video translator we are obviously interested in the work these scientists are doing. Our approach is a little bit different, but we cannot do lip syncing, so maybe its a moot point.\nVideo Translator: Face-To-Face Translation So what is the team at IIIT-H doing? From the paper, only provide textual transcripts or translated speech for talking face videos to also translate the visual modality i.e. lip and mouth movements. Consequently, our proposed pipeline produces fully translated talking face videos with corresponding lip synchronisation.\n    How AI Dubbing Will Change Everything: Face To Face Translation    So this really very cool. What is happening here is:\n First there is a text-to-text translation happening Next there is a speech-to-speech translation happening This gets added to the visual translation (which is the bit the IIIT-H team worked on)  Together these give what the researchers are calling Face-To-Face Translation. One of the research team has a YouTube channel, so this is a sample below.\n  How AI Dubbing Will Change Everything: Face To Face Translation Sample\n   While the technology is very cool, its not something we really do. The approach we have taken is quite different.\nVideo Translator: Speech-To-Speech Translation (Our App!) So how is this technology different to what is happening here at video translator?\n    How AI Dubbing Will Change Everything: VideoTranslator\u0026#39;s Speech-To-Speech Translation    So what we are doing is we expect human intervention at (1) and (2). That is:\n Do a Speech-To-Text AI Transcription (human post-editing expected) With the transcript do a Text-To-Text Translation (human post-editing expected) With the translated transcript, do a Text-To-Speech Dubbing (human post-editing expected)  Generally this means the end-to-end flow is better suited for assets which are expected to be online for a long time. Hence we put in the extra effort into making the asset really nice.\nWhat do such assets look like? This is an English video a client recently provided us.\n  How AI Dubbing Will Change Everything: English Original\n   This is the AI Vietnamese version.\n  How AI Dubbing Will Change Everything: AI Vietnamese Translation\n   Obviously the work that IIIT-H has done is a scientific paper, whereas you can try our technology for free, because its a production Saas app.\nCheap too! :)\nWhich Is Better? Clearly we are biased, and we think our approach is superior. But lets talk about why?\nOur clients report that you always want to over-disclose with AI.\nOk, here is what is happening. You always want to tell people it is an AI. This is because if they don't know, most people feel like you are trying to fool them somehow. And then they react badly.\nBasically AI Dubbing is pretty good, but its NOT that good. So a human will always work out that something is up. If you do not disclose, people get cranky.\nDisclosing its an AI is very good. Mostly because normal people (outside tech) are excited about technology, so will (paradoxically) pay more attention. That is, we get a win when we disclose, and people are cranky when you do not disclose.\nThe lip-syncing is a very cool feature, but comes awfully close to fake news, and communities worldwide have deep concerns (totally legitimate concerns too!) about fake news.\nNo really - disclose that you are using an AI!\nWe think you need standards/regulation, and lip syncing with AI is probably not going to reassure the community. That being said, if properly disclosed, there is almost certainly a place for this new technology.\nWe wish the team at IIIT-H the best, and hopefully we see their tech out in the wild sooner rather than later. Best of luck gents, and very nicely done!\nConclusion Curious about how we could help your business? Check out our managed service, or try our app for free! Alternately drop us an email at hello@videotranslator.ai.\nPlease connect with us on LinkedIn, YouTube or Facebook for any comments, questions, or just to keep up to date with the work we do!\n","permalink":"https://videotranslator.ai/news/how-ai-dubbing-will-change-everything/","tags":["English","Vietnamese"],"title":"How AI Dubbing Will Change Everything: Building A Video Translator"},{"categories":["Video Translation","Enterprise","Transcription","Translation","Dialects","Accessibility","Languages","Translation Services"],"contents":"AI Transcription has been all the rage recently. Several companies have been coming out with new products to meet this requirement.\nWhat does it mean? Does it work? How to evaluate these products? We take a look and try to think behind the hype.\nFirst we look at some of the incoming offerings. Then some issues with AI Transcription and Translation.\nIncoming Offerings There is a very large number of AI products hitting the market place. Here are a few examples of what is happening.\nGoogle Translate To Add Real-Time Transcription Feature Earlier this month Silicon Angle posted this article about how Google is going to be adding a real time transcription feature.\nHere is the money quote, “Your mobile phone effectively turns into a language translator for long-form speech,” Sami Iqran (pictured), product manager for Google Translate, told SiliconANGLE in an interview at a press event Wednesday in San Francisco.\nImportantly, also from the same article, The feature sounds a bit similar to the Live Transcribe app on Android, which is aimed at the hearing-impaired and allows them to see a transcription of people’s speech on their smartphones. However, that app cannot translate speech into another language.\nCisco Integrates Voicea Transcription AI into Voice Assistant From the VoiceBot website, which you should totally check out for very interesting AI news, came this article.\nWhat Cisco says about their new product, “Voicea users have reported saving more than six hours per week per user with more actionable and efficient meetings – and we believe Webex users will experience similar results,” Cisco senior vice president Sri Srinivasan said in a statement. “We’re excited to bring this and other cognitive features to the 300 million users we already serve with Cisco Collaboration. This technology will fundamentally change how we are able to deliver massively personalized experiences and transform the way we work.”\nSo this is an interesting offering in a couple of different ways. Cisco is marketing this as a AI Secretarial Service. So the idea here is:\n Use the AI to transcribe the content Users can tag key moments, and there is some kind of mechanism to follow up Using another mechanism further conversation points can be followed up on  Not having seen the product or worked on it, we have no idea what kind of traction will happen here. But lots of interesting ideas here from Cisco.\nMicrosoft’s AI Automatically Comments On Video Clips Venture Beat has another bit of news from earlier this month. The basic idea is, Generating live video captions with AI could bolster engagement on social media ...\nOk - that kind of makes sense. But it seems an awful lot like, lets get AI\u0026rsquo;s commenting on our content, and maybe someone will be fooled and start commenting on it too.\nThat may be a bit of a cynical viewpoint but that is what it sounds like to me.\nBut giving these folks the benefit of the doubt, the team from Microsoft Research Asia and Harbin Institute of Technology came up with a new model which, iteratively learns to capture the representations among comments, video, and audio, and they say that in experiments, it outperforms state-of-the-art methods.\nIn fairness, the code is available on GitHub, so might be worth checking out.\nWe have not yet done this, so please be aware of that when reading our take on it. Why have we not done this? Because the last commit is from December 2018, so\u0026hellip;\nThere is a pretty cool picture though. The below is just a screenshot from the same article.\n    How AI Transcription Fails And What To Do About It: AI generated comments from MS Research    But we should not be too cynical here as the researchers admit this is a interesting project, “[W]e believe the multimodal pre-training will be a promising direction to explore, where tasks like image captioning and video captioning will benefit from pre-trained models,” wrote the researchers. “For future research, we will further investigate the multimodal interactions among vision, audio, and text in … real-world applications.”\nCool - even if the use case is a bit of a mystery and the project seems to be dead on Github.\nWhat Does It Mean? And Does It Work? AI Transcription is obviously a hot space for new product and research. And here at video translator our product is obviously in the same space.\nAlso, in the world of AI, never say never, because technology is moving very fast. That being said, we feel there are two major issues with the majority of AI transcription products available today.\nThis is not to say AI transcription/translation does not work - it absolutely does, when used properly.\nIssue 1: AI Transcription Fails Because Of the Differences In Languages Vs Dialects The first issue is language vs dialects. People speak in different dialects. What are you going to do?\nIn the VideoTranslator app we have an explicit language-dialect mapping which allows the user to specify the specific dialect which the content should be transcribed with - the example below shows the AI dialect options for English.\n    How AI Transcription Fails And What To Do About It: Language-Dialect Mapping    Now this is not to say a more general AI (in terms of its training corpus) cannot get a really good transcript.\nHowever, we find that using the specific AI on a dialect basis results in higher accuracy. This is also not entirely surprising for obvious reasons.\nIssue 2: AI Transcription Fails As We Move Up Information Complexity So this is a bit hard to explain. AI\u0026rsquo;s are trained on a corpus (data set). So a transcription AI is trained with lots of sound files, and a translation AI with lots of text files.\nThis is the problem, high information complexity content, is by definition, not that common. Hence the more complex a subject is, the less likely this content is in the corpus used to train the AI.\nThink about it this way, for a gossip column the AI will probably be pretty good; for medical information, the AI will be less good; for quantum physics, yeah ... nah.\nBut higher information complexity content is precisely what is valuable.\nAgain, higher information complexity content is precisely what makes the information valuable, in fact, the higher the complexity, generally speaking, the more valuable it is.\nThis is why your doctor can charge you lots of money, or your lawyer, or accountant. Because they have higher information complexity knowledge in their heads. You are paying for the time they spent learning the subject matter.\nThis is why many of these AI\u0026rsquo;s don\u0026rsquo;t work so well.\nAt VideoTranslator, we explicitly sell our product as an efficiency win, not a cost saving. You really want a human subject matter expert (i.e. good old human judgement!) to finesse your transcript or translation.\nConclusion AI Transcription is very capable, and with the right use-cases, can lead to really big productivity wins. This means you can increase the quality of the transcription or translation depending upon what you are trying to do. We hope this post shows you some of the things to think about when choosing your preferred AI toolkit.\nRemember: Use the VideoTranslator AI's for the heavy lifting, and your own staff to do high value tasks. Practically this means your staff can think more about engagement and converting clients, as opposed to manually doing the first pass transcription or translation.\nCurious about how we could help your business? Check out our managed service, or try our app for free! Alternately drop us an email at hello@videotranslator.ai.\nPlease connect with us on LinkedIn, YouTube or Facebook for any comments, questions, or just to keep up to date with the work we do!\n","permalink":"https://videotranslator.ai/news/how-ai-transcription-fails-and-what-to-do-about-it/","tags":["English"],"title":"How AI Transcription Fails And What To Do About It"},{"categories":["Best Practices","Transcription","Enterprise","Internationalization Industry","Localization Industry","Video","Translation Services","Users","Translation Professionals","Dialects","Accessibility"],"contents":"Oddly, its the feel-good stories which we think are the most important. This week we had a few stories come by which show much progress is being made in the popularity of regional languages.\nHere at VideoTranslator we feel that most people are quite proud of where they come from - its totally natural.\nEach one of us has a story of how we came to be, and the stories of those who came before are a vital part of any human identity. This week we have two such stories.\nWe are also experimenting with more video, so here is a sample! Let us know what you think!\n  One Igbo Woman Trying To Save Her Language\n   One Igbo Woman Trying To Save Her language This article from the Nigerian Vanguard newspaper covers one such story.\nOnyinye Ibelegbu, the CEO of the NwaadaIgbo Language School is working to save indigenous Nigerian languages from extinction.\n    One Woman Trying To Save Her Mother Tongue: Onyinye Ibelegbu, from Vanguard Nigeria    The model was first pioneered by her in her mother tongue Igbo. \u0026ldquo;\u0026hellip;At the time I left ZINOX, I had signed up on international teaching platforms. I also signed up on Tuterial as an Igbo Language teacher. I notice, however, that the demand for Igbo Language teaching was very high.\u0026rdquo;\nNice! This paragraph is illuminating however, I remember that we got punished as students for speaking our mother tongue which was tagged ‘vernacular’ at school. That affected the growth of our indigenous languages greatly. I however think it starts from the home. Yes, our national language is English, but that doesn’t mean we won’t grow our indigenous languages.\n\u0026ldquo;\u0026hellip; The Hausa Language is faring better. The average Hausa person will ask you why you cannot speak Hausa and will tell you that you’re supposed to speak her language since you are on her land. I learned the language while working there because they are a people who either do not care to speak English or who don’t know how to. And no matter how wealthy a Hausa man is, Hausa Language is always the language of communication in his home.\u0026rdquo;\nThis is true - within the VideoTranslator we have Hausa, but we do not have Igbo. We wish Onyinye Ibelegbu best of luck! Reach her here and check out her Udemy course in Igbo here!\nWhat Does Igbo Look Like? Google was our friend here, and we found these fantastic images of what Igbo is right now.\n    One Woman Trying To Save Her Mother Tongue: What does Igbo look like?    And this is also very cool, what Igbo might one day look like!\n    One Woman Trying To Save Her Mother Tongue: What could Igbo look like?    Tasmania Supports Vision For Aboriginal Languages To Be Taught To All Students Tasmanian Education Minister Jeremy Rockliff is looking to have children learn a little bit of the local Aboriginal languages, reports The Advocate from Hobart.\nThe idea is to promote reconciliation, and with any luck this is a positive step forward.\nFrom the article, \u0026ldquo;They want their language to be brought to the surface in a respectful way and like to have ownership over where it can be used and need to be given respect over how it is used.\u0026rdquo;\n    VISION: Jeremy Rockliff speaking at the Reconcilliation Tasmania launch of education programs for 2020. Picture Phillip Biggs    \u0026ldquo;For them to give permission to non-Aboriginal people is part of that journey.\u0026rdquo;\nAt VideoTranslator we think this is a very interesting development. Aboriginal languages are very hard to use (with computers) as much of the infrastructure is missing.\nAdditionally the majority of Aboriginal languages are dialects, and there is a large number of these dialects which are basically dying out. If you are interested in looking up more information we recommend this website run by the Australian Institute of Aboriginal and Torres Strait Islander Studies(AIATSIS).\nConclusion Please connect with us on LinkedIn, YouTube or Facebook for any comments, questions, or just to keep up to date with the work we do!\nWe are very grateful for your support!\nCurious about how we could help your business? Check out our managed service, or try our app for free! Alternately drop us an email at hello@videotranslator.ai.\n","permalink":"https://videotranslator.ai/news/one-igbo-woman-trying-to-save-her-language/","tags":["English"],"title":"One Igbo Woman Trying To Save Her Language"},{"categories":["Best Practices","Transcription","Enterprise","Internationalization Industry","Localization Industry","Video","Translation Services","Users","Translation Professionals","Visual Guides","Dialects","Accessibility"],"contents":"At VideoTranslator we keep an eye on what everyone else is doing.\nWell, we try to anyways. And one of the better resources out there is Social Media Today. This article, \u0026lsquo;What Gen Z is Watching Online - and What That Means for Marketers in 2020\u0026rsquo; is full of wonderful titbits about how to think about video.\nHow Gen Z Is Using YouTube The big takeaway from the article is that Vlogging and Informative Videos are the biggest draws.\nVlogging has become far more professional in the last few years since YouTube launched its YouTube Partnership Program.\nReading a bit more, including from this article we work out that:\nGen Z Learns How to Do Something by Watching Videos Gen Z is watching experts do something on YouTube to learn how to do it themselves.\nAccording to GenHQ\u0026rsquo;s national study from 2017, 85% of Gen Z watched at least one online video in the past week to learn a new skill.\nGen Z Discovers New Brands and Products on YouTube Basically Gen Z discovers new products by watching YouTube influencers. Influencers are often not what we think they are - here at VideoTranslator we are big fans of Justin Rhodes.\n    Source: Justin Rhodes Permaculture Pigs Kickstarter    Well - probably just me, but hey! Get on them Permaculture Pigs. The image is from his Kickstarter.\nThe point is, influencers are people who have their own content channel about something they are experts in, in the above case the expert is a family man who decided to change his families way of living to something sustainable.\nThe takeaway is, Gen Z has far more access to authentic experts across the different fields of human endeavour. Seen this way, the reliance on influencers is probably not a passing fad.\nHow To Use AI To Reach Gen Z The simple answer is to optimise search for video. That is, use AI to transcribe your content, and optionally translate your content. Once you have the captions (in *.srt, or *.vtt) you can do many things!\nThere are a few simple ways of doing this.\nUse Open Captions To Make Your Content Accessible Open captions are a simple way to reach a wider audience while meeting accessibility requirements.\nIn the VideoTranslator use the Auto Overlay feature to do this quickly and easily.\nUse Open Captions To Engage More People     Reach Gen Z With AI: Open Captions for fun and profit!    This is simple. use open captions to engage people on social media, especially social media channels where video content auto-plays muted.\nRemember to change the colours to match your brand!\nVTT On Your Website We have a patch coming out soon which will talk more about this in the future. Here is what you need to know.\nVTT files are super similar to *.srt files. But where SRT does not work with HTML 5, VTT is designed to work with the video tag in HTML 5.\nThis means that your video content can be indexed by search engines. Make sure you do this properly!\nConclusion What sources of information do you track to learn more about the advances in AI? Let us know what digital marketing stories caught your interest?\nPlease connect with us on LinkedIn, YouTube or Facebook for any comments, questions, or just to keep up to date with the work we do!\nWe are very grateful for your support!\nCurious about how we could help your business? Check out our managed service, or try our app for free! Alternately drop us an email at hello@videotranslator.ai.\n","permalink":"https://videotranslator.ai/news/how-to-reach-gen-z-using-ai/","tags":["English"],"title":"How To Reach Gen Z Using AI"},{"categories":["Video Translation","Enterprise","Weekly Roundup","Accessibility","Artificial Intelligence"],"contents":"If there\u0026rsquo;s one thing most of us can agree on, it\u0026rsquo;s that wildlife preservation is important. The animals on this planet have been suffering a lot since we humans came on the scene. Luckily, there are amazing people out there trying to right the wrongs. Using Artificial Intelligence, researchers are able to continue this quest all the more and we\u0026rsquo;re looking into just how that\u0026rsquo;s being done.\nHow Artificial Intelligence Is Changing Wildlife Research     Giraffe populations are rapidly declining but AI is here to help    Researcher Jenna Stacy-Dawes and her team at San Diego Zoo\u0026rsquo;s Institute for Conservation Research are being assisted in their work in giraffe conservation with the AI software program, Wildbook.\nWildbook, \u0026ldquo;automatically identifies individual animals by their unique coat patterns or other hallmark features, such as fluke or ear outlines\u0026hellip;Stacy-Dawes and her colleagues are now able to blitz a giraffe population with photos over two days, upload the images and location data to their GiraffeSpotter database, and presto: a robust population assessment emerges. So far they’ve used Wildbook to assess giraffe numbers across three wildlife conservancies in northern Kenya.\u0026quot;\nRead more here\nGoogle Aims AI At Whales, Their Words And Well-being     Google using its AI technology to track endangered whale species    Google is using its technology for good, with its AI whale tracking technology. One such technology is a \u0026ldquo;\u0026ldquo;bioacoustics\u0026rdquo; project using AI to help scientists, governments and nonprofit groups track endangered species.\u0026quot; This isn\u0026rsquo;t the first time the tech giant has used AI tracking for whales, \u0026ldquo;Two years ago, it partnered with the US National Oceanic and Atmospheric Adminstration to track humpback whales by using AI which recognises the sound of whales in audio captured by underwater microphones.\u0026quot;. The tracking helps to identify whales and their whereabouts in conservation efforts.\nRead more here\nConclusion If you are interested in trying out our technology, please try our platform or drop us an email at hello@videotranslator.ai.\nPlease connect with us on LinkedIn, YouTube or Facebook for any comments, questions, or just to keep up to date with the work we do!\n","permalink":"https://videotranslator.ai/news/ai-and-wildlife-preservation/","tags":["English"],"title":"AI \u0026 Wildlife Preservation"},{"categories":["Best Practices","Transcription","Retail","Enterprise","Subtitles","Video","Translation Services","Users","Translation Professionals","Dialects","Case Study"],"contents":"At VideoTranslator, we get lots of feedback from clients. Most of it is good, some of it not so much. Recently, as we have started to build out our retail client base it has become interesting.\nThe product challenge with retail is quite different from an enterprise offering or a managed service. Because the user is not being paid to use the product (or being told to by their manager) expectations for the product are totally different.\nThis is a challenge from a product perspective. On the plus side, the feedback means that the product becomes much much better, and we can take risks and see what works.\nOn the negative side, clients are not invested in you, so the feedback can be blunt to put it mildly. This is very negative for one\u0026rsquo;s ego. Also, you only get one shot to get it right.\nWe think the exposure to retail is critical because of the feedback it provides. This IS how you make a product better!\nWhen A Client Makes You Blush In the below, the app had some problems with large *.mov / *.avi files. We think we have isolated the issue, but it had not come up before and a patch is still pending.\nThe client pointed this out. But in the sweetest, most decent way possible. Thank you to our clients from the bottom of my heart. You guys are a blessing.\n    Clients: You are amazing, and make it all worthwhile    Here is the deal. We don't really know this clients use case. I don't know why he is transcribing Russian, and then translating to English.\nBut... and this is the big one, for some reason this capability is important to this client.\nAnd he was happy despite the bugs in the platform. He even sent a pretty decent bug report in, and was still happy with the product!\n    Clients: Just made my day to read the mail above!    You guys are phenomenal. We love you. Please keep us on our toes. But its really nice to be told when we do something right too.\nGod bless you all.\nConclusion The small things are often really big things. The personal is often the driver behind the business.\nIf we are really really lucky going forward, we will keep our wonder at customers being amazing. Thank you for your support so far.\nCurious about how we could help your business? Check out our managed service, or try our app for free! Alternately drop us an email at hello@videotranslator.ai.\nPlease connect with us on LinkedIn, YouTube or Facebook for any comments, questions, or just to keep up to date with the work we do!\n","permalink":"https://videotranslator.ai/news/clients-why-you-make-me-blush/","tags":["English","Russian"],"title":"Clients: Why You Make Me Blush!"},{"categories":["Video Translation","Enterprise","Weekly Roundup","Accessibility","Languages","Translation Services"],"contents":"We recently came across an article with the exciting news that the Indian government is planning on making its Internet content available in regional languages \u0026ldquo;to remove the language barrier among Indians.\u0026quot;\nCurrently websites are available in English and Hindi but that leaves out the remaining 20 regional languages that are spoken across the country.\n\u0026ldquo;We need a method through which any Indian using his or her language should be able to converse with any user in any other Indian language without the impediment of English as a link language. This is the kind of goal we have set,\u0026rdquo; says Ajay Prakash Sawhney, Information Technology Secretary.\nYou can read the rest of the article here. Of course, not everyone speaks English, so providing these kinds of services would be of great benefit to many people in India.\nHere at VideoTranslator, we offer Hindi, Bengali, Urdu and Tamil as subtitles to videos and currently offer Hindi in various AI voices for dubbing.\nHave A listen To Our Hindi Voices Below (S) is Standard, and (P) is Professional. Standard is simply an older generation of AI. The pricing on both is the same, and we recommend Professional where possible. Languages where Professional is not available, Standard is recommended.\nMidlife Male (S)   Sorry, your browser does not support the  tag.    AI Dubbing: AI Dubbing: Hindi Midlife Male - Standard   Midlife Male (P)   Sorry, your browser does not support the  tag.    AI Dubbing: AI Dubbing: Hindi Midlife Male - Professional   Young-adult female (S)   Sorry, your browser does not support the  tag.    AI Dubbing: AI Dubbing: Young-adult female - Standard   Young-adult female (P)   Sorry, your browser does not support the  tag.    AI Dubbing: AI Dubbing: Young-adult female - Professional   Young-adult Male (S)   Sorry, your browser does not support the  tag.    AI Dubbing: AI Dubbing: Young-adult male - Standard   Young-adult Male (P)   Sorry, your browser does not support the  tag.    AI Dubbing: AI Dubbing: Young-adult male - Professional   Conclusion Please connect with us on LinkedIn, YouTube or Facebook for any comments, questions, or just to keep up to date with the work we do!\nWe are very grateful for your support!\nIf you are interested in trying out our Indian languages or any of our different AI languages and dialects, please try our platform or drop us an email at hello@videotranslator.ai.\n","permalink":"https://videotranslator.ai/news/speaking-in-the-mother-tongue-ai-indian-languages/","tags":["English","Hindi","Bengali","Urdu","Tamil"],"title":"Speaking In The Mother Tongue: AI Indian Languages"},{"categories":["Best Practices","Transcription","Enterprise","Subtitles","Captions","Video","Healthcare","Accessibility","Translation Services","Users","Translation Professionals","Dialects"],"contents":"At VideoTranslator, we do a lot of work with clients who are part of the healthcare ecosystem.\nThat being said, we are not transcribers, translators, voice over artists, or in this case, nurses/doctors. We use AI to do transcription, translation and synthetic (AI) dubbing - we are technologists who are trying to service our clients to the best of our ability.\nEvery now and then a story turns up which brings a lot of our work into sharp focus. This week we look at a hearing impaired couple from Arizona who are suing their healthcare provider.\nArizona Couple Sues Their Healthcare Provider From the Ahwatukee Foothills News we get this story. An Arizona couple are taking their healthcare provider, Dignity Health and its Chandler Regional Medical Centre to federal court over what they consider to be a lack of interpretive services for deaf patients.\nThe information in the story says that the couple has been waiting more than five years to resolve a civil complaint for practices they think are discriminatory against the deaf community.\n    Accessibility: Arizona couple Mitchell and Dawn Siegel, sourced from AFN    From the article, \u0026ldquo;Dawn Siegel visited Dignity’s Chandler Regional Medical Center in 2014 for severe stomach pains and claims she was not provided a sign language interpreter who could translate what doctors and nurses were telling her.\u0026rdquo;\n\u0026ldquo;She was instructed to write down what she needed to tell hospital staff or communicate through an off-site interpreter via webcam video.\u0026rdquo;\n\u0026ldquo;Siegel found the video service ineffective due to poor visual quality and the interpreter’s inabilities. She claims her requests for a certified, in-person interpreter were not granted during her nine-day hospital visit, resulting in Siegel never wanting to return.\u0026rdquo;\nCan You Get Sued For Not Providing Accessible Services? \u0026ldquo;The Siegels were among a group of deaf individuals who joined together in 2014, to sue Dignity Health for violating protections under the Americans with Disabilities Act obligates health providers to “effectively communicate” with deaf people.\u0026rdquo;\nSo you probably can get sued. As technologists, we have no idea if there is merit to the lawsuit, and clearly we do not have many facts at all.\nBut yes, you can get absolutely sued. Whether this will hold up in court is a different matter, and not something we can comment on.\nIs The Couple Justified In Suing Their Healthcare Provider? Again, on this specific case, we cannot comment seeing as we do not know the details.\nMore generally, is there limited support available to people with disabilities? We think most reasonable people can agree with that sentiment.\nThe challenge is that providing disability friendly facilities is hard to think about, complex to do and expensive to implement.\nHow Can You Use AI To Provide A Better Outcome, And Increase Engagement VideoTranslator allows you to use AI to do two things which can help with providing better disability friendly facilities.\nBut first some context, people want to feel empowered to make good decisions, and providing them access to relevant information is the key here.\nHow To Add Open Captions To Your Video Adding Open Captions is one of the simplest ways to reach the hearing impaired community.\nThe heuristic is pretty simple:\n Use an AI to transcribe your video. Use the Auto-Overlay feature to bake in, or burn in, your captions into the video.  This article about the Quick Transcribe feature covers the process.\nHow To Make Your Video Disability Friendly / Accessible Assume the video content is going to be deployed on your website, and social media channels.\nThe key idea is to make sure the transcript is also in the description. So what you need to do is grab the transcript and make sure you are adding that information into the description/metadata fields of your preferred social media channels.\nOnce you have used the AI to transcribe your video, you need to get the captions without any time stamp codes.\n    Accessibility: (Before) Transcript with timestamps    Use the Hide Timestamps button to get the transcript without the timestamps and then copy the content to use on social media.\n    Accessibility: (After) Transcript with timestamps    Deploying Your Asset With Open Captions If you have used the Auto-Overlay feature to add Open Captions the outcome will look something like below - you can also use the translate feature here for reaching your preferred target demographic.\n    Accessibility: Another example of Open Captions - note the font/colour is fully editable    Hopefully the above was useful in showing you how to make your video content disabled friendly. Spending the time/money to make this happen is good for your stakeholders, and proven to increase engagement, so it\u0026rsquo;s well worth it!\nConclusion We don\u0026rsquo;t have any specific legal qualifications, and no idea if you will or will not be sued. Our technology offers a solution where healthcare clients can add accessibility options to their content spend.\nCurious about how we could help your business? Check out our managed service, or try our app for free! Alternately drop us an email at hello@videotranslator.ai.\nPlease connect with us on LinkedIn, YouTube or Facebook for any comments, questions, or just to keep up to date with the work we do!\n","permalink":"https://videotranslator.ai/news/accessibility-why-it-matters-and-how-to-avoid-being-sued/","tags":["English"],"title":"Accessibility: Why It Matters And How To Avoid Being Sued"},{"categories":["Video Translation","Enterprise","Weekly Roundup","Accessibility","Languages","Translation Services"],"contents":"Thousands of kilometres apart, and in incredibly different cultures; three linguists are doing their part to save the culture of their people through language.\nMasahiro Yamada and Natsuko Nakagawa in Japan and Kenny Pheasant in the United States are all passionate about ensuring almost lost languages are preserved and continue to be taught; and a lot of it comes down to teaching the languages to children.\nLinguists Work To Preserve Ryukyu Dialects Now Dying Out     Image courtesy of Nobuaki Tanaka    Professors at the National Institute for Japanese Language and Linguistics made an alarming discovery when they found that many dialects in the Okinawa Prefecture are on the verge of dying out.\nAssociate professor of linguistics, Masahiro Yamada began research in 2010 and found that the elders on the island of Okininawa found it difficult to maintain their dialects and convey them to younger generations.\n\u0026ldquo;Yamada was awed by a local proverb that states: “Forgetting language leads to forgetting the island. Forgetting the island leads to forgetting our parents.”\u0026quot;\nSo, Yamada chucked a Helen Lovejoy and thought of the children. Together with his team and the islanders of Okinawa, Yamada has created a children\u0026rsquo;s picture book that tells stories and folk tales from the islands, using the dialects that are in need of recovery. The book will be available in July of this year.\nRead more here\nLocal Man Breathes Life Into Language     One man and his goal to keep his native language alive    In Manistee County in the United States, one man is doing all he can to preserve his native language and help it to continue on for centuries to come.\nKenny Pheasant of the Anishinaabe people teaches Anishinaabemowin, his native language through series of videos on Facebook and even runs a yearly language camp for those interested in learning and preserving the dying language.\nPheasant is so invested in keeping Anishinaabemowin alive that he has created certain words to adapt to the 21st century. Words like television didn\u0026rsquo;t exist because TV wasn\u0026rsquo;t a part of the Anishinaabe culture.\nMuch like Yamada in the previous article, Pheasant believes in teaching the younger generations to help preserve the language and culture, \u0026ldquo;If you want to save the language, teach the kids.\u0026rdquo;\nRead more here\nConclusion Please connect with us on LinkedIn, YouTube or Facebook for any comments, questions, or just to keep up to date with the work we do!\nWe are very grateful for your support!\nIf you are interested in trying out our technology, please try our platform or drop us an email at hello@videotranslator.ai.\n","permalink":"https://videotranslator.ai/news/on-the-brink-of-extinction/","tags":["English","Japanese"],"title":"On The Brink Of Extinction: Nearly Dead Languages And The Dedicated Linguists Bringing Them Back To Life"},{"categories":["Video Translator","Enterprise","Weekly Roundup","Accessibility","Languages","Translation Services"],"contents":"For something that is used by an estimated 70 million people worldwide, there is still a lot we don\u0026rsquo;t know when it comes to the origin of sign language - luckily research is being done to change that. Going from the past to the future, Google Translate is developing a way to translate sign language into speech and we are excited about the possibilities that this brings for, well, everyone!\nGoogle’s AI Can Translate Sign Language Into Speech     Image courtesy of Google Translate    In what we consider to be a really exciting achievement, Google Translate has developed the ability to translate sign language into speech.\n\u0026ldquo;This means that in theory, this piece of software would allow those with speech issues to communicate more easily with others who might not know sign language. This is done by using a camera coupled with software that can track the movement and gestures of the user’s hand and interpret it accordingly.\u0026quot;\nWhile the technology is still being tested, we can\u0026rsquo;t wait for it to make it\u0026rsquo;s debut. With sign language being used by an estimated 70 million people worldwide, we can only imagine the world of opportunity this would open for those using sign language being able to communicate with those who don\u0026rsquo;t.\nRead more here\n‘Evolutionary History’ Of Sign Language Uncovered     Discovering the origins of sign language    Researchers have traced the origins of sign language back to six European languages. \u0026ldquo;A new study suggests these sign language lineages are made up of three larger groups of Austrian, British and French origin, as well as three smaller groups of Spanish, Swedish and Russian origin. They believe that the six European lineages dispersed to other parts of the world, beginning in the late 18th Century.\u0026quot;\nAuthor of the study, Justin Power states that while there are many studies around the origin of spoken language, the study of sign language is lacking beyond historical accounts of deaf students and their teachers. This research delves further into how sign language originated and how it was first used back in Europe in the late 18th century.\nRead more here\nConclusion Being advocates for sign language (and language in general!), we believe that open captions is imperative for the deaf community and those who are hard of hearing to be able to experience the world like everyone else.\nWe are also big fans of Open Captions which work very well. Using VideoTranslator we can transcribe the content and embed them into video. Take a look at why we think open captions are important here.\nPlease connect with us on LinkedIn, YouTube or Facebook for any comments, questions, or just to keep up to date with the work we do!\nWe are very grateful for your support!\nIf you are interested in trying out our technology, please try our platform or drop us an email at hello@videotranslator.ai.\n","permalink":"https://videotranslator.ai/news/sign-languages-their-past-present-and-future/","tags":["English"],"title":"Sign Languages: Their past, present and future"},{"categories":["Best Practices","Transcription","Enterprise","Internationalization Industry","Localization Industry","Video","Translation Services","Users","Translation Professionals","Visual Guides","Dialects","Accessibility"],"contents":"At VideoTranslator.Ai, we work closely with the Internationalization And Localization industry. This industry has many different participants, and they use our technology in different ways.\nAs a software firm, the hardest thing is to really understand what our clients do and why they do these things. Sounds funny, but it is true.\nWe had a strong response to our previous article, 3x Increase In Transcription Efficiency, and a number of questions and suggestions.\nThe majority of suggestions were along the lines of how the app was messy to use. In today\u0026rsquo;s blog post, we look at the new Quick Transcribe functionality - a no frills way to get what you need to do done.\nQuick Transcribe - What Are Clients Trying To Use VideoTranslator For? Quick Transcribe was built to serve a specific need - engagement and accessibility.\n    Quick Transcribe: Clients are using VideoTranslator for accessibility and engagement! Font, size, colour and transparency are fully customisable!    Quick Transcribe - Accessibility We recently had really bad bush fires in Australia, and fire-fighters are still looking at a tough fire season. A major part of what the RFS goes during this period is communicate with the community about what actions they should take.\nThen this happened.\n    Quick Transcribe: Accessibility is hard to do well, even more so in emergency situations    The point being made was how can hearing impaired people access video information. Historically the solution has been Auslan (Australian Sign Language).\nBut this is really hard in a situation where you have massive bush fires burning.\nIncrease Engagement On Your Video Content This is pretty simple - having open captions in you video means better engagement on social media platforms.\nPractically, most social media auto-plays video content muted - this is why open captions are useful.\nQuick Transcribe - How Does It Work? The idea was how to make it super simple. As few clicks as possible. Assuming you are already logged in or have just signed up for the free-trial.\nStep 1: Click On The Quick Transcribe button     Quick Transcribe: Click on the quick transcribe button    Step 2: Upload Your Video Using Drag And Drop     Quick Transcribe: Upload your video using drag and drop, adding a link, or import from your Google Drive or MS OneDrive    Step 3: Select Your Preferred Language And Dialect     Quick Transcribe: Select your preferred language and dialect    Remember: Selecting the correct dialect is super important - this affects the quality of the AI transcription.\nHere is how to think about it. An AI is not human, and gets easily confused. Be nice to our computer friends.\nCongratulations: Your Video Has Been AI Transcribed! Below we have resized the video so the image came out nicely. You can see the transcript at the bottom of the image.\n    Quick Transcribe: Select your preferred language and dialect    Almost. I Lied, I\u0026rsquo;m Sorry. You Still Need To Clean Up The Transcript (Post-Editing) The process of fixing up an AI transcript (or AI translation, or AI dubbing) is known as post-editing.\nKey in the changes, and the overlay will show you what it looks like instantly.\n    Quick Transcribe: Click on the Captions button and edit the AI captions, this is called post editing    Quick Transcribe: What To Do Once Your Video Has A Transcript There are a few options:\n Download the *.srt file and use this in the Closed Captions for YouTube.      Quick Transcribe: Download the SRT file for use in Closed Captions     Use Auto-Overlay to bake the captions in - this is called Open Captions.      Quick Transcribe: Open Captions with a highlight using Auto-Overlay     We used Montserrat, black text, and 255,255,0 yellow for the highlight, with a transparency of 0.8.      Quick Transcribe: Some Auto-Overlay options shown above    Quick Transcribe: Finished With Open Captions Download the video once its complete, and deploy to your preferred social network.\n  Quick Transcribe: Video after being transcribed with Open Captions\n   Conclusion Please connect with us on LinkedIn, YouTube or Facebook for any comments, questions, or just to keep up to date with the work we do!\nWe are very grateful for your support!\nCurious about how we could help your business? Check out our managed service, or try our app for free! Alternately drop us an email at hello@videotranslator.ai.\n","permalink":"https://videotranslator.ai/news/quick-transcribe-for-when-you-need-to-get-transcription-done-quickly/","tags":["English"],"title":"Quick Transcribe: For When You Need To Get Transcription Done Quickly"},{"categories":["Best Practices","Transcription","Enterprise","Internationalization Industry","Localization Industry","Translation","Translation Services","Users","Translation Professionals","Dialects"],"contents":"Today we look at a humorous articles which look at what happens when AI goes wrong. Here at video translator we like to keep abreast of the latest news in the intersection of Artificial Intelligence, Natural Language Programming, Human Languages and Culture.\nRead on to find out how Facebook\u0026rsquo;s AI got in trouble, and why Oracle thinks replacing your manager with a robot is likely, and a good thing to boot!\nFacebook\u0026rsquo;s AI Got In Trouble This Week From this article at Gizmodo we get a funny story. The below picture says it all.\n    Mr Sh*thole: Facebooks AI gets in trouble...    Is this your nightmare?\nHow To Avoid AI Disasters? The following rules of thumb are really useful in terms of avoiding AI disasters.\n  Do not assume AI is a replacement for sound human judgement. The fact of the matter is, irrespective of whether we wish it or not, AI is sold as a replacement for humans with all the lovely lovely cost savings that implies.\n  Do not buy into this myth. While it may be possible that AI will seem like a viable replacement for good, well paid employees, this is absolutely a fools paradise.\n  Here is a simple way to think about it If replacing humans were so easy, very simple jobs would get automated first. What\u0026rsquo;s the simplest job? Flipping burgers at McDonald\u0026rsquo;s? There is a very good reason why this is hard and has not been automated. If you think your job is harder than flipping burgers at McDonald\u0026rsquo;s, chances are AI can\u0026rsquo;t replace you.\n  How To Use AI Properly? When we talk to clients (especially on the managed service offering) this question comes up. Here is the reality, your AI usage has to be calibrated to your own organisations risk profile.\n  We do a lot of work for healthcare providers. The translated video content we provide the concerns is always checked before being released to the public. Why? Because in healthcare content, getting it wrong might kill someone.\n  Use the AI as a productivity win. Do not think of it as a cost saving. This has the added advantage of not pissing your customers off.\n      Mr Not Sh*thole: Don\u0026#39;t go after someone else\u0026#39;s crust    But there is good news on the horizon\u0026hellip;\nHumans May Prefer Robot Overlords According to this bit of research from Oracle, 64% of People Trust a Robot More Than Their Manager. Bugger.\nIs this good or bad? Neither we think. Its simply a reflection of a changing world. To create better working spaces and better in-aggregate living standards, we see a world where AI acts in conjunction with humans.\nPeople are tool makers, and AI is just another tool. Sure it is a tool which has a remarkable ability to be misused, but this makes is no different from our more impressive tools.\nQuoting, AI is becoming more prominent with 50 percent of workers currently using some form of AI at work compared to only 32 percent last year. Workers in China (77 percent) and India (78 percent) have adopted AI over 2X more than those in France (32 percent) and Japan (29 percent).\nAI should not be thought of as a my-way-or-the-highway binary outcome by people. Understanding what AI can do, and how it can improve your earning power is a better approach.\nConclusion Please connect with us on LinkedIn, YouTube or Facebook for any comments, questions, or just to keep up to date with the work we do!\nWe are very grateful for your support!\nCurious about how we could help your business? Check out our managed service, or try our app for free! Alternately drop us an email at hello@videotranslator.ai.\n","permalink":"https://videotranslator.ai/news/mr-shithole-what-to-do-when-your-ai-misbehaves/","tags":["English","Chinese"],"title":"Mr Sh*thole: What To Do When Your AI Misbehaves"},{"categories":["Video Translation","Enterprise","Weekly Roundup"],"contents":"We\u0026rsquo;re talking language today and how diverse it can be even in the same country, or city! Germany is still a country divided when it comes to what a pancake should be called - maybe they should be called egg-cakes? Also Mandarin is now Melbourne and Sydney\u0026rsquo;s \u0026ldquo;most widely spoken community language.\u0026rdquo;\nLanguage matters, it\u0026rsquo;s important culturally and on a deeper level to help us identify with ourselves and others.\nRead on for a linguistic journey of the differences in language.\nGermans Still Divided On Dialect     A split of a different kind    It\u0026rsquo;s been thirty years since the Berlin came down but there is still a divide between the east and west in Germany, at least linguistically.\nA group of linguists who studied language in Germany for two years, discovered that there are linguistic differences between those who live in the east and west of the country; especially when it comes to food.\n\u0026ldquo;West of the former Berlin Wall, Germans call a pancake a Pfannkuchen; on the eastern side, they emphatically tuck into Eierkuchen or “egg cakes”.\u0026quot;\nTry not to get hungry and delve into what makes vernacular language still so important in today\u0026rsquo;s society as you read this.\nRead more here\nThe Word On The Street Is In Mandarin     Mandarin is now the common most spoken community language in Sydney    A recent study has found that besides English, Mandarin is the most widely spoken language in both Sydney and Melbourne. \u0026ldquo;The number of Mandarin speakers in Sydney increased by 71 per cent between 2011 and 2016, according to a new book titled Multilingual Sydney: A city report.\u0026quot;\nThe report found that multilingualism is not just in the inner city, with numerous suburbs in Sydney\u0026rsquo;s west becoming more and more diverse. Interestingly, there have found to be 20 different languages spoken in Sydney with over 20,000 people speaking them. Professor Phil Benson, co-editor of the book expects those numbers to increase.\nThis report is a fantastic read for anyone interested in the stats of various languages in our cities and what it means as we become more and more multicultural as a whole.\nRead more here\nConclusion We are very interested in the differences, and similarities, which language habits bring out. Some are shared, others are specific. Many are useful, and some tell us more about ourselves.\nPlease connect with us on LinkedIn, YouTube or Facebook for any comments, questions, or just to keep up to date with the work we do!\nWe are very grateful for your support!\nOur approach to try to understand this is through technology. If you are interested in trying out our technology, please try our platform or drop us an email at hello@videotranslator.ai.\n","permalink":"https://videotranslator.ai/news/one-place-many-languages/","tags":["English","German","Chinese"],"title":"One place, many languages"},{"categories":["Audio","Dubbing","Transcription","Translation","Transliteration","Subtitles","Welcome","Languages","Dialects","Users","Translation Services"],"contents":"Previously we\u0026rsquo;ve gone through the list of our English speaking AI and the different dialects they speak. You can see them all here.\nIn this article we\u0026rsquo;re looking at our Arabic speaking AI and the different dialects and voices available.\nIf you need a reminder as to how to select the appropriate AI language and dialect, check out our article here.\nNow, on to the voices! We\u0026rsquo;ve used the phrase birds of a feather, flock together or الطيور على أشكالها تقع for our AI to say each time for the examples.\nWhat voices are available in Arabic? Below you can listen to each voice provided in Arabic on our app:\nMidlife Female (S)   Sorry, your browser does not support the  tag.    AI Dubbing: Arabic Midlife Female - Standard   Midlife Female (P)   Sorry, your browser does not support the  tag.    AI Dubbing: Arabic Midlife Female - Professional   Midlife Male (P)   Sorry, your browser does not support the  tag.    AI Dubbing: Arabic Midlife Male - Professional   Midlife Male (S)   Sorry, your browser does not support the  tag.    AI Dubbing: Arabic Midlife Male - Standard   Young-Adult Male (P)   Sorry, your browser does not support the  tag.    AI Dubbing: Arabic Young-Adult Male - Professional   Young-Adult Male (S)   Sorry, your browser does not support the  tag.    AI Dubbing: Arabic Young-Adult Male - Standard   Conclusion And there you have it! Examples of all the AI Arabic voives that are currently available on the videotranslator.ai app. Stay tuned as we continue to update our database and for further articles displaying our AI in other languages and dialects.\nPlease connect with us on LinkedIn, YouTube or Facebook for any comments, questions, or just to keep up to date with the work we do!\nWe are very grateful for your support!\nIf you are interested in trying out our technology, please try our platform or drop us an email at hello@videotranslator.ai.\n","permalink":"https://videotranslator.ai/news/what-arabic-voices-are-available/","tags":["English","Arabic"],"title":"What Arabic Voices are Available?"},{"categories":["Transcription","Translation","Transliteration","Welcome","Languages","Dialects"],"contents":"There\u0026rsquo;s a lot of exciting developments at VideoTranslator, which means exciting things for you! This means that you\u0026rsquo;ll be hearing more from us going forward in the form of a weekly email.\nIf you haven\u0026rsquo;t subscribed to our mailing list or signed up for a free trial yet, please do so here.\nThe email will be featuring the latest articles we\u0026rsquo;ve posted which will be like the following:\n  What English Dialects are Available?\n  Where are we heading with AI computing in the 2020s? And how human can they really become?\n  Open Captions: Enhancements November 2019\n  So you\u0026rsquo;ll be the first to know about all things VideoTranslator as they happen and never be out of the loop.\nWe\u0026rsquo;re looking forward to a lot of great progress this year and can\u0026rsquo;t wait to share it with you!\nConclusion If you are interested in trying out our technology, please try our platform or drop us an email at hello@videotranslator.ai.\nPlease connect with us on LinkedIn, YouTube or Facebook for any comments, questions, or just to keep up to date with the work we do!\n","permalink":"https://videotranslator.ai/news/extra-extra-read-all-about-it/","tags":["English"],"title":"Extra! Extra! Read all about it!"},{"categories":["Video Translation","Enterprise","Weekly Roundup","Translation","Transcription","Accessibility","Languages"],"contents":"We now well and truly know that Artificial Intelligence is here to stay (and in fact has been for quite some time), but what will become of it, and us, in the future? One author has some very interesting thoughts on how AI computing will reach beyond just recognising how to act like a human but rather see the world the way we do and have a form of common sense. Also in a win for sign language, a lovely little clip of Prince William signing to an MBE recipient will warm your heart if the thought of AI having common sense is almost too much for you to bear.\nAI computing will enter the \u0026lsquo;land of humans\u0026rsquo; in the 2020s: The promise and the peril     Will we know when we\u0026#39;re dealing with AI in the future?    A great read for anyone who is questioning the pros and cons of sharing the world with AI computing. Author, Subbarao Kambhampati writes, \u0026ldquo;Of course, to get computers to go beyond recognition and see the world the way we do, we still have some hard AI problems to solve — including giving computers the “common sense” that we humans share, and the ability to model the mental states of those humans who are in the loop. The current pace of progress makes me optimistic that we will make important breakthroughs on these problems within this decade.\u0026quot; Which is an exciting and daunting prospect in itself.\nRead more here\nPrince William Expertly Signs \u0026lsquo;Congratulations\u0026rsquo; to Deaf Award Recipient     Prince William repping BSL    This heartwarming video shows Prince William use British Sign Language to congratulate \u0026quot; TV personality and deaf translator Alex Duguid\u0026rdquo; for receiving an MBE for his service to the deaf community. Duguid, has been a popular mainstay on British television for over 30 years. Kensington Palace\u0026rsquo;s Instagram posted the video, saying \u0026ldquo;He is an example of how profoundly deaf people can have an impact on their community, their peers and their country\u0026hellip;He is passionate about BSL and the need to promote and protect it.\u0026quot;\nRead more and see the video here\nConclusion Please connect with us on LinkedIn, YouTube or Facebook for any comments, questions, or just to keep up to date with the work we do!\nWe are very grateful for your support!\nIf you are interested in trying out our technology, please try our platform or drop us an email at hello@videotranslator.ai.\n","permalink":"https://videotranslator.ai/news/where-are-we-heading-with-ai-computing-in-the-2020s-and-how-human-can-they-really-become/","tags":["English"],"title":"Where are we heading with AI computing in the 2020s? And how human can they really become?"},{"categories":["Engineering","Video Translator","Video Translation","Support","Patch Notes","Accessibility"],"contents":"There are a number of bug fixes and patches, which may affect your experience. In fact, we hope it will affect your experience for the better!\nImages below are from our UAT environment. Please contact your relationship manager for more information or access.\nFixes include the below. If you have any questions please contact us at hello@videotranslator.ai.\n Spaces In FileTemplate And FileItem Names Transcription Without Time-Coding Transcription Copy Function Edit/Exit Modals Removed/Modified Fixes To Locking Cosmetic Fixes To Billing  January 2020: Spaces In FileTemplate And FileItem Names Previously, it was not possible to have spaces in fileTemplate and fileItem names. This was due to a previous issue where audio and video uploads failed inside a fileItem with a space in its name. This has now been fixed.\nDetails: Spaces In FileTemplate And FileItem Names  Click on a fileTemplate, and then click the New Item button. Note this is the Arabic template.      Patch Notes January 2020: Click on the Arabic template and create a new item for video translation     This creates the new fileItem. The upload questions are in Arabic.      Patch Notes January 2020: The modal now allows filenames with spaces    January 2020: Transcription Without Time-Coding Previously, there was no easy way to extract the captions without manually removing the timestamps from the source *.srt content.\nIn the below image, the captions are visible. To extract these captions without the time coding information, it was necessary to\n Select the content Ctrl-a Copy the content Ctrl-c Paste into MS Word or similar text editor Ctrl-v Manually edit out the timestamps for the content data only.      Patch Notes January 2020: Captions are shown in a sample video, which is also visible in the picture-in-picture    An enhancement has now been put in place. This means you can click on the Show/Hide timecode button to see the text content without associated time codes.\n    Patch Notes January 2020: Captions are shown in a sample video, with the time codes hidden and the button highlighted in yellow    January 2020: Transcription Copy Function Another request which made a lot of sense was to enable a copy-function. This allows the user to copy the contents of the *.srt source, with or without time-codes.\nPlease ensure that the correct source is selected when you are using this functionality.\n    Patch Notes January 2020: Captions can be copied using the Copy To Clipboard button, and a notification appears.    January 2020: Edit/Exit Modals Removed/Modified A number of selection modals have been removed or set to timers. Previously, when the user tried to go into a FileTemplate or FileItem by clicking the Edit button a modal asking for a confirm would appear - this has now been removed.\nAdditionally, when triggering a transcription, translation or dubbing action, a modal confirming and allowing the user to exit would show. Now, this modal is set to a timer and auto exits.\nJanuary 2020: Fixes To Locking The locking function has been the source of a reasonable amount of confusion, and it does not help the function had a bug.\nEarlier, to unlock a file, the user had to exit using the file menu. Now, clicking on Root, or MyTeam, will also properly unlock the fileTemplate or fileItem.\nJanuary 2020: Cosmetic Fixes To Billing Inside the app, there were are number of hints to how to use the billing. This information is presented in the billing section. Many of these hints were outdated.\nOriginally, our pricing model was $10/language-month + a balance for AI usage. This caused a lot of confusion so it was simplified to just be the $10/language-month which is run down on AI usage. This new model is based on a mobile phone plan.\nThe hints have been updated to better reflect the valid pricing model.\nConclusion There are a number of additional cosmetic fixes. Please let us know if you have any questions or concerns. We hope these fixes/enhancements are useful to your user experience using our application.\nPlease connect with us on LinkedIn, YouTube or Facebook for any comments, questions, or just to keep up to date with the work we do!\nWe are very grateful for your support!\nIf you are interested in trying out our technology, please try our platform, or drop us an email at hello@videotranslator.ai.\n","permalink":"https://videotranslator.ai/news/patch-notes-january-2020/","tags":["English"],"title":"Patch Notes: January 2020"},{"categories":["Video Translator","Enterprise","Weekly Roundup"],"contents":"Wouldn\u0026rsquo;t it be fantastic if we could understand what our pets were trying to tell us? Having them be able to communicate if they like the food we give them, when they\u0026rsquo;re not feeling well and when they want to be pet, would take out so much of the guess work. (Although hearing dogs constantly asking to have a ball thrown might get a bit old after a while). Researchers are looking into decoding animal languages and we are here for it! We also have some extremely thought-provoking pieces for you to read involving translation issues at the US border and the love affair that is learning a new language. Enjoy our first weekly roundup of the new decade!\n1. Artificial intelligence is helping us talk to animals (yes, really)     If we could talk to the animals - just imagine it    Dr Dolittle can do it, and many of us with pets really wish we could; so why not use AI to talk to the animals? In this thought provoking article, Mary Lou Jespen explains how projects like the Earth Species Project are working on developing AI systems that will decipher what large animals (think whales and elephants) are \u0026ldquo;saying\u0026rdquo;.\nAI has already deciphered ancient languages that are no longer in use anymore, so the stretch to understand animals really isn\u0026rsquo;t as far as you might think.\n\u0026ldquo;There is something deeply comforting to think that AI language tools could do something so beautiful, going beyond completing our emails and putting ads in front of us, to knitting together all thinking species. That, we perhaps can all agree, is a better – and perhaps nearer-term – ideal to reach than brain-computer communications. The beauty of communicating with them will then be joined to the market ideal of talking to our pet dogs. (Cats may remain beyond reach.)\u0026quot;\nRead more here\n2. Pocketalk Announces 2020 Model Of Two-Way Translation Device, Marking Official U.S. Launch One of the leaders in translating devices, Pocketalk, has released it\u0026rsquo;s latest model with some big updates and changes. Pocketalk founder and CEO, Noriyuki explains, \u0026ldquo;Our goal with the newest Pocketalk was to take into account the many different ways people communicate. We don\u0026rsquo;t just use voice - we use visuals, we use currencies - all of these connect us closer together and with our newest model, we are providing the most dependable, thoughtful, all-encompassing device to form deeper connections without language as a barrier\u0026rdquo;\nThe new model is available for pre-order now and features new updates such as:\n Camera: instantly recognises and translates text, the written word and signs, because language shouldn\u0026rsquo;t be limited to just verbal communication Faster: increased software processing speed for more immediate translations Conversion: computes exchanges for currency, length, width and temperature One-button translation: for simple translations in fewer steps  Read more here\n3. A Translation Crisis at the Border     Image credit: Ulysses Ortega for The New Yorker    A fantastic insight to the ongoing border crisis in the US. Written by Rachel Nolan, this piece delves into the lack of translation services provided for Indigenous Mayan-Guatemalans who speak indigenous languages - not Spanish and the tragedies that are taking place for people seeking asylum because they don\u0026rsquo;t have a representative who can translate for them.\nNolan speaks with interpreter Oswaldo Martín, a native Mam speaker, who is drastically helping the lives of refugess who would otherwise be deported simply because they can\u0026rsquo;t speak English or Spanish and thus can\u0026rsquo;t tell their reasoning for needing refugee status.\nAs Nolan states, \u0026ldquo;Guatemala has a population of fifteen million people, forty per cent of them indigenous, according to the most recent census. In the past year, two hundred and fifty thousand Guatemalan migrants have been apprehended at the U.S.-Mexico border. At least half of them are Mayans, and many speak little or no Spanish. According to the Department of Justice, Mam was the ninth most common language used in immigration courts last year, more common than French. Three Guatemalan Mayan languages made the top twenty-five: Mam, K’iche’, and Q’anjob’al.\u0026quot;\nThe need for translators in less common spoken languages is still extremely necessary and this article really demonstrates why.\nRead more here\n4. Learning a new language is like an illicit love affair Learning a new language can often be a love/hate relationship, we\u0026rsquo;re excited to get started, only to become frustrated when the language we long to speak is harder to master than we thought.\nFor those of us who are really determined, we stick to it and eventually it sticks! We are in no way near being fluent, but the language becomes easier to understand and the love affair truly begins.\nThis article describes the ups and downs of learning new languages and how it has helped many authors and writers in becoming the renowned wordsmiths we know them to be.\nRead more here\n5. Singular \u0026lsquo;they\u0026rsquo; voted word of the decade by US linguists     Pronouns they/them have shot up in use in the past decade    The Amercian Dialect Society has voted the singular \u0026lsquo;they\u0026rsquo; as word of the decade, deciding that it \u0026ldquo;stands the test of time and sums up the decade as a whole.”\nBeing used by non-binary and/or people who don\u0026rsquo;t associate with soley being male or female, the pronouns they/them have become increasingly used, \u0026lsquo;they\u0026rsquo; was also voted as word of the year in 2015.\n\u0026ldquo;The most popular pick for word of the year was “(my) pronouns”, a reflection of “how the personal expression of gender identity has become an increasing part of our shared discourse”, the society said in a statement announcing the outcome.\u0026quot;\nThe rise of the third-person pronouns have been aided by the use of social media and the fast pace at which it helps to get ideas, messages and phrases out to the world.\nRead more here\nConclusion Please connect with us on LinkedIn, YouTube or Facebook for any comments, questions, or just to keep up to date with the work we do!\nWe are very grateful for your support!\nIf you are interested in trying out our technology, please try our platform or drop us an email at hello@videotranslator.ai.\n","permalink":"https://videotranslator.ai/news/the-weekly-roundup-08-jan-2020/","tags":["English"],"title":"Real life Dr Dolittle: We are on our way to talking to the animals and AI may make happen sooner than you think!"},{"categories":["Best Practices","Transcription","Enterprise","Internationalization Industry","Localization Industry","Video","Translation Services","Users","Translation Professionals","Visual Guides","Dialects"],"contents":"At VideoTranslator, we do a lot of work in what is called the Internationalization And Localization industry.\nThat being said, we are not transcribers, translators, or voice over artists. We use AI to do transcription, translation and synthetic (AI) dubbing.\nWhen do we do this work for our clients? Generally when a client needs a managed service. This happens when a client is looking to try out tech and/or better understand the value proposition, or has their own reasons for us to provide this service.\nWhen this happens, the first task on our side is simple old transcription. That is what we are going to look at today - how do to a simple transcription.\nHow Long Does Transcription Generally Take? Google is our friend here. From the team at Opal Transcription Services, \u0026quot;The industry standard is four hours of transcription time for one hour of clear audio, or a 4:1 ratio – that is, one hour of transcription time for a 15-minute-long recording.\u0026quot;\n    Google Search: How Long Does Transcribing Take?    This is a pretty good way of thinking about it. Generally it will take about 4x the time of the video content.\nCan You Really Do Transcription At 3x Faster? Maybe. We think so, but there are caveats. This is how we did out testing. For this demonstration, we will use our standard Your Money: Peter Switzer video.\nYour Money was a short lived channel, but Peter Switzer has a very distinctive Australian accent, so we use this clip as a standardised test bed for a a number of different processes internally.\nThe below is how we tested our hunch.\nStep 1: Create a New Item And Upload The Video Step 1 is the same every time. Select the relevant template and upload the video.\n    3x Increase: Select the correct template and create a new item    Once the new item opens, upload the video - once uploaded it looks like below.\n    3x Increase: Upload your video using the highlighted button    Step 2: Use Action -\u0026gt; Transcribe to Transcribe Your Video     3x Increase: Action -\u0026gt; Transcribe to trigger the AI transcription    Click on Action -\u0026gt; Transcribe to use the AI to transcribe your content. We used Australian English here.\n    3x Increase: Action -\u0026gt; We selected Australian English here...    Depending on your file size, this can take time. The Your Money video is about 5 mb, and takes milliseconds. Basically, the bigger your video the longer it will take.\nStep 3: Clean Up The Transcription - Post Editing     3x Increase: Action -\u0026gt; We selected Australian English here...    This is where the majority of the work takes place. Here is what you need to do:\nScroll Down And The Video Will Pop Out (Picture-In-Picture) This is point 3 in the image above. The text in yellow is a projection, so you can change the colour (point 1) for ease of transcription.\nEdit Times And Text The editor works in real time (point 2), make changes as you go. Realistically, simply hit play and edit to your hearts content.\nDownload The SRT, Or Copy Paste The Content Depending on what you are doing, you will either (i) add open captions and download the video, (ii) download the SRT file, or (iii) access the captions directly.\nWe recently added the ability to directly access the captions without the time stamps - option (iii) above. Click the button highlighted in the below image to use this functionality.\n    3x Increase: Action -\u0026gt; Use the toggle to get the captions separately    Did We Get To A 3x Efficiency Gain? The above was not super scientific but we did get to the 3x gain. Effectively, the above means that the time it takes to transcribe the video is a little bit more than the video length itself.\nThis is due to stopping starting the PIP while you correct the captions. We found, for a 15 minute video, transcribing takes us about 20 minutes in total give or take. To be precise, 18 and a bit, but this is dependent on how good the original AI produced transcript is, which is in turn dependent on the kind of content in the video.\nAssuming 20 minutes though, given some video content will be faster and some will be slower, we get an improvement from 60 minutes -\u0026gt; 20 minutes, giving us the 3x improvement.\nConclusion Using the original 4:1 ratio, we think the average video of 15 minutes will take 20 minutes to transcribe, as opposed to 60 minutes for a fully human transcription. This is how we got to the 3x improvement.\nCurious about how we could help your business? Check out our managed service, or try our app for free! Alternately drop us an email at hello@videotranslator.ai.\nPlease connect with us on LinkedIn, YouTube or Facebook for any comments, questions, or just to keep up to date with the work we do!\n","permalink":"https://videotranslator.ai/news/3x-increase-in-transcription-efficiency/","tags":["English"],"title":"3x Increase In Transcription Efficiency"},{"categories":["Video Translation","Support","Welcome","Happy New Year","Translation Professionals","Translation Services"],"contents":"Its the start of a new decade! This is a big deal, the only question is will this be the roaring 20\u0026rsquo;s all over again. Here at VideoTranslator we think it is going to be an exciting year.\nSeveral amazing things happened last year, and this was mostly due to the kindness of strangers. Thank you very much to all the folks who took an interest in our work.\nWe started to get some traction, we found a niche where our tech was useful, and slowly slowly things started to come together. We think big things are ahead of us in 2020!\nThank You To The RFS And Other Heroes Who Keep Us Safe Here in Sydney, we had very smoky time over Christmas and New Year. Our thoughts and prayers go out to all the people fighting fires across Australia. We think the below image captures the struggle people in Australia have been going through. We ask you keep these everyday heroes in your thoughts and prayers. We originally heard about this incident here.\n    A firefighter and a koala watch on as fire burns through the Lobethal vineyard in the Adelaide Hills    Happy New Year Some other thoughts in no specific order.\n  We got a logo! We would like to thank the lovely Tarryn Myburgh and her team at TMCreates for all their support!\n    VideoTranslator.Ai now has a logo!      We are super grateful for the support everyone gave us in 2019. From the folks at Fishburners, to the support of our accounting partners Richards Financial Services, to our clients - it was a pretty good year.\n  We are also very thankful to the good people at JobsForNSW, who give us a bunch of money. It was our first true \u0026lsquo;street-cred\u0026rsquo; in startup-land.\n  Renee Dubé joined the team and immediately set about doing stuff in Content and UX. The majority of the posts, emails and notifications you get - Renee is the brains behind the magic.\n  It turned out our specific niche is AI dubbing, or synthetic AI speech, so this is what we are going to be doing quite a bit of work in 2020.\n  Conclusion Thank you so much again for all the support through 2019. Hopefully you are reading this coming out of a good holiday season. We at Video Translator hope you and yours have nothing but wins in 2020! Curious about our technology, or have questions? Please feel free to reach us at hello@videotranslator.ai.\nThanks so much,\nTat Banerjee\n","permalink":"https://videotranslator.ai/news/happy-new-year-2020/","tags":["English"],"title":"Happy New Year 2020!"},{"categories":["Video Translator","Enterprise","Transcription","Translation","Happy New Year"],"contents":"What a year it\u0026rsquo;s been! From our launch in May we would not have believed we\u0026rsquo;d come so far in such a short amount of time.\nThank You Thank you everyone for all your support! We want to wish you and yours a Merry Christmas and a Happy New Year. We hope you have a brilliant 2020!\nEveryone who engaged with us, others that offered feedback, and folks who made a purchasing decision - thank you very much.\nThank you to everyone whose time, thoughts and work touched our lives. We hope that your holiday season is joyful and surrounded by friends, family and good cheer, and next year is filled with wins.\nSee you in the new year,\nTeam VideoTranslator\nWinning In 2020! If you are interested in trying out our technology, please try our platform, or drop us an email at hello@videotranslator.ai.\nPlease connect with us on LinkedIn, YouTube or Facebook for any comments, questions, or just to keep up to date with the work we do!\n","permalink":"https://videotranslator.ai/news/happy-hoidays-from-videotranslator/","tags":["English"],"title":"Happy Holidays from VideoTranslator!"},{"categories":["Video Translator","Enterprise","Weekly Roundup"],"contents":"Language. It's something we're passionate about here at Video Translator, we can't get enough of it. And, judging by the news that\u0026rsquo;s come out in the past week, there\u0026rsquo;s a lot of folks out there who share our passion. We\u0026rsquo;re delving into language from all across the globe this week; NLP research engineers working with pidgin English, YouTube India is branching out into local and regional Indian languages, Navajo is getting it\u0026rsquo;s own version of one of the most popular (read: annoying for adults) songs amongst toddlers and we see the effects on the brain from being bilingual from an early age.\n1. Baby Shark creators to release Navajo version of wildly popular song     Bringing popular culture to the Najavo speaking people, helps to bring awareness of the vulnerable language    Just when the Navajo people thought they were safe, Baby Shark is coming to get and/or annoy them too! The creators of the Baby Shark (Doo Doo Doo Doo) video, which has over 4 billion views on YouTube are working with Navajo Nation Museum in the US to create a new version of the catchy song.\nA vulnerable language, Navajo is now only spoken by about 120,000 people.\n\u0026ldquo;The Navajo Nation, a semi-autonomous territory that stretches across swaths of Arizona, New Mexico and Utah, previously arranged for Disney’s Finding Nemo to be dubbed in Navajo as well. The museum is also exploring options beyond children’s programming. “All of these projects have been strategically chosen for the demographics we’re trying to address in the Navajo Nation.” “Language preservation is talking Navajo in the home and having more formal programs and schools that teach Navajo language.” Director of the museum, Manuelito Wheeler said being included in mainstream media has boosted Navajo pride in their culture.\nRead more here\n2. Regional languages to drive creators in 2020 Following the success of YouTube creators who speak in regional Indian languages over the past three years, the company has stated in will be focusing on even more Indian regional languages in the new year. This is to encourage growth amongst creators and viewers alike.\nDirector of Content Partnerships for YouTube Indian, Satya Raghavan, languages such as Tamil, Telugu, Malayalam, Bengali, Punjabi, Gujarati and Marathi are continuing to be used and growing amongst YouTube creators and influencers.\nIndia is now the top audience in the world for YouTube and is continuing to be one of the fastest growing audiences on the site. With regional languages being used on YouTube, the company can expect to see an ever-growing audience, who are able to relate and understand it\u0026rsquo;s creators and their content.\nRead more here\n3. How two Nigerian AI engineers built the world’s first pidgin-to-English translation model     Orevaoghene Ahia and Kelechi Ogueji worked on their translation model for three months    AI is still in it\u0026rsquo;s very early stages in Nigeria, but two engineers are beating the odds and have created the world\u0026rsquo;s first ever pidgin-to-English translation model. Due to there being no Wikipedia Pidgin available, engineers Orevaoghene Ahia, 21 and Kelechi Ogueji, 23 had to train a Unsupervised Neural Machine Translation (UNMT) model to learn the language from scratch, \u0026ldquo;scraping 56,695 pidgin sentences and 32,925 unique words from a couple of websites.\u0026quot;\nWhilst the pair have done a lot and we mean a lot to increase awareness and the availability of pidgin English online, their hope is for their work to help Google \u0026ldquo;be more inclusive of the 75 million Nigerians who speak pidgin English. Pidgin English is the closest thing West Africa has to a unifying lingua franca.\u0026quot; As of yet, there is still no Google translate for pidgin.\nRead more here\n4. 12 Everyday Applications Of Artificial Intelligence Many People Aren\u0026rsquo;t Aware Of We\u0026rsquo;ve all heard about the devious plans Artificial Intelligence has in store to take over the world and end the human race, but did you know they\u0026rsquo;re also already a part of our every day lives?\nThe Forbes Technology Council have listed 12 ways that AI is assisting and improving our lives, especially when it comes to interacting with businesses. Online shopping that\u0026rsquo;s personalised to your taste? That\u0026rsquo;s done with AI. Keeping security companies safe from cyberattacks? AI. Ensuring your finances are protected? Keeping internet services running smoothly? Better online customer service? AI. AI. AI.\nThis is a great read for anyone that\u0026rsquo;s just really interested in how AI is being used everyday or to share with the anti-technology doomsdayers we all have in our lives.\nRead more here\n5. The Sooner You Expose A Baby To A Second Language, The Smarter They’ll Be     Starting early, gives your child the best chance at being bilingual and in turn smarter    In what might be the cutest study ever to be conducted, researchers have discovered that babies who are raised as bilingual \u0026ldquo;develop core cognitive skills like decision-making and problem-solving \u0026ndash; before they even speak.\u0026quot;\n\u0026ldquo;The babies from English- and Spanish-speaking households had lots of activity in the prefrontal cortex and orbitofrontal cortex \u0026ndash; the regions of the brain responsible for executive functions, like decision-making and problem-solving. “Our results suggest that before they even start talking, babies raised in bilingual households are getting practice at tasks related to executive function,” said lead author Naja Ferjan Ramírez in a press release. \u0026ldquo;Babies raised listening to two languages seem to stay \u0026lsquo;open\u0026rsquo; to the sounds of novel languages longer than their monolingual peers, which is a good and highly adaptive thing for their brains to do,\u0026rdquo; co-author Patricia Kuhl said in the same release.\u0026rdquo;\nRead more here\nConclusion Please connect with us on LinkedIn, YouTube or Facebook for any comments, questions, or just to keep up to date with the work we do!\nWe are very grateful for your support!\nIf you are interested in trying out our technology, please try our platform or drop us an email at hello@videotranslator.ai.\n","permalink":"https://videotranslator.ai/news/the-weekly-roundup-17-dec-2019/","tags":["English"],"title":"For the Love of Language"},{"categories":["Conservation","Translation","Video","Accessibility","Translation Services","Users"],"contents":"At VideoTranslator, we are big fans of the work of Tim Brookes. Recently, his work has included a kickstarter to create art work in traditional Nepalese script known as Ranjana.\nWe look at a language he shone some light on today. We also look at work Comcast is doing to support hearing impaired clients. This is quite exciting from an operational perspective.\nLastly we look at a recent write up from the Latin Post which looks at how to interface with commercial translation firms for your localisation and internationalization requirements.\nA Once and Future Alphabet If you like language related content you should follow Tim Brookes. His work sits at the intersection of language and art.\nThis is from his recent kickstarter; disclaimer: we gave him a small amount of money because we are fans.\nBasically he works with artists to create woodcuts of content in relatively unknown languages. This is my favourite bit of woodwork.\n    Source: Tim Brookes; \u0026#39;Suksma\u0026#39;, the Balinese \u0026#39;Thank you\u0026#39;    Recently he wrote an article about Tifinagh, the script of the Amazigh family of languages, spoken by people in Morocco and North Africa generally.\nGo and read the article. Amazigh dialects are spoken by about 17 million in Morocco, 10 million in Algeria, 4 million in the Mali/Burkina Faso/Niger region, perhaps half a million in Libya, tens of thousands each in Tunisia, Mauritania, and Egypt, and several million scattered overseas, especially in France and Spain.\nUntil recently, this script was marginalised in favour of Latin/Arabic scripts, so writing a Tifinagh symbol on a wall, and may be interpreted as a political or generally subversive act.\nDue to work by the Institut Royal de la Culture Amazigh (IRCAM) in Rabat, Tifinagh is slowly coming back. This kind of news makes us happy. Go check out Tim\u0026rsquo;s work!\n    Source: IRCAM, Morocco; Schoolbook for teaching the Amazigh language in Tifinagh script    Comcast Now Offers Customer Service In ASL Here in Australia we have been having a bad fire season. Summers in Australia can be hazardous, but this year seems to be worse.\nFire bulletins go out but there were some concerns about Auslan support (the Australian version of ASL). One such example can be seen below. The link is here. Our take at VideoTranslator is that this was an oversight, and was corrected pretty quickly, so no harm no foul hopefully.\n    Source: Twitter; Retrieved Dec 13, 2019    But it would appear progress is being made more generally. The good people at Comcast and Connect Direct are taking the challenges of the hearing impaired community more seriously and have added ASL support to their customer service.\nQuoting, \u0026quot;For the first time in the cable industry, ASL will be a language option for customer service. The new feature will further bridge the digital divide for Americans with disabilities by ensuring that members of the deaf community can get connected to the Internet at home without barriers.\u0026quot;\nThe operational challenges of pulling this of are likely significant, so congratulations to Comcast for taking this step - we wish them best of luck with the continued delivery of this service.\nAccurate Translations and Localization Is Not Possible With Machines From the Latin Post, comes this headline.\nThe article makes the following points:\n Machines are programmed, humans program them. Humans come with cultural backgrounds, machines don\u0026rsquo;t. Humans understand humans, machines can\u0026rsquo;t. People get the intent, machines don\u0026rsquo;t. When in doubt, go for someone you can hold accountable.  Here at VideoTranslator, you might expect us to disagree with the above. We think the above points are actually quite reasonable, with caveats.\nFor every point above, we could furnish an example where the above either is, or is not, true. This might seem counter-intuitive, but this is complicated stuff, so it should not be surprising that there is truth to both points of view.\nThe way to think about AI is, use AI for the heavy lifting, and use humans for higher value tasks.\nUsing technology like our platform, human transcribers, translators and voice artists can greatly increase their efficiency. This does not mean it is a one-size-fits all.\nBut that is not really what this article is about. This article is about the pervasive belief that AI will replace human jobs.\nWe don\u0026rsquo;t think this is true, or at least not the way most people think. It is true that AI is causing dislocations in several business models. It is also true that many of these business models were declining to begin with - AI can be thought of as the final straw rather than the reason for the failures.\nDoes this make a difference if you are likely to loose your job due to automation - hell no. however, it is a valid distinction to make when policy makers are looking for solutions.\nWe don\u0026rsquo;t have all the answers, but we do think our approach of using AI will be a net benefit to the transcription, translation and dubbing communities. This is because fundamentally, humans and computers are good at different things.\nWe should still have empathy for people at the margins who are getting their wages squeezed by the relentless march of technology.\nNot least because it will take humans to solve these, and other, challenges of the 21st century.\nConclusion We don\u0026rsquo;t have all the answers, but we think it is possible to build platforms where the best of technology can help people be more effective and do more in less time. Talk to us to find out more!\nCurious about how we could help your business? Check out our managed service, or try our app for free! Alternately drop us an email at hello@videotranslator.ai.\nPlease connect with us on LinkedIn, YouTube or Facebook for any comments, questions, or just to keep up to date with the work we do!\n","permalink":"https://videotranslator.ai/news/an-old-language-feels-young-again/","tags":["English"],"title":"An Old Language Is Young Again..."},{"categories":["Video Translator","Enterprise","Weekly Roundup"],"contents":"It seems like every week there are exciting new developments with artificial intelligence being used in the health, medicine and science fields; and that\u0026rsquo;s because, well, there is. There is often quite a negative attitude amongst the public in relation to AI, \u0026ldquo;they\u0026rsquo;re going to take our jobs!\u0026rdquo;, \u0026ldquo;it\u0026rsquo;s the end of the human race!\u0026rdquo; But it\u0026rsquo;s not all doom and gloom. Really good, positive, and not to mention lifesaving advances in medicine, are taking place all with AI and proving that our new robot overlords are not planning on taking over the world just quite yet\u0026hellip;\nWe\u0026rsquo;re looking at exciting developments for Epilepsy patients with, you guessed it, the help of AI. Amazon has added 22 new languages to Amazon Translate and has Microsoft given children the ability to speak to reindeer? Read on to find out.\n1. Digital Health Trial Uses AI For Better Epilepsy Treatment Decisions     The possible drug combinations needed for Epilepsy patients are a lot of trial and error.    Clinical trials are underway in the US to better help specialists and patients when it comes to determining which drug scenario would be best for those who suffer from Epilepsy. Currently, there are over \u0026ldquo;14,000 different treatment scenarios\u0026rdquo; in which patients and doctors have in order to decide which medication would work best for each individual patient. As imagined, it\u0026rsquo;s a lot of trial and error at the beginning of diagnosis. What the researchers at Stanford and doc.ai are aiming to do, is use AI to streamline the process so that it is more scientific and based on real life exposures. The medication needed to treat Epilepsy can depend on their lifestyle, age and their local environment. \u0026ldquo;The predictive capabilities of AI to figure out the most effective choices given the complexity of the disease and relatively high number of treatments.\u0026quot;\nRead more here\n2. New York City Creates Chief Algorithms Officer Position Mayor of New York City, Bill de Blasio has created the position of Algorithms Management and Policy Officer, \u0026ldquo;a senior-level position to manage the city\u0026rsquo;s use of algorithms.\u0026quot; After a report, from the Automated Decision Systems Task Force was released, detailing that there was a need to eliminate \u0026ldquo;implicit or explicit biases,\u0026rdquo; as well as other risks, that might be coded into tools used by the city to deliver services on a daily basis.\u0026quot;, Mayor de Blasio created the position through executive order. It\u0026rsquo;s a step in the right direction and one that more cities and companies should follow as new technologies are used to assist in the running of said cities and companies.\nRead more here\n3. A.I. camera system launches in Australia to catch drivers on phones     NSW cameras can detect if you\u0026#39;re using your phone and driving    We\u0026rsquo;re almost all guilty of it, and we know it shouldn\u0026rsquo;t be done, but sometimes it\u0026rsquo;s tricky to stay off your phone when you\u0026rsquo;re driving. Well, if you\u0026rsquo;re in NSW, you\u0026rsquo;re about to become a lot more aware and mindful when you\u0026rsquo;re doing it. In a world-first that commenced December 1 2019, the NSW Centre for Road Safety are using AI mobile phone detection cameras to spot drivers who are illegally (read: not using their phones handsfree) when driving. The system uses artificial intelligence to automatically review images and detect offending drivers, and to exclude images of non-offending drivers from further action. Images that the automated system considers likely to contain a driver illegally using a mobile phone are verified by authorised personnel. For the first three months drivers will receive a warning letter. Once the three month period is up, drivers will receive five demerit points and fines of $344 or $457 if in a school zone. In what is already a notoriously dangerous time of year on the roads, play it safe and stay off your phone when driving regardless of which state you\u0026rsquo;re in please.\nRead more here\n4. AWS extends Amazon Translate to 2,804 language pairs, 6 more cloud regions Amazon Web Services Inc. (AWS), have added a further 22 new languages to its Amazon Translate service. The technology, which uses machine learning to automatically translate and convert text between languages can now translate Afrikaans, Albanian, Amharic, Azerbaijani, Bengali, Bosnian, Bulgarian, Croatian, Dari, Estonian, Canadian French, Georgian, Hausa, Latvian, Pashto, Serbian, Slovak, Slovenian, Somali, Swahili, Tagalog and Tamil. \u0026ldquo;Amazon Translate’s AI algorithms are now versed in a total of 54 languages and dialects. In practice, that means the service can provide automated translations across some 2,804 language pairs, more than 20 times the number it supported a year ago.\u0026quot; The company appears to be putting a lot of time, money and effort into advancing its natural language processing technologies. For those interested, they have a blog detailing the work being put into machine learning by its researchers.\nRead more here.\n5. Microsoft’s holiday ad shows off translation technology for dozens of languages (and reindeer)     Microsoft’s holiday spot, “Holiday Magic: Lucy \u0026amp; The Reindeer” McCann    We couldn\u0026rsquo;t resist featuring this in our roundup, it is the most wonderful time of the year, after all. Microsoft has cleverly released a new ad that promotes it\u0026rsquo;s voice translation service, while appealing to kids of all ages (including this 33 year old author) with it\u0026rsquo;s lovely story of Christmas magic and technology. After seeing her mother having an online meeting with Japanese colleagues and being told by her father that \u0026ldquo;they\u0026rsquo;re speaking to your mum in Japanese and she\u0026rsquo;s hearing them English\u0026rdquo;, Lucy later sees reindeer outside of her house. Rushing out with the Microsoft tablet she converses with the reindeer, asking all the important questions such as, \u0026ldquo;How do you guys fly?\u0026rdquo;, and \u0026ldquo;what does Santa do in the summer?\u0026rdquo; And while, as the ad states, Reindeer isn\u0026rsquo;t a language that can be translated in real time\u0026hellip;yet, it\u0026rsquo;s a fantastic way to advertise the technology\u0026rsquo;s capabilities.\nWatch the video here\nRead more here\nConclusion Please connect with us on LinkedIn, YouTube or Facebook for any comments, questions, or just to keep up to date with the work we do!\nWe are very grateful for your support!\nIf you are interested in trying out our technology, please try our platform or drop us an email at hello@videotranslator.ai.\n","permalink":"https://videotranslator.ai/news/the-weekly-roundup-10-dec-2019/","tags":["English"],"title":"Exciting developments for Epilepsy patients, Amazon has added 22 new languages to Amazon Translate and do children have the ability to speak to reindeer?"},{"categories":["Transcription","Translation","Transliteration","Welcome","Languages","Dialects"],"contents":"Did you know that our AI can speak in over 180 languages and more than 120 differing dialects and different genders? It\u0026rsquo;s true! That\u0026rsquo;s one smart robot ;)\nIn this article we\u0026rsquo;re focusing on English and the four different dialects that you can choose from when using our app.\nFor those that have you used the app before, you will notice that we have renamed the \u0026ldquo;voices\u0026rdquo;. Previously we had them named as EN-IN-P-M1, or UK-S4-M which didn\u0026rsquo;t make a lot of sense for those who were unfamiliar with the technology.\nNow, as you\u0026rsquo;ll see below the names are much more user friendly; we start with the country of origin, followed by the \u0026ldquo;age\u0026rdquo; of the voice, the gender and whether the AI\u0026rsquo;s voice is standard (S) or professional (P). Please note that standard (S) is an older version of the technology and so may sound a little more robotic than the professional (P) voices.\nWhat Dialects are available in English? We are constantly working on updating and adding new dialects to our app, at present we have four English dialects; Australian, Indian, British and American.\nWe\u0026rsquo;ve had each voice say the phrase \u0026ldquo;Life is what happens when you\u0026rsquo;re busy making other plans\u0026rdquo;, so you can hear the difference between each of the voices. Fun fact! Even though John Lennon is credited for the popular quote, it was actually writer and cartoonist Allen Saunders who published it in Reader’s Digest in January 1957.\nBelow you can listen to each dialect and voice provided in English on our app:\nAustralian English Midlife Female (P)   Sorry, your browser does not support the  tag.    AI Dubbing: Australian English Midlife Female - Professional   Midlife Female (S)   Sorry, your browser does not support the  tag.    AI Dubbing: Australian English Midlife Female - Standard   Midlife Male (P)   Sorry, your browser does not support the  tag.    AI Dubbing: Australian English Midlife Male - Professional   Midlife Male (S)   Sorry, your browser does not support the  tag.    AI Dubbing: Australian English Midlife Male - Standard   Young-Adult Female (P)   Sorry, your browser does not support the  tag.    AI Dubbing: Australian Young-Adult Female - Professional   Young-Adult Female (S)   Sorry, your browser does not support the  tag.    AI Dubbing: Australian Young-Adult Female - Standard   Young-Adult Male (P)   Sorry, your browser does not support the  tag.    AI Dubbing: Australian Young-Adult Male - Professional   Young-Adult Male (S)   Sorry, your browser does not support the  tag.    AI Dubbing: Australian Young-Adult Male - Standard   Indian English Midlife Male (P)   Sorry, your browser does not support the  tag.    AI Dubbing: Indian English Midlife Male - Professional   Midlife Male (S)   Sorry, your browser does not support the  tag.    AI Dubbing: Indian English Midlife Male - Standard   Young-Adult Female (P)   Sorry, your browser does not support the  tag.    AI Dubbing: Indian English Young-Adult Female - Professional   Young-Adult Female (S)   Sorry, your browser does not support the  tag.    AI Dubbing: Indian English Young-Adult Female - Standard   Young-Adult Male (P)   Sorry, your browser does not support the  tag.    AI Dubbing: Indian English Young-Adult Male - Professional   Young-Adult Male (S)   Sorry, your browser does not support the  tag.    AI Dubbing: Indian English Young-Adult Male - Standard   British English Midlife Female (P)   Sorry, your browser does not support the  tag.    AI Dubbing: British English Midlife Female - Professional   Midlife Female (S)   Sorry, your browser does not support the  tag.    AI Dubbing: British English Midlife Female - Standard   Midlife Male (P)   Sorry, your browser does not support the  tag.    AI Dubbing: British English Midlife Male - Professional   Midlife Male (S)   Sorry, your browser does not support the  tag.    AI Dubbing: British English Midlife Male - Standard   Young-Adult Female (P)   Sorry, your browser does not support the  tag.    AI Dubbing: British English Young-Adult Female - Professional   Young-Adult Female (S)   Sorry, your browser does not support the  tag.    AI Dubbing: British English Young-Adult Female - Standard   Young-Adult Male (P)   Sorry, your browser does not support the  tag.    AI Dubbing: British English Young-Adult Male - Professional   Young-Adult Male (S)   Sorry, your browser does not support the  tag.    AI Dubbing: British English Young-Adult Male - Standard   American English Midlife Female (S)   Sorry, your browser does not support the  tag.    AI Dubbing: American English Midlife Female - Standard   Midlife Female 1 (P)   Sorry, your browser does not support the  tag.    AI Dubbing: American English Midlife Female 1 - Professional   Midlife Female 2 (P)   Sorry, your browser does not support the  tag.    AI Dubbing: American English Midlife Female 2 - Professional   Midlife Male (P)   Sorry, your browser does not support the  tag.    AI Dubbing: American English Midlife Male - Professional   Midlife Male (S)   Sorry, your browser does not support the  tag.    AI Dubbing: American English Midlife Male - Standard   Young-Adult Female (P)   Sorry, your browser does not support the  tag.    AI Dubbing: American English Young-Adult Female - Professional   Young-Adult Female (S)   Sorry, your browser does not support the  tag.    AI Dubbing: American English Young-Adult Female - Standard   Young-Adult Male (S)   Sorry, your browser does not support the  tag.    AI Dubbing: American English Young-Adult Male - Standard   Young-Adult Male 1 (P)   Sorry, your browser does not support the  tag.    AI Dubbing: American English Young-Adult Male 1 - Professional   Young-Adult Male 2 (P)   Sorry, your browser does not support the  tag.    AI Dubbing: American English Young-Adult Male 2 - Professional   Conclusion And there you have it! Examples of all the AI English dialects that are currently available on the videotranslator.ai app. Stay tuned as we continue to update our database and for further articles displaying our AI in other languages and dialects.\nPlease connect with us on LinkedIn, YouTube or Facebook for any comments, questions, or just to keep up to date with the work we do!\nWe are very grateful for your support!\nIf you are interested in trying out our technology, please try our platform or drop us an email at hello@videotranslator.ai.\n","permalink":"https://videotranslator.ai/news/what-english-dialects-are-available/","tags":["English"],"title":"What English Dialects are Available?"},{"categories":["Internationalization Industry","Localization Industry","Best Practices","Video","Video Translator","Languages","Translation Services","Video"],"contents":"Google produces all sorts of very interesting research. I mean, all kinds! One of the specific bits of intel which is well worth tracking is Think With Google.\nToday we are going to look at a set of remarkable trend lines which point the way in which the world is heading.\nWe look at a 3 behaviour and cultural shifts inside YouTube.\n2 Behavioural And Cultural Shifts You should really read the article yourself, but the below was what we found super useful.\nSo the article has 3 big trends, but only 2 are listed below. We don\u0026rsquo;t really have anything to add to the third point.\nLocal Content Went Global     Source: Think with Google, YouTube Internal Data, U.S., March 2019–May 2019    Any way you look at this number, it is a remarkable number. When we consider how quickly this has all happened\u0026hellip; No seriously, its remarkable.\nWe are not surprised by this number - after all, our product is a video translator. Digging a bit deeper into the research Google has done, we get this image.\n    Source: Think with Google, Google Internal Search Data, Global, 2017 vs. 2018.    This quote is remarkable, \u0026quot;.. the U.S., we found people were often looking to reconnect with their heritage through their clothing. “I\u0026rsquo;ve become interested in my ancestry over the past four years and have started to include some Scandinavian styles in my wardrobe,” one American respondent told us — an insight relevant for more than just fashion marketers.\u0026quot;\nWe could not agree with this sentiment more. Culture is changing, and to be entirely honest, its a remarkable time to be alive.\nShopping Content Became Entertainment Ok - so we kind of disagree with this particular sentiment. Its a terribly well researched conclusion but I\u0026rsquo;m not sure this is exactly what is happening. From the research, we get the below infographic.\n    Source: Think with Google, Pew Research, 2016.    But does it mean what we think it means? Not sure we entirely agree.\nHere at Video Translator we think people connect to content other people care about. It is a fundamentally human thing to do.\nIf you make a video where you clearly care about the topic, other people are likely to also care. In a happy coincidence almost anything, when looked at closely, is fascinating.\nThis deep rooted human interest in \u0026lsquo;stuff\u0026rsquo; other humans find to be of value, we think is the mega trend. Well, its the mega trend also known as civilization.\nThe point is not to disagree that some merger between shopping an entertainment has happened, its to note that this is part of a bigger, richer, human story and should really be treated as such!\nConclusion Do you also track the research Google puts out? Even if not in digital marketing, they put our absolutely remarkable stories.\nLet us know what digital marketing stories caught your interest?\nCurious about how we could help your business? Check out our managed service, or try our app for free! Alternately drop us an email at hello@videotranslator.ai.\nPlease connect with us on LinkedIn, YouTube or Facebook for any comments, questions, or just to keep up to date with the work we do!\n","permalink":"https://videotranslator.ai/news/60-of-the-content-produced-by-us-youtubers-is-watched-in-other-countries/","tags":["English","Hindi"],"title":"60% Of The Content Produced By US YouTubers Is Watched In Other Countries"},{"categories":["Internationalization Industry","Localization Industry","Enterprise","Management","Retail","Translation Professionals","Translation Services"],"contents":"Rev.com, a online transcription platform, got in trouble last month. It picked up a negative profile last month by none other than the New York Times.\nEven worse was that Rev managed to become the poster child of gig-economy companies who mistreat workers. This led to a lot of negative media coverage which is probably not what Rev is looking to do.\nWhat Set Off Media Focus This article by the NYT set of this series of events.\n    Changes: Not the kind of media coverage you are hoping for...    \u0026ldquo;Until last week, Li Zilles was one of the many nameless and faceless contractors toiling in the bowels of the internet, providing online services that might have been mistaken for the work of artificial intelligence.\nThe job: to transcribe audio files for the start-up Rev.com, churning out texts without clients ever knowing the name of the transcriber.\nThis was a lonely existence, and not an easy one. The pay, even though the work was full-time, was little enough that food stamps became necessary.\u0026quot;\nUgly... then things got worse\u0026hellip;\n    Changes: Things get worse... that is 5.7k retweets and a lot of likes!    What Did Rev Do? Slator, an industry portal, covered the issue quite well. Quoting, \u0026rdquo;\u0026hellip; Rev offers a platform where Revvers (what freelancers on Rev.com are called) can work on transcription, video captioning, foreign subtitles and, to a much smaller extent, translation. A Revver takes a job by going on the platform, checking out the job specs, and claiming the job if they wish, or returning the job to the queue if not.\nRev found itself in the center of a maelstrom when, on November 8, 2019, it lowered job-pricing rates for freelancers hired through its platform. Revvers took to social media, complaining that the announcement of lower rates was poorly handled; that is, through an internal Rev.com forum that Revvers say they hardly ever check.\u0026quot;\nRevvers And Clients Get Involved. Gizmodo Jumps In\u0026hellip; Rev clients started to weigh in, and this unfortunately made Rev look worse.\n    Changes: In response to the media firestorm clients started to weigh in    Gizmodo picked up the issue. Quoting, \u0026ldquo;Rev, one of biggest names in transcription—and one of the cheapest services of its kind—opted to alter its pay structure with little warning for thousands of contractors on its platform, some of whom are furious at what they expect will be smaller paychecks from here on out. \u0026ldquo;\n    Changes: Gizmodo\u0026#39;s take on the issue    OneZero, an online publication got in on the act, but looking at a different point of view.\n    Changes: OneZero starts looking at other issues that Rev is currently having    Then Rev\u0026rsquo;s competition started to jump on the bandwagon.\n    Changes: Rev\u0026#39;s competition gets involved    You may be interested in the full text - its a pretty interesting read and makes valid points. Importantly, it goes over numbers which are pretty revealing.\nThe good bit, \u0026ldquo;Rev previously paid $0.45 per audio minute, so a typical worker would earn the equivalent of $6.75 per hour. At its new rate of $0.30 per audio minute, that same worker doing the same work would earn only $4.50 per hour.\u0026quot;\nI don't want a 1/3 pay cut, and I'm assuming you don't either!\nSo What Does It All Mean.. We don't really want to comment on the specific issues Rev has been having. Clearly, some things went wrong and there appear to have been a few technology failures as well.\nThis kind of thing can happen to any technology company, gig economy powerhouse or otherwise. We at VideoTranslator do not have the details of what happened inside Rev, and the drivers of their decision making - with luck Rev's staff is able to navigate this challenge in a way which works for Revvers and the client base.\nWhat we really care about is - this event set is based on a number of structural issues.\nWe think there are two structural issues these events revealed, and below is the thinking at VideoTranslator on how to handle these issues.\nStructural Issue 1: Are We Talking About Freelancers, Contractors Or Workers? The NYTimes articles starts with, \u0026ldquo;gig-economy company whose workers\u0026rdquo;. While several parties are involved here, the implication is pretty clear.\nIrrespective of what gig-economy companies might say/do, there are sections of the public who think that the contractors or freelancers (whatever your preferred nomenclature is) are workers.\nThis can be disputed, of course, but the structural issue for technology companies is that pressure can be expected around this challenge.\nYour product may not be affected directly, but your people and clients clearly are, so chances are your product is going to have to evolve to meet this challenge.\nRealistically, chances are its going to be an ugly learning process for any company caught up in these issues.\nStructural Issue 2: Is AI Reducing Take Home Pay For Workers? Maybe yes, maybe no. This specific instance did not directly involve AI, but Rev\u0026rsquo;s management is probably feeling pressure from AI based competition.\nIs this an instance of AI reducing take home pay? Probably not directly, but the likelihood is AI probably accelerated any pre-existent pressures.\nI think AI is not particularly responsible for causing these pricing pressures per se, but is making the competitive landscape more exciting, which is causing business models to break down in a number of instances.\nAI firms need to understand the broader pressures in the economy, if for no other reason than it directly affects our competitive landscape. Pretending this is not happening unfortunately does not make it go away.\nStructural Issue 3: How To Create Solutions Where AI Complements Humans? In theory, computers are good at things humans are terrible at (math, doing repetitive tasks) while humans are good at things computers are terrible at (judgements calls, adapting to a rapidly changing environment). This is the good news.\nIn practise, this is really hard. There are some really positive views on how machines can help people - for example here. Also lots of examples of how this interaction works out negatively.\nOur approach is to build a platforms that treat people as in integral part of the process. Use AI for the heavy lifting, and people for higher value tasks.\nConclusion We don\u0026rsquo;t have all the answers, but we think it is possible to build platforms where the best of technology can help people be more effective and do more in less time.\nTalk to us to find out more!\nCurious about how we could help your business? Check out our managed service, or try our app for free! Alternately drop us an email at hello@videotranslator.ai.\nPlease connect with us on LinkedIn, YouTube or Facebook for any comments, questions, or just to keep up to date with the work we do!\n","permalink":"https://videotranslator.ai/news/changes-in-the-internationalization-and-localization-industry/","tags":["English"],"title":"Changes In The Internationalization And Localization Industry"},{"categories":["Translation","Audio","Video","Dubbing","Video Translator","Languages","Dialects","Visual Guides","Accessibility"],"contents":"A few posts ago we transcribed an Indian English video using a Speech-To-Text Indian English transcription Artificial Intelligence (AI). Today we are going to take the same idea forward, and now going to translate the video into Hindi.\nTo recap, we used a sample clip from Rajya Sabha TV which as (a) transcribed using a speech-to-text AI, and (b) cleaned up by a human. We will now clean it up a little bit more, and then translate the content into Hindi. Finally, we will use a Text-To-Speech AI to speak out the Hindi content.\nIts going to be awesome. We hope this post gives you some ideas about how to use our technology. Let\u0026rsquo;s begin!\nWhat Are We Going To Be Working With? Our Source Video Is Already Transcribed We will use the video we produced at the end of this post. It is posted below.\n  Transcribing Indian English: Outcome after using the AI\n   First though, a bit of theory! Just like school!\nThe Look-Ahead And Forward Algorithms - The Theory One of the challenges in working with AI is the Look-Ahead and Forward algorithm usage. The majority of translation AI\u0026rsquo;s use the look forward algorithm to translate text content.\nFrom our trusty source of all knowledge (Wikipedia), Look-Ahead (backtracking) is 'In backtracking algorithms, look ahead is the generic term for a sub-procedure that attempts to foresee the effects of choosing a branching variable to evaluate one of its values. The two main aims of look-ahead are to choose a variable to evaluate next and the order of values to assign to it.'\nAlso, and slightly more technically, a Forward Algorithm is 'The forward algorithm, in the context of a hidden Markov model (HMM), is used to calculate a 'belief state': the probability of a state at a certain time, given the history of evidence. The process is also known as filtering. The forward algorithm is closely related to, but distinct from, the Viterbi algorithm.'\nThe Look-Ahead And Forward Algorithms - What Do I Need To Know? Okay - what does the above mean? Basically, the translation AI looks for a full stop. Once it finds the full stop, it translates the sentence.\nNo really - what? You need to add grammar, primarily full stops and comma\u0026rsquo;s so that the text-to-text translation AI works properly\nTo do this, make sure you check your transcript for grammatical correctness. This is shown below. Practically this means:\n  Add lots of full stops everywhere! Humans are very good at understanding each other, so we don\u0026rsquo;t need to be told where one sentence ends and where another sentence starts. AI\u0026rsquo;s - not so much.\n  If you watch the video embedded below, the sentences have all been converted into shorter sentences which are in third person. An AI can translate the shorter sentences way better, but take care to not loose meaning.\n  It is expected that a human subject matter expert translator will do post editing after the AI has done its first pass. However, simplifying means that you can translate into many languages quickly, and the post-editing can be reduced. Use your judgement!\n  The grammar was changed - shown below. If you watch through the video below, you will notice the open captions do not match what is being said. Note that this step is being taken primarily in preparation for the translation step.\n    What A Hindi Speaking AI Sounds Like: Add lots of grammar      After the process was complete we add an Auto-Overlay so you can see the full outcome. Note that the words are a little bit different, tense had been changed to past tense for everything and sentences are shorter.\n  What A Hindi Speaking AI Sounds Like: Amend the English and add an Auto-Overlay\n     Very cool. Now we can begin the translation process. Nicely done!\n  Translating The Content To Hindi   So the first thing we need to do is translate the content. Click Action -\u0026gt; Translate and translate this video into Hindi.\n    What A Hindi Speaking AI Sounds Like: Translate your video      It\u0026rsquo;ll take a few seconds and then you will see the translated file in your Root pane. It is hightlighted in yellow in the below image.\n    What A Hindi Speaking AI Sounds Like: Translation is complete!      Open it up, and in the Captions tab you will be able to see the translation. In the below image, note that the colour of the text has been set to black so it is easier to see for your post-editing.\n    What A Hindi Speaking AI Sounds Like: Hindi captions can be edited as necessary      When you do your own video, please ensure you do post editing! Remember, use the AI for the heavy lifting, but use human subject matter experts for the best results.\n  Below, we use the Auto-Overlay so you can see the output. We are using a black text with a yellow highlight at transparency of 80%. The little spinner indicates that the app is applying the Auto-Overlay to the video asset. This is what creates the open captions in the video.\n    What A Hindi Speaking AI Sounds Like: The spinner shows the app adding an Auto-Overlay      This is a direct AI translation so some errors are expected. Also, note that the timings are a little bit off. What is happening in the background is our code is trying to do a best fit of the sentences, but manual edits are often required. Please do this as part of the post-editing process.\n  What A Hindi Speaking AI Sounds Like: After adding the Hindi captions\n     Well done! Your video is now translated. But you thought it was going to speak Hindi?\n  AI Dubbing In Hindi - Now The Magic Starts! This is the simple version - we can get much more sophisticated in our outcome, including voices that sound like young or older people, men or women, and changing the volume and speed of the speech.\nIt is also possible to break the conversation up into different blocks of speech, properly matching the English content spoken.\nDrop us an email at hello@videotranslator.ai if you are curious and have questions. Or try the free-trial!\n  Copy the captions from the Video component into the Audio component.\n    What A Hindi Speaking AI Sounds Like: Copy the captions into the Audio component      Now we will use a Text-To-Speech AI to 'speak-out' the content in Hindi. Use the Action -\u0026gt; Transcribe to access the Text-To-Speech AI as shown below. This will give us the AI dubbing.\n    What A Hindi Speaking AI Sounds Like: Use the Text-To-Speech AI for AI dubbing      Abracadabra!\n   Next Steps - How To Implement Your Own AI Dubbing There are many options you have once you AI dubbing is complete. Several clients simply prefer to download the asset and work on it in their preferred audio/video editor. However, much of the same functionality is also present in the app.\n  Mute the original audio soundtrack using the \u0026lsquo;minus\u0026rsquo; button as shown below.\n    What A Hindi Speaking AI Sounds Like: Remove the original audio stream from your video      Generally it is recommended you slow-down the AI dubbing. This is because it is an AI, there is limited scope for tone. People expect changes is tone when talking to each other. An AI is unable to do this so when there is less tone, it helps to slow down the speech to about 90%. This helps people to understand the words.\n  When you insert the AI speech into the video as an Audio-Overlay use the 'plus' button to add the AI dubbing *.mp3 file.\n    What A Hindi Speaking AI Sounds Like: Remove the original audio stream from your video      Above, the highlights show (a) the plus button at the bottom to add additional audio overlays, (b) the original soundtrack muted and new soundtrack added, (c) the new soundtrack has its speed reduced to 80%, and (d) start and end time can be managed on a per conversation block basis.\n  The final outcome is below. This has several errors, and needs more work. To see the error forward to 1:57 and you will hear the sound stops. This is because we have just used one mp3 Voice Overlay for simplicity to explain the workflow.\n  What A Hindi Speaking AI Sounds Like: After adding a female Hindi speaker\n     Congratulations! We hope you found this post useful. This is quite a simplified workflow - let us know if you have any questions.\n  How To Think About This   Generally, you would break up the transcript into multiple conversation blocks. This helps space out the AI speaking nicely.\n  Select the appropriate gender of the AI if there is a conversation happening between a man and a woman.\n  If two men or two women are speaking in a conversation, use multiple AI voices. This helps your viewers understand what is happening.\n  Remember, the key win is SEO. When deploying the asset to some social media channel like LinkedIn or YouTube, make sure to translate the relevant metadata. This helps search engines index your content making it reachable in other languages.\n  Conclusion Please connect with us on LinkedIn, YouTube or Facebook for any comments, questions, or just to keep up to date with the work we do!\nWe are very grateful for your support!\nCurious about how we could help your business? Check out our managed service, or try our app for free! Alternately drop us an email at hello@videotranslator.ai.\n","permalink":"https://videotranslator.ai/news/what-a-hindi-speaking-ai-sounds-like/","tags":["English","Hindi"],"title":"What A Hindi Speaking AI Sounds Like"},{"categories":["Video Translator","Enterprise","Weekly Roundup"],"contents":"Considering it is something that keeps the human race going, maternal and placental health is still not properly understood, which proves extremely detrimental to the health of mother and baby during pregnancy. Thanks to a new development in AI technology, that will begin to change. We\u0026rsquo;re also looking at how educators in the US are frantically searching for a better solution to interpretations services that help communicate with non-English speaking families and we look at the leaps and bounds being made in medicine thanks to machine learning.\n1. Using artificial intelligence to analyze placentas     Using AI to determine the health of placenta and baby    Research is under way to aid pathologists in better understanding placental development and how it can benefit both mother and baby during pregnancy. Artificial intelligence will study both sides of the placenta in order to determine the placenta\u0026rsquo;s health and any risks associated to the pregnancy. The end goal being that the technology will aid many women during and after their pregnancies, especially in areas of lower income; these places tend to have less resources and hence more complications during pregnancy and childbirth.\nRead more here\n2. Education Department’s phone translation system clogged with long waits, dropped calls: teachers Educators in the US are struggling with a lack of translation technology and lacklustre interpretation services when it comes to parent/teacher interviews with non-English speaking families. After the US Education Department switched interpretation service vendors earlier this year, educators are dealing with extremely long wait times, calls constantly being dropped and often times no pick ups at all. Teachers are having to rely on fellow bilingual staff to interpret important information to families about their students.\nRead more here\n3. Machine learning has revealed exactly how much of a Shakespeare play was written by someone else     Shakespeare didn\u0026#39;t always work alone    It\u0026rsquo;s been a mystery that has been plaguing literary analysts since 1850, but thanks to AI technology, we now know that Shakespeare wasn\u0026rsquo;t just a one man show. It has been discovered that fellow playwright of the time, John Fletcher contributed to passages to Shakespeare\u0026rsquo;s Henry VIII. AI studied both men\u0026rsquo;s works and writing characteristics and analysed how much of each was prevalent in the play. As it turns out, it is believed that Fletcher co-wrote about 50% of Henry VIII.\nRead more here\n4. Paging Dr. Robot: Artificial intelligence moves into care Stress and ill mental health unfortunately often go hand in hand with university students and so the University of Southern California has developed AI programs for students to talk to during trying times. Using an AI and virtual reality character Ellie and AI-based program, Ask Ari, students are able to talk to both Ellie and Ari, that will in turn give them information about when to talk to a counsellor and vital resources to improve their mental wellbeing. The aim is to not replace therapists, but rather work with them to determine \u0026ldquo;who is most likely to be suffering.\u0026quot;\nRead more here.\n5. Lung cancer: AI shows who will benefit from immunotherapy     AI is helping to determine the benefits of immunotherapy on lung cancer patients    The fight to cure cancer is stronger than ever, and again doctors and scientists are looking to AI programs to help determine which lung cancer patients would benefit from immunotherapy. A relatively new form of treatment, \u0026ldquo;immunotherapy works by boosting a person\u0026rsquo;s immune response against cancer tumours.\u0026quot; The AI model, being developed by a team led by researchers in Case Western University, will help doctors determine, which patients are responding to the immunotherapy, resulting in higher survival rates as well as lessening unnecessary costs.\nRead more here\nConclusion Please connect with us on LinkedIn, YouTube or Facebook for any comments, questions, or just to keep up to date with the work we do!\nWe are very grateful for your support!\nIf you are interested in trying out our technology, please try our platform or drop us an email at hello@videotranslator.ai.\n","permalink":"https://videotranslator.ai/news/the-weekly-roundup-26-nov-2019/","tags":["English"],"title":"Hello baby! Machine learning helping to understand placental health, did Shakespeare have help? And advances in health and medicine thanks to AI."},{"categories":["Best Practices","Video Translator","Accessibility"],"contents":"DISCLAIMER: This blog post was updated after having a conversation with JobsForNSW. [3 Dec 2019]\nPlease check the JobsForNSW website for updates. The process covered below changes regularly and DO NOT rely on the below to be correct going forward. It was correct at time of publication, but talking to the JobsForNSW staff it is LIKELY to change pretty soon.\nEarlier this year we put in an application for a Minimum Viable Product Grant from JobsForNSW, a NSW Government initiative.\nIn this blog post we are going to look at the entire process and work through our successful application. Specifically:\n What is the MVP grant and where do you get more information? What the grant process looks like and what information we had to provide to get the grant. What the grant process was like, step by step, at a procedural level.  The point of this post is to provide information to anyone else within the Sydney/NSW startup ecosystem who is also looking into this grant and potentially applying.\nWill probably do another post of the content of (a) the videotranslator.ai grant application itself, and (b) the progress report at the end.\nWe are also hoping to have a follow up post where we talk to one of the officers inside JobsForNSW to get a insider view into how the process works.\nWhat Is The JobsForNSW MVP (Minimum Viable Product) Grant? From the JobsForNSW website, Minimum Viable Product (MVP) grants are designed to support promising startups with the funds needed to progress from a proof of concept stage to a minimum viable product. The grants are aimed at startups that are yet to generate revenue to help them engage with a potential business customer, or channel to market, and create innovative solutions that address compelling industry needs or market gaps.\nHow Much Money Can I Get From The JobsForNSW MVP Grant? From the JobsForNSW website, An MVP grant is a matched funding grant up to 50% of approved project costs, to a maximum of $25,000.\nRemember: You do not have to ask for the full $25,000.\nIn the specific case of videotranslator.ai we had a total project cost of $41,400.00. The idea is JobsForNSW is funding 50% of approved project costs, to a maximum of $25,000. Hence the amount we ended up getting for our project was $41,400 * 0.5 = $20,700.\nAssuming We Get The Grant - What Is The Timeline For The Application Process? From the JobsForNSW website, Successful grant applicants will receive 35% of the funding up-front and 65% after completion and validation of the MVP.\nThe exact sequence of events is provided below:\nDISCLAIMER: SmartyGrants below is the old system - JobsForNSW are transitioning to a new system.\n  You put in your application using an online system called SmartyGrants. The form itself is fairly straightforward - we did not use any external consultants.\n  You get a notification saying your submission has been received. This is an email and looks like below. Note the blacked out telephone numbers and emails are public, but have been hidden to the JobsForNSW staff don\u0026rsquo;t get spammed. If you really need to reach them, get creative with Google.\n    Winning: Submission Acknowledgement from JobsForNSW      You get another notification saying you have been moved to round 1 of the selection process. Unless your application is terrible and you have not completed the form, you should get to here without too many issues. It looks like below:\n    Winning: Round 1 Acknowledgement from JobsForNSW      Once here JobsForNSW has an internal process. In another post we will talk about how that exactly works. For now, the application goes to an internal committee and either you get the grant or you don\u0026rsquo;t get the grant.\n  In our specific case, videotranslator.ai got the grant - Winning! Also, on winning the grant you get notified by email. This looks like below:\n    Winning: We Won!      You will also get another email, from a person - that how you know :)\n    Winning: The JobsForNSW team is working on your funding deed      Download the deed, and make sure you sign and return the contract.\n    Winning: Get your pen out and sign the contract!      Sweet - the entire process took maybe 8 weeks - its a pretty quick turnaround.\n  Assuming We Get The Grant - What Do I Need To Know About The Deed? The grant is fairly simple. That being said, there are a few things which are really important:\n  The grant will cover the budget you put into your application. You really want to get this part right!\n    Winning: Make sure your budget reflects what the project is about!      Additionally, it is important that 80% of the Project Costs are within NSW. This does not mean if you pay Google Cloud or AWS or Azure you are in breach, it means that you can use a maximum of 20% of your budget on offshore resources. You also need to be aware that the duration of the projects is a maximum of 6 months.\n  Don\u0026rsquo;t worry too much about being too specific - in private conversations, the JobsForNSW staff understand you are a startup and maybe not everything works out. They understand that you are trying to do something really hard, and not everything goes to plan always.\n    Not Winning? If things go wrong with your project, talk to your advisor. Its ok, JobsForNSW understands that things go wrong sometimes      Lastly, the deed will cover exactly what JobsForNSW will fund and its timing. This looks like so:\n    Winning: Payment terms for your MVP grant      You're good to go!\n  Assuming We Get The Grant - What Is The Timeline For The Project? The main points to know:\n  The payment is in two parts. The first 35% is pretty much immediate. You raise and invoice and that is it.\n  The second part happens at the end of the project. You submit a report (using the same online application), have a meeting with your advisor, and then raise another invoice for the remaining 65% of the grant monies.. You get an email about this too:\n    Winning: Progress report accepted      In the app, at the end of the process (I\u0026rsquo;m writing this post after we have finished) the payments will look like below.\n    Winning: Three submissions in total after winning the grant, (a) 35% invoice, (b) Progress Report on completion, and (c) 65% invoice      That is kind of it in terms of process.\n  Conclusion We are super grateful to JobsForNSW. We did complete out prototype, filling out bits that did not work very well. We picked up a client (hopefully they will become a keystone client) during the project, and the client is super happy with our work.\nPersonally, we have not yet reached product-market fit, which I think of as having a scaleable sales process for your product at a good customer acquisition number (CAC), rather than product itself, but also think we are well on our way :) :)\nThank You I spoke to some other folks at Fishburners for advice through the process and after. Would like to thank the folks below, you guys are awesome.\n David Cox at QAChef. Man LEE at Sana. Peter Boyer at Muster - a mate at Fishburners was curious about the MVP process. Hope you get the grant bud!  Check out the above startups - they are doing very cool technology stuff!\nPlease connect with us on LinkedIn, YouTube or Facebook for any comments, questions, or just to keep up to date with the work we do!\nWe are very grateful for your support!\n","permalink":"https://videotranslator.ai/news/winning-how-we-won-a-jobsfornsw-mvp-grant/","tags":["English"],"title":"Winning: We Won The JobsForNSW MVP Grant! Before, During And After..."},{"categories":["Transcription","Video","Subtitles","Captions","Languages","Visual Guides","Accessibility"],"contents":"Working with a prospect, we added a number of enhancements to our open captions workflow. If you are interested in what open captions are and what its use cases are please have a look at this blog post.\nVery simply open captions are generally used as an accessibility tool focused on people who have hearing impairments. More recently due to the rise of streaming services, open captions have been making a come back.\n  As an example, a simple use case would be a new mum at home with her child. If the child is sleeping, the mum can watch video content (on TV or online) with open captions on mute.\n  Another example is people watching video on a social media platform, where the video content is often auto-played but in a muted environment.\n  We have added one simple enhancement to the Auto-Overlay functionality. The new functionality allows a user to add the open captions anywhere in the video.\nWe will be using the same RSTV sample which we worked with in an earlier blog post. To see how we used an AI to caption the Indian English video, please read this blog post.\nContext + The Enhancement A client we have been working with for a while had the following requirement. He wanted to add the open captions in a specific place in the video. Historically this was possible but was very hard to use effectively.\nThe enhancement is that we now allow X and Y coordinates to be placed, allowing the user to have fine grained control over the placement of the overlay.\nWhat Used To Be Possible? Assuming you followed the steps in this visual guide, you would be aware we can add open captions using the Auto-Overlay feature.\nBasically we used the Auto-Overlay feature as shown below. This is a two step process - we already have the captions from the previous steps.\n  Use Action -\u0026gt; Auto Overlay and choose a text colour, size and font. We have chosen black colour text, with font size 36 and font Ubuntu.\n    Open Captions: Step 1 in the Auto Overlay      In the second step, it used to only be possible to choose from three options Top, Centre and Bottom. This is shown below.\n    Open Captions: Step 2 in the Auto Overlay      It is important to understand what is happening here. Its basically a mathematical function called a text writer that is writing-out (or baking-in) the open captions into the video. The yellow highlight was probably not the best choice but its useful in demo.\n  Open Captions: After the Auto Overlay process has finished\n     Ok - now we are going to make some changes. First we use Action -\u0026gt; Remove Auto-Overlay to take away the open captions as we want to move them around. This looks like the below image.\n    Open Captions: Remove the Auto Overlay      How Has Auto-Overlay Changed? The change is slightly different for (a) the stripe, and (b) the highlight in the Auto-Overlay function. First, lets talk about the stripe and then we will look at the highlight.\nUse the Action -\u0026gt; Auto-Overlay and we use the pre-filled values for Step 1. The below images are from the point-of-view of Step 2.\nNo Stripe Or Highlight In this use case we don\u0026rsquo;t want a stripe or a highlight. This is shown in the image below.\n    Open Captions: No Stripe or Highlight    Depending on the colour scheme of the underlying asset the lack of a stripe or highlight may not offer the best user experience.\nUsing A Stripe In this case we want a stripe. The idea of the stripe is a bar across the screen. Here there are two options, show the stripe always, or show it only where there is text on the screen.\nFirst of course, go ahead and remove the no-stripe/no-highlight overlay from your asset. Then, trigger the Auto-Overlay process again.\nText Only Vs No Text Only Why would you use this? The use case is to do with the speed of the speech in your video.\n In the case where the speech is very quick, with minimal breaks in the speaking, we would recommend No Text Only Alternately, if there are gaps in the speech, use Text Only.  The idea is when the underlying speech is relativity fast the flickering of the stripe looks terrible, so you want the stripe to be in place irrespective of whether the text is showing or not showing.\nThe below example is of a Stripe with Text Only and we are using the blue colour.\n    Open Captions: Stripe with Text Only    This does not look amazing but you can see the effect of the Stripe with Text Only.\n  Open Captions: Stripe with Text Only\n   Using A Highlight In this case we want to use a highlight. The idea here is a highlight around the text in question. Using the highlight option looks like below. Text only is not a thing with the highlight for obvious reasons.\n    Open Captions: Highlight    In the video below, we used the Centre option to make it very obvious what is happening. Transparency is also turned down for the highlight itself.\n  Open Captions: Highlight but centred with no transparency\n   The Big Change: Advanced Options - Stripe The stripe example is the slightly more complicated of the two options. The first thing to note is the actual dimensions of your video. In our case, the video is 640 x 360 pixels. This is shown in the image below.\n    Open Captions: Work out the dimensions of your video    Add a stripe with the below advanced settings. Note that these numbers are actually wrong, but very useful to understand what is happening.\n    Open Captions: Add X and Y coordinates    What we are doing here is setting X and Y coordinates for the text at 20, 20. We are also setting the X and Y for the stripe at 40, 40. Normally you would set the stripe to X and Y coordinates similar to the text.\n  Open Captions: Stripe with incorrect advanced options\n   Ok - so that was nice, but not really useful. Lets try again with the below settings.\n    Open Captions: Add different X and Y coordinates    This looks much better. The idea here is to put the stripe at the bottom of the video. But we have made a mistake in the alignment of the text.\n  Open Captions: Stripe with less incorrect advanced options\n   With the examples above, hopefully it makes sense how to use this functionality.\nImportant: If you are using the stripe, please note that the height of the stripe is 10% of the height of the video itself. You may need to manually fix up the captions so that all the captions are single lines only.\nThe Big Change: Advanced Options - Highlight Highlights are easier to use than the Stripe - mostly because we only require one set of X and Y coordinates. The setup used is shown below.\n    Open Captions: Add X and Y coordinates - just one set for the text    This results in the following video using the highlight. Please note this setup is not optimised and make the changes required on your side.\n  Open Captions: Highlight is much easier to use!\n   Important: If you are using the highlight, it is well worth making sure that each sentence is roughly the same length and centring the open captions into the video nicely.\nConclusion We hope that this visual guide is helpful to you! Open Captions are very useful, and a critical part of the value proposition our video translator offers to clients.\nPlease connect with us on LinkedIn, YouTube or Facebook for any comments, questions, or just to keep up to date with the work we do!\nWe are very grateful for your support!\nIf you are interested in trying out our technology, please try our platform or drop us an email at hello@videotranslator.ai.\n","permalink":"https://videotranslator.ai/news/open-captions-enhancements-november-2019/","tags":["English"],"title":"Open Captions: Enhancements November 2019"},{"categories":["Video Translator","Enterprise","Weekly Roundup"],"contents":"It\u0026rsquo;s another AI focused week and with so much going on in the world of Artificial Intelligence, can you blame us? The field of medicine and science have long been advocates of using AI for the greater good and it appears there are some incredible trail blazers helping to make that happen.\n1. A Star Professor—And Her Radical, AI-Powered Plan To Discover New Drugs     Using AI to discover new medicine    One woman is using her incredible skills and mind to advance the way in which drugs can be discovered and created with the help of artificial intelligence. Daphne Koller, whose background includes winning \u0026ldquo;a \u0026ldquo;genius grant\u0026rdquo; for research that combined artificial intelligence and genomics\u0026rdquo; among other amazing acheivements has founded Insitro. The AI technology that Insitro uses will be able to study and conduct scientific experiments that would have once taken years, in a matter of weeks. The aim is to discover new drugs that will be able to provide treatment for diseases that are currently untreatable.\nRead more here\n2. For the sake of safety: This AI sensor triggers an alarm when kids are left alone in a car Too many times we hear the heartbreaking stories of children and animals dying after getting left in cars on hot summer days. Luckily scientists at the University of Waterloo, Canada have developed a low-cost AI sensor that may very well save lives. The small device will be able to detect movement from breathing and will sound an alarm (and potentially disable the ability to lock the car), if it detects a living being is still in a vehicle.\n\u0026ldquo;\u0026ldquo;It addresses a serious, world-wide problem. The system is so affordable it could become standard equipment in all vehicles,\u0026rdquo; George Shaker, an engineering professor at Waterloo said in a statement.\u0026rdquo;\nHoping to be on the market by the end of next year, we look forward to this advancement in technology.\nRead more here\n3. Farmers are using AI to spot pests and catch diseases — and many believe it’s the future of agriculture     AI enhanced drones are able to detect disease in crops    Drones equipped with AI computer vision are beginning to gain traction world wide in the agriculture industry. On a farm in Argentina, the drones are able to \u0026ldquo;look\u0026rdquo; at each and every single wheat stalk and identify the start of disease that could threaten the crop for that year. While the technology is an exciting advancement and could help farmers immensely, cost is still playing a key factor and the technology is not cheap.\nRead more here.\n4. Artificial intelligence: the fall of the Mad Men and the rise of the machines This article delves into why it is better to be on the side of new technology rather than fight against it and how those in the marketing field can and should be making the most of the new era we find ourselves in. Interestingly describing artificial intelligence as \u0026lsquo;enhanced intelligence\u0026rsquo;, author Graham Hayday demonstrates how new technology is actually a friend instead of a foe in the marketing industry and how creatives are using AI to enhance their abilities. The future is now and it\u0026rsquo;s time to make the most of it! (As far as this article is concerned.)\nRead more here\n5. Using AI to Understand What Causes Diseases     Image courtesy of C.J. Burton/Getty Images    We really couldn\u0026rsquo;t have summed up this article better ourselves, so we\u0026rsquo;ll let authors Sema Sgaier and Francesca Dominici do it for us:\n\u0026ldquo;Health care leaders are embracing AI. But by conducting an extensive review of case studies and research literature, we’ve found that their AI initiatives are predominantly focused on developing algorithms that can predict a problem such as cancer in order to make diagnoses better, faster, and less expensively. Rarely, are their organizations devoting resources to AI efforts aimed at understanding why diseases occur. To intervene as effectively as possible, both kinds of algorithms are crucial.\u0026rdquo;\nThe article goes in depth of explaining what is being done to use AI at discovering the causes of disease as well as just predicting them.\nRead more here\nConclusion This week has shown great developments in technology, especially in the AI field where we are seeing just how beneficial AI technology is becoming for us around the world.\nPlease connect with us on LinkedIn, YouTube or Facebook for any comments, questions, or just to keep up to date with the work we do!\nWe are very grateful for your support!\nIf you haven’t yet and are interested in trying out our technology, please try our platform, or drop us an email at hello@videotranslator.ai.\n","permalink":"https://videotranslator.ai/news/the-weekly-roundup-12-nov-2019/","tags":["English"],"title":"Using machine learning for the greater good; advances in medicine, agriculture and saving lives, is there anything we can't do with the help of artificial intelligence?"},{"categories":["Transcription","Video","Subtitles","Captions","Languages","Visual Guides","Accessibility"],"contents":"Today we are going to look at how to transcribe Indian English. Firstly of course, what is Indian English, and what does it sound like? How many such dialects exist? Have a look.\nNow that we know what Indian English sounds like, we are going to use a short clip from Rajya Sabha TV, an Indian government content creator. We use our AI to transcribe this clip.\nLastly, we add an Auto-Overlay so that we can show you the video. The final output is shown below.\n  Transcribing Indian English: Outcome after using the AI\n   What Is Indian English? From the folks at Wikipedia, \u0026ldquo;Indian English is the regional variety of the English language spoken in the Republic of India, and among the Indian diaspora elsewhere in the world. The Constitution of India has mandated Hindi in the Devanagari script to be the official language of the Indian union; English is an additional official language for government work along with Hindi.\u0026rdquo;\nCool. What does it sound like?\n  Rajya Sabha TV: 5 November 2019\n   Are you keen on hearing what other dialects of English sound like? Here are some samples.\nHow Do I Transcribe Indian English? Follow the below to transcribe your content in Indian English.\n  Click on the English Template and add an new Item. We've called it rstv1 in the image.\n    Transcribing Indian English: Use the English Template to create a new Item      Upload your video. We\u0026rsquo;ve made some changes to the upload screen which you can see below.\n    Transcribing Indian English: Add your video to the video component in item \u0026#39;rstv1\u0026#39;      Use Action -\u0026gt; Transcribe and a modal similar to below should show up. In the below image we have used Indian English - essentially telling the Artificial Intelligence that our video should be transcribed the the Indian English specific AI.\n    Transcribing Indian English: Tell the AI to use Indian English      The item will close and a little spinner will appear. Once complete the item with un-gray and we go in and look at our transcript. The captions button gets highlighted. Woohoo! This is the half way mark - now we have to clean up the transcript a little bit.\n  How Accurate Is The AI Transcribed Video? How Do I Make Changes If I Need To Edit The Transcript? We always recommend you have a subject matter expert check the AI's work - this process is called post-editing.\n  Scroll down so you see the captions - the video will pop out as a picture-in-picture for easier editing.\n    Transcribing Indian English: Picture-In-Picture pop out      To start with click on the text colour box and change it so you get a decent contrast - we picked blue. The idea is to change the colour to make it easier to work with - note this is just to make your life easier!\n    Transcribing Indian English: Change the colour of the text      Now go through and make any changes you need! Remember you can change both the times and text to match your use case. We made a number of changes - mostly fixing time/words and adding grammar. Below, you can see we go from 2 -5. This makes no difference, and will be auto-fixed on save.\n    Transcribing Indian English: Make any changes you need too!      Add In Open Captions Using the Auto-Overlay Functionality Now that we have our captions sorted out we add in Open Captions. Open Captions are recommended from both (a) accessibility considerations, and (b) increasing traction on social media.\n  Use the Action -\u0026gt; Auto-Overlay to add font Montserrat yellow text with size 30. This looks like below.\n    Transcribing Indian English: Add black colour text, size 30 with font Montserrat      We are also going to add a blue highlight.\n    Transcribing Indian English: Add a yellow highlight      All done - what do you think? Download the asset and deploy!\n  Transcribing Indian English: All done!\n     Conclusion Edit: We originally use the yellow test/blue highlight in the last section. This looked terrible on top of the pastel colouring of the video. So it was changed to black text/yellow highlight.\nIn another blog post we will translate the content into Hindi. And then get an AI to speak out the Hindi content. Stay tuned!\nPlease connect with us on LinkedIn, YouTube or Facebook for any comments, questions, or just to keep up to date with the work we do!\nWe are very grateful for your support!\nIf you are interested in trying out our technology, please try our platform or drop us an email at hello@videotranslator.ai.\n","permalink":"https://videotranslator.ai/news/transcribing-indian-english-a-simple-guide-to-using-ai-to-speed-up-transcription-and-add-open-captions/","tags":["English"],"title":"Transcribing Indian English: A Simple Guide To Using AI To Speed Up Transcription And Add Open Captions"},{"categories":["Video Translator","Enterprise","Weekly Roundup"],"contents":"It\u0026rsquo;s the start of a new month and news from around the globe keeps on rolling in. This week we\u0026rsquo;ve learnt the power of YouTube, its content creators and their followers and how they\u0026rsquo;re working together for the greater good. We also focus on the Western Australian Government\u0026rsquo;s foreign language road signs initiative that aims to save lives and we delve into the world of deepfake videos. Are they as dangerous as they seem? And what can we really believe?\n1. West Australian government installs foreign language signs on deadly tourist roads     Image courtesy of 9News    In effort to keep the roads safe for tourists and locals alike, the WA Government has begun to implement road signs in various languages. WA\u0026rsquo;s Indian Ocean Drive is a notorious hotspot for motor vehicle accidents with many of the people dying in these accidents being from European countries. \u0026ldquo;WA Transport minister Rita Saffioti said it\u0026rsquo;s about ensuring everything possible is being done to keep motorists safe\u0026hellip;Advisory signage with symbolic \u0026ldquo;keep left\u0026rdquo; arrows, and \u0026ldquo;keep left\u0026rdquo; spelled in German, French and Simplified Mandarin will be installed.\u0026rdquo; If proven successful, the signs will be installed in more popular tourist driven roads across Western Australia.\nRead more here\n2. Deepfakes: is seeing still believing? If you\u0026rsquo;re yet to witness deepfake videos, just know that when done correctly they are both highly convincing and at times very unnerving at just how real these videos seem. Watch this equally impressive and somewhat unsettling example here. In this new era of fake news and unable to believe everything we see and hear on the Internet, are deepfakes further proof of impending doom? This well-thought-out piece looks into just how dangerous deepfake videos are and what the legal implications could be (if any).\nRead more here\n3. \u0026lsquo;The largest YouTube collaboration ever\u0026rsquo; wants to plant 20 million trees     Image courtesy of Night Media    Youtube content creators are working towards the gargantuan goal of planting 20 million trees and looks like they may just make it happen. Influencer Destin Sandlin said, “Something needs to happen, so we\u0026rsquo;re just going to do it..We\u0026rsquo;re not going to wait for policies; we’re not going to wait for anything like that. We\u0026rsquo;re just going to do things because we know how, and we\u0026rsquo;re able to. But that being said, it\u0026rsquo;s not limited to the younger generation. This is everybody. We want no boundaries, no borders on this at all. It\u0026rsquo;s all ‘we and us,’ and we\u0026rsquo;re all planting trees, which is awesome.” For every dollar donated to the Arbor Day Foundation, one tree will be planted. At time of writing the #TeamTrees effort has raised $8 million USD with $1 million being donated by Elon Musk.\nRead more here\n4. The financial benefits of being bilingual One study has to lead to research that suggests that by being bilingual you are more likely to be less emotionally invested in your financial transactions. Conducted by Mustafa Karatas of Koç University in Turkey, the study had bilingual participants decided on the amount they\u0026rsquo;d sell an item for. When they were deciding on the amount in their native language, the price at which they would sell the item was significantly higher compared to those who were selling in their non-native language. It appears the psychological phenomenon known as the endowment effect (where a person who has an emotional investment in an item values it at a higher cost than a potential buyer), does not effect a person when they not interacting in their native language. Read more here\n5. 17 of the funniest movie title translations, from The Full Monty to Knocked Up     Image courtesy of The Mehan Group    The act of translation is amazing and at times downright hilarious, this fun article highlights 17 movie translation titles that will have you giggling. Favourites include Knocked Up being translated in Chinese as One Night Big Belly and Austin Powers: The Spy Who Shagged Me being translated to Austin Powers: The Spy Who Behaved Very Nicely Around Me in Malaysian. Special credit goes to the Chinese translation of The Sixth Sense which almost gives away the twist! (NB we\u0026rsquo;re not mentioning exactly what the twist is in case you still haven\u0026rsquo;t seen the movie. FYI it\u0026rsquo;s been 20 years! We\u0026rsquo;re being very kind to you!)\nRead more here\nConclusion Please connect with us on LinkedIn, YouTube or Facebook for any comments, questions, or just to keep up to date with the work we do!\nWe are very grateful for your support!\nThank you for reading this news item! We hope you found it interesting. Let us know at hello@videotranslator.ai!\n","permalink":"https://videotranslator.ai/news/the-weekly-roundup-05-nov-2019/","tags":["English"],"title":"Foreign signs installed to save lives, when seeing isn't believing, learning about deepfake videos and content creators coming together to save the planet!"},{"categories":["Video Translator","Enterprise","Weekly Roundup"],"contents":"Exciting news for content creators this week at Instagram\u0026rsquo;s IGTV releases features that will allow videos to viewed as a series. Google is releasing an on-device transcribing app that may be a game-changer, plus just because we loved it so; a video showing a deaf father signing to his newborn daughter, that has really hit us with all the feels.\n1. Pixel 4’s live transcription goes up against “real-life” challenges     Image courtesy of The Wall Street Journal    Google is a releasing a new built in app in their Pixel 4 and honestly, it\u0026rsquo;s very impressive. The app is able to transcribe audio in real time and without the need to be connected to wifi or data. It\u0026rsquo;s completely \u0026ldquo;on-device\u0026rdquo;. To test the capabilities of Recorder, The Wall Street Journal set it up against a stenographer as they listened and transcribed people with different accents and a Guinness World Record holder for fastest talker. We won\u0026rsquo;t ruin the results for you, so you\u0026rsquo;ll have to find out for yourself.\nRead more here\n2. IGTV Rolls Out Tools Enabling Creators To Publish Videos As An Episodic Series Instagram\u0026rsquo;s IGTV just upped it\u0026rsquo;s game as it rolled out features that will give creators the opportunity to release their videos in series form. \u0026ldquo;The update includes: the ability to turn on notifications for clips within an IGTV series; an organisational tool that will allow creators to add a series title badge to videos (so that they’re differentiated from standalone IGTV videos); and a ‘continued viewing’ feature, which will automatically play the next episode in a series after the previous instalment concludes.\u0026rdquo;\nRead more here\n3. Abhijit Banerjee delivers speech in Shuddh Bangla at MIT. Viral video is a blockbuster on Internet     Image courtesy of Scott Eisen/Getty Images    Nobel Prize winner, Abhijit Banerjee has delivered an acceptance speech partly in Shuddh Bangla at the Massachusetts Institute of Technology in Cambridge. Sharing it on his Facebook page radio announcer, Mirchi Agni has expressed his pride in seeing Shuddh Bangla being spoken amongst predominantly English speakers. Agni wrote, \u0026ldquo;Nobel laureate is addressing MIT in Bengali. Goosebumps, teary eyes and people whistling in the hall.\u0026rdquo; The video has gone viral in India as many others share in Agni\u0026rsquo;s pride for Banerjee and the language.\nRead more here\n4. Mozilla Adding Privacy-Focused Translation to Firefox Mozilla is joining the translation game as it announces it will be \u0026ldquo;adding an automatic page translation feature to its browser.\u0026rdquo; Unlike Chrome however, which sends the translated text to the cloud, Firefox will be keeping it client-side; which means it\u0026rsquo;s completely private. In a society that is now quite concerned when it comes to privacy (or lack thereof), this could be the upper hand that Mozilla is after. At the time of writing, there is no confirmed date of the release, but rest assured it is on its way.\nRead more here\n5. Love doesn\u0026rsquo;t need sound: Deaf man uses signs to talk with daughter, video warms hearts online     Image courtesy of Indian Express    This one proves that love is the universal language! A video has gone viral that shows a deaf father signing to his newborn daughter. She has his full attention as he signs to her, \u0026ldquo;Daddy. I’m your daddy. I love you. You’re a beautiful girl. Your eyes are such a beautiful colour, bright green! Just beautiful! What a cute smile! I love you. You’re a cutie. That’s a warm blanket. I love you. I love you. You’re beautiful. Cute.\u0026rdquo; If you haven\u0026rsquo;t seen it already, do yourself a favour and check it out. Meanwhile, we\u0026rsquo;ll be over here trying to figure out who\u0026rsquo;s cutting onions in the office\u0026hellip;\nRead more here\nConclusion Please connect with us on LinkedIn, YouTube or Facebook for any comments, questions, or just to keep up to date with the work we do!\nWe are very grateful for your support!\nIf you haven’t yet and are interested in trying out our technology, please try our platform, or drop us an email at hello@videotranslator.ai.\n","permalink":"https://videotranslator.ai/news/the-weekly-roundup-29-oct-2019/","tags":["English"],"title":"Google's latest Pixel 4 app impresses, praise for Nobel Prize winner and a feel-good video to brighten your week!"},{"categories":["Retail","Audio","Transcription","Dubbing","Dialects","Accessibility"],"contents":"Following on from last week\u0026rsquo;s blog post, where we looked at different English dialects, we are going to do much the same today in Dutch, French and German.\nDo you like the below examples? Let us know - we are super keen to hear what you think?\nTo try other languages (for FREE!) sign up to the free trial and give it a go!\nSteps   First, as per our usual create a new item using the English language template. We called our new item simpleA and it looks like below. All the action is going to happen in our Audio component shown below.\n    Samples From A Voice Over Robot: Click on the English template and add a new item      Use the audio component to add our seed, The quick brown fox jumps over the lazy dog as shown below.\n    Samples From A Voice Over Robot: Add the seed into the Audio component and Save      In the English dialect example, we transcribed directly. We do something different here, we translate first, and then use the AI dubbing.\n  Use the Action -\u0026gt; Translate to translate to Dutch, French and German. French is shown the process is the same for each of the languages.\n    Samples From A Voice Over Robot: Action -\u0026gt; Translate to French shown in the image      On completing this, your screen should look something like below.\n    Samples From A Voice Over Robot: New items are shown post translation      Each item will have the same content, except in the correct language.\n    Samples From A Voice Over Robot: After the English to German translation      Now use the the Action -\u0026gt; Transcribe: Text-To-Speech to create the synthetic dubbing's for all the items. The German and Dutch transcription menu\u0026rsquo;s are shown below. In the samples today, we used female voices.\n    Samples From A Voice Over Robot: Trigger the Text-To-Speech AI for the voice over in German        Samples From A Voice Over Robot: Trigger the Text-To-Speech AI for the voice over in Dutch      The below is the image for the French transcription menu. Be careful! There are two dialects here, French (Canada) and French (France). In the below, we have chosen Canadian French. Note: Because the seed is tiny, the French dialects sound pretty similar.\n    Samples From A Voice Over Robot: Trigger the Text-To-Speech AI for the voice over in Canadian French      Woohoo - all done. Do you want to hear what all the other AI voices sound like? Give our application a free trial today!\n  Samples Dutch Female 1   Sorry, your browser does not support the  tag.    Samples From A Voice Over Robot: Dutch Female - Professional   French Female 1 (Canadian)   Sorry, your browser does not support the  tag.    Samples From A Voice Over Robot: French (Canada) Female - Professional   French Female 1 (France)   Sorry, your browser does not support the  tag.    Samples From A Voice Over Robot: French (France) Female - Professional   German Female 1   Sorry, your browser does not support the  tag.    Samples From A Voice Over Robot: German Female - Professional   Conclusion In this visual guide, we used our video translator to translate and then dub a sample text fragment.\nWould you like to try this functionality? Send us some feedback if you do.\nPlease connect with us on LinkedIn, YouTube or Facebook for any comments, questions, or just to keep up to date with the work we do!\nWe are very grateful for your support!\nIf you are interested in trying out our technology, please try our platform or drop us an email at hello@videotranslator.ai.\n","permalink":"https://videotranslator.ai/news/samples-from-a-voice-over-robot-french-german-and-dutch/","tags":["English","French","German","Dutch"],"title":"Samples From A Voice Over Robot: French, German and Dutch"},{"categories":["Retail","Audio","Transcription","Dubbing","Video Dubbing","Dialects","Accessibility"],"contents":"Today we are going to look AI dubbing and look at a few different samples of what an AI can sound like in English. We are going to do something pretty simple, we will use the quick brown fox jumps over the lazy dog for our seed text.\nIf you don\u0026rsquo;t know what this sentence is, quoting from Wikipedia, \u0026ldquo;The quick brown fox jumps over the lazy dog\u0026rdquo; is an English-language pangram—a sentence that contains all of the letters of the alphabet. It is commonly used for touch-typing practice, testing typewriters and computer keyboards, displaying examples of fonts, and other applications involving text where the use of all letters in the alphabet is desired. Owing to its brevity and coherence, it has become widely known.\nSo we are going to use it as a simple sample and use our AI to speak (text-to-speech AI) this sentence out and listen to the differences.\nA few of the English dialects are provided below. To try the others (for FREE!) sign up to the free trial and give it a go!\nSteps   First, as per our usual create a new item using the English language template. We called our new item simple3 and it looks like below. All the action is going to happen in our Audio component shown below.\n    AI Dubbing: Select the English Template and create and new Item      Use the add caption to add a caption, The quick brown fox jumps over the lazy dog. This is shown below. Then click the save button.\n    AI Dubbing: Add the test string into the caption      Note that normally this would come from the video transcription, but we are just putting in the text and getting the AI to speak it out.\n  Nice! Now, we are going to use the Action -\u0026gt; Transcribe -\u0026gt; Text-To-Speech as shown below.\n    AI Dubbing: Select your preferred voice to speak out the text fragment      What is happening here? The S/P designation refers to Standard / Professional. The F/M refers to Female / Male, and the country code refers to the accent.\n  This is essentially the entire process, pick a dialect and click Accept to trigger the Text-To-Speech AI.\nSamples   English (Australian) Female\n  Sorry, your browser does not support the  tag.    AI Dubbing: Australian English Female - Professional     English (Australian) Male\n  Sorry, your browser does not support the  tag.    AI Dubbing: Australian English Male - Professional     English (India) Female\n  Sorry, your browser does not support the  tag.    AI Dubbing: Indian English Female - Professional     English (India) Male\n  Sorry, your browser does not support the  tag.    AI Dubbing: Indian English Male - Professional     Are you keen to hear more? Would you like to hear how an English (UK) or English (US) AI sounds? Well - go on then, give the video translator a shot!\nConclusion In this visual guide, we used our video translator to dub a sample text fragment.\nWould you like to try this functionality? Send us some feedback if you do.\nIf you are interested in trying out our technology, please try our platform or drop us an email at hello@videotranslator.ai.\nPlease connect with us on LinkedIn, YouTube or Facebook for any comments, questions, or just to keep up to date with the work we do!\n","permalink":"https://videotranslator.ai/news/ai-dubbing-what-different-dialects-of-english-sound-like/","tags":["English"],"title":"AI Dubbing: What Different Dialects Of English Sound Like"},{"categories":["Video Translator","Enterprise","Weekly Roundup"],"contents":"It\u0026rsquo;s another big week in AI news, from assisting in search and rescue methods to aiding doctors in detecting brain bleeds, it\u0026rsquo;s being proven time and time again how Artificial Intelligence can help humanity in meaningful ways. We also see that AI is helping historians create a portal into the past of Europe and creating virtual worlds that we can experience. In other news, one woman is advocating for more support and resources for translators in domestic violence cases and one author and translator explains her love for language and translation.\n1. Walking through time: how AI is rebuilding centuries-old Europe     Forget the DeLorean, AI is making time travel possible    Europe is renowned for its diverse, centuries-long history and culture and now AI is helping us to travel back in time to experience the European days of old. Experts including computer scientists and historians have gathered in Dresden, Germany to discuss how best to use AI to document Europes expansive history. Virtual worlds is at the top of their list. AI will have the arduous task of transcribing documents that will in turn show us just how Europeans lived in the past. Virtual worlds built upon this data, will allow us to experience how cities and towns looked in various years over time.\nRead more here\n2. Australian court interpreters working with domestic violence survivors call for more support Interpreters are vital in domestic violence cases for non-English speakers in Australia and yet there is a lack of resources in the legal system. Interpreter for the legal sector, Liana Papoutsis says that the lack of interpreters for domestic violence cases can be somewhat attributed to the impact the cases have on the interpreters. \u0026ldquo;Interpreters have been traumatised by family violence details, and\u0026hellip;many will avoid family violence matters, whether it is for a family violence intervention order, or breaches, which move the matter from the civil to the criminal,\u0026rdquo; she said. She is urging for services to be put in place to ensure that interpreters get the support they need during and after difficult cases. This will hopefully, in turn encourage interpreters to take on domestic violence cases, where they are very much needed.\nRead more here\n3. Artificial intelligence to enhance Aussie search and rescue capabilities     AI assisted search and rescue will aid the ADF and many SAR teams Australia wide    Australian search and rescue teams have it tough. Trying to find people in water, bushland and desert is a daunting and taxing job and \u0026ldquo;has largely been done in the same way for a hundred years – using unaided visual search to find objects.\u0026rdquo;\nThe Australian Defence Force (ADF) is now using and AI system that will change the way search and rescue teams are able to, well, search and rescue. The ADF \u0026ldquo;enlisted the help of budding AI guru, Lieutenant Harry Hubbert, Warfare Innovation Navy Branch. We gave Harry a challenge – find an orange hull, in a large body of water, using AI, and do it in a month. Harry developed the algorithms in his own time within two weeks.\u0026rdquo;\nRead more here\n4. So you want my arts job: literary translator \u0026ldquo;I resisted the call of literary translation for years, despite it being the perfect marriage of my interests, because I thought that I wouldn’t be able to feed myself if I had two vocations (writing and literary translation). Then I read Claudia Salazar Jiménez’s La sangre de la aurora and wanted to press it into the hands of everyone I knew.\u0026rdquo; This thought-provoking piece featuring author and translator, Elizabeth Byer tells us how she got into the world of translating and why. For any budding translators out there, the interview goes into detail about how to get started, useful resources and just what is so magical about being able to retell a story from one language to another.\nRead more here\n5. Doctors could team up with AI to spot dangerous brain bleeds faster     Easier and quicker detection in brain injuries and trauma could be potentially lifesaving    Brain bleeds, head injuries and strokes can be particularly hard to detect and diagnose, which can lead to life-altering or ending circumstances. A team at the University of California, San Francisco are developing AI software that will assist doctors in determining the diagnoses of such cases. The software, called PatchFCN is able to \u0026ldquo;interpret CT scans of heads\u0026rdquo;, which at times can be somewhat more difficult for doctors who are trying to find a tiny area in the brain from just a scanned image. While the AI will not be replacing specialised doctors, the hope is for it to be able to help the doctors make diagnoses quicker and easier, resulting in potentially lifesaving outcomes.\nRead more here\nConclusion Please connect with us on LinkedIn, YouTube or Facebook for any comments, questions, or just to keep up to date with the work we do!\nWe are very grateful for your support!\nIf you haven’t yet and are interested in trying out our technology, please try our platform, or drop us an email at hello@videotranslator.ai.\n","permalink":"https://videotranslator.ai/news/the-weekly-roundup-22-oct-2019/","tags":["English"],"title":"Travelling back in time with AI, learning the love of translation and why it is imperative to get more interpreters in courthouses!"},{"categories":["Retail","Audio","Transcription","Translation","Dubbing","Video","Visual Guides"],"contents":"We get a number of questions around AI Accuracy, and depending on the context, the question can refer to a number of things.\nWanted to put down a note describing the various iterations of what Accuracy in Artificial Intelligence refers to, and where it is going from my point of view.\n Is the AI accurate? Is AI accurate when it comes to Transcription? Is AI accurate when it comes to Translation? If I use AI for Text-To-Speech Dubbing, will it sound natural?  Lets look at these ideas one at a time.\nIs The Artificial Intelligence Accurate? When Is Artificial Intelligence Not Accurate? Answer: It depends.\nLets talk about where Artificial Intelligence / Machine Learning came from - both of these technologies were originally known as Big Compute and/or Big Data. While referring to the field in this form is no longer useful, its super useful to think about the field in these terms.\nUsing vast amounts of computing power on large databases set the stage for the advent of AI. The way to think about AI is pattern discovery at scale (@petertboyer). The pattern discovery and/or matching is essentially statistics and this is what data scientists spend their time doing.\nFailure in AI - that is, when the AI gets stuff wrong - can be due to a number of issues. The simplest kind of error to diagnose is probably the over-fitting problem, where the statistical model behind the AI is tweaked so much, there is no room for small deviations.\nThe more general mode of AI failure is the AI does not have a large enough data set to be trained properly. The reason we refer to this as a more general failure mode, is if the event we are trying to pick up has not happened before, there is little chance the AI will pick it up.\nThere are several other failure modes for AI, but we will be looking at the more general failure mode as described above.\nIs AI Accurate When It Comes To Transcription? Answer: It depends, pro-tip: pretty much all the answers here are going to be some variant of it depends :)\nUntil fairly recently, dialects were less studied by linguists. This is because the tools to truly understand dialects did not exist.\nLargely, this has changed due to Google and the other big technology players. Now, due to low costs of data storage, we are able to store and analyse large amounts of audio/video content.\nWithin the Video Translator application, we have a one-to-many language-to-dialect mapping.\nIn the case of Spanish for example, we have a number of dialects. Using the correct dialect is vital for AI accuracy. Similarly, we have a large number of English dialects too - our latest is English (Singapore).\n    AI Transcription, Translation And Dubbing: Several Spanish dialects are available.    Use the correct AI for the correct speaker. What if your content has multiple speakers? Right now, read this to understand how to compensate - but it is absolutely a problem we are working on and think some very exciting things are possible in the future.\nIs AI Accurate When It Comes To Translation? Answer: It can be very accurate. Lets be clear - AI when used for translation is normally a bit meh. Here is how we recommend you play it.\n  Assuming you did a AI transcription first, that is - you used an AI to do a Speech-To-Text conversion, you need to clean up the grammar. This process is known as post-editing.\n  Humans are smart, so in a conversation, we know when a comma, or full-stop, would be appropriate. In addition, a large amount (possibly even a majority) of communication is not related to words. It can come from tone, hand gestures or even facial gestures.\n  All of this communication is not visible to an AI. Hence, fix up the grammar and check your transcription.\n  Remember: Use the AI for the heavy lifting, and use your own Human translators for the high value tasks of cleaning up the AI\u0026rsquo;s work. Practically, this means thinking deeply about the intended audience, and what concepts they are familar with, and plugging that gap.\nIf I Use The AI For Text-To-Speech Dubbing, Will It Sound Natural? Answer: Yes - but this depends on what you are trying to achieve. Two examples might be useful here:\n  For our healthcare clients, the use case is often the video is aimed at possible low literacy/exposure stakeholders. Practically this means we may take some AI generated dubbed speech, and slow it down up to 85% of the original. Note, this is specifically because we are trying to reach people who may not be literate.\n  For elderly clients, we sometimes change the dialect. For example, an elderly man of Indian descent may speak English perfectly, but has trouble understanding Australian English (or vice versa). In this case we might slow the AI down 5%, but it is the changing of dialect which becomes magic. For a visual guide read this.\n  Remember: Think deeply about your target audience. There is no such thing as translation quality, there is only - did my target audience understand? It is perfectly valid to loose information content, if context is preserved. Indeed, people are very good at working out what someone else is saying, as long as both are on the same page.\nConclusion In this blog post we looked at some of the different ways in which AI Accruacy can be thought of - while we do not have all the answers, we hope the above is useful for you.\nThe way to think of Video Translator - strategy and discretion across your translation life cycle. Use our app if you think it make sense! Send us some feedback if you do.\nIf you are interested in trying out our technology, please try our platform or drop us an email at hello@videotranslator.ai.\nPlease connect with us on LinkedIn, YouTube or Facebook for any comments, questions, or just to keep up to date with the work we do!\n","permalink":"https://videotranslator.ai/news/ai-transcription-translation-and-dubbing-how-to-think-about-accuracy/","tags":["English"],"title":"AI Transcription, Translation And Dubbing: How To Think About Accuracy"},{"categories":["Retail","Audio","Transcription","Video","Visual Guides"],"contents":"Today we are going to look AI dubbing and its various use cases. If you are wondering, is my content suitable for AI dubbing, or AI localisation? In simple terms:\n What is dubbing or dub localisation? Should I use a human, or a machine for my dubbing? How do I use a video translator to dub my video? Rules of thumb, or heuristics, to achieve a superior outcome with AI dubbing?  On reviewing this visual guide, you will be able to (1) upload your own video content, (2) transcribe your content, (3) dub your content into a different dialect.\nNote: We are going to take a video in Australian English, and switch it into American English. Obviously, the usual use case is to translate into some other language first, and then do the dubbing. We forego the translation so this guide is easier to understand.\nBasics From Wikipedia, \u0026lsquo;Dubbing, mixing, or re-recording is a post-production process used in film making and video production in which additional or supplementary recordings are \u0026ldquo;mixed\u0026rdquo; with original production sound to create the finished soundtrack.\u0026rsquo;\nIn everyday usage however, the term 'dubbing' commonly refers to the replacement of the actor's voices with those of different performers speaking another language, which is called 're-voicing', or a 'voice-over' in the film industry.\nOutcomes - Before And After To make it obvious what we are talking about, the after is provided.\n  AI Dubbing: After Adding the AI voice-over\n   Steps - Transcribe Your Content Using The Provided AI   We are working with an English video today, so select the English template, and create a new item. Note that the account we are using to show this functionality has Chinese, French and Vietnamese as translation options. We will not be using this functionality today.\n    AI Dubbing: Select the English Template and create and new Item      This is the original content.\n  AI Dubbing: Before Adding the AI voice-over\n     We know the speaker is an Australian so we select English (Australia) as the preferred dialect to transcribe with - note picking the correct dialect makes AI accuracy much better.\n    AI Dubbing: Use Action -\u0026gt; Transcribe and then select Australian English      Once transcription is complete, use the Picture-In-Picture to clean up the transcript. Note that the text shown in the PIP is real time, so you can edit both timestamps/text of the transcript and see the changes directly.\n  You can see we removed text fragment 9 and merged it into text fragment 8 as an example. This makes no difference to the rendering of the captions. Use the Auto-Index button to fix this up if you require your *.srt to work properly.\n    AI Dubbing: Use the Picture-In-Picture to clean up the transcript      Save your changes and your transcription is complete. If you need the captions burnt into the asset, use the Auto-Overlay. Nicely done!\n  Steps - Dubbing/Adding A Voice Over With AI   To dub the content using a different voice, our first step is to copy the captions from our video component into our audio component. Click into your editor, and hit Ctrl-A and Ctrl-C.\n    AI Dubbing: Select the captions and copy using Ctrl-A and Ctrl-C      Go to the Audio component, click add captions and paste your content. Use the highlighted button to add captions without adding an audio file.\n    AI Dubbing: Go to an Audio component, and paste your captions there using Ctrl-V      We will transcribe again this time using the Text-To-Speech Transcription AI. In the below image, we use the Text-To-Speech tab. It is also possible to break up your captions into fragments, as shown below. We will only use the first fragment, but you can break your content to produce different *.mp3 files.\n    AI Dubbing: Use the Speech-To-Text AI to speak out your content      A few quick notes. The options shown are the different voices, with (M) for Male and (F) for Female. The accent can also be seen and we are using English (US) (M) which is American English Male. The S/P indicates Standard, or Professional - we recommend Professional, Standard is simply an older technology (sounds more robotic). Once done, it looks like below.\n    AI Dubbing: Audio component after text-to-speech transcription      The audio content is below. Have a listen! Sweet - dubbing is complete.\n   Steps - Overlaying Our Audio On Our Video   We are now going to add our generated audio to our original video. Go back to your video component, and click on Audio Overlays. Click the + and your audio fragment will be shown.\n    AI Dubbing: Add the AI speech using Audio Overlay      Notice, we have not set any times. Add (in seconds) the time. We added 0.5 and 21 as start and end times, and then clicked the + button to bake in the audio overlay. That is the entire process. The final output is shown below.\n  AI Dubbing: After Adding the AI voice-over\n     Conclusion In this visual guide, we used our video translator to dub, or overlay a different voice, on our video. It should be noted, that most clients prefer to download assets and do the last, audio overlay step themselves. But you can use our app if you think it make sense! Send us some feedback if you do.\nPlease connect with us on LinkedIn, YouTube or Facebook for any comments, questions, or just to keep up to date with the work we do!\nWe are very grateful for your support!\nIf you are interested in trying out our technology, please try our platform or drop us an email at hello@videotranslator.ai.\n","permalink":"https://videotranslator.ai/news/text-to-speech-ai-dubbing-and-what-you-can-do-with-it/","tags":["English"],"title":"Text-To-Speech: AI Dubbing And What You Can Do With It"},{"categories":["Video Translator","Enterprise","Engineering"],"contents":"More than just cute little stinkers, babies are exceptional learners, so good in fact that we\u0026rsquo;re trying to simulate their learning process to assist AI in becoming evermore smarter. Our first article details just how babies learn and what they\u0026rsquo;re doing to make AI do the same. Plus, machine learning is helping us prepare and respond to natural disasters and an app is now available to help content creators reach their target market, with the click of a button.\n1. The Ultimate Learning Machines     The best learners in the universe come in a cute and tiny package    They may appear to have no clue about the world around them, but \u0026ldquo;human babies are the best learners in the universe. How do they do it? And could we get AI to do the same?\u0026rdquo; That is the question that professor of psychology, Alison Gopnik is pondering as she and a team of computer scientists look at understanding how babies learn; and how they can teach AI to learn the same way. Teaching AIs how to process data and learn from that is one thing, giving them the ability to adapt and learn in a messier and more complex way is another.\nRead more here\n2. Why Machine Learning Is Critical for Disaster Response As unfortunate as it is, natural disasters are a common occurence and arguably taking place more often as the years go by. So, what can we do about it? While that answer is better suited for another time and place (and possibly a whole thesis written on the subject), we can look at how to manage ourselves and our surrounds when these disasters take place. Machine learning is now being used to help better forecast when natural disasters may take place and how we can be better prepared for them.\nRead more here\n3. These AR Smart Glasses Could Be the Future of Multilingual Live Translation     Image courtesy of Zoi Meet    It\u0026rsquo;s all about effectice communication in the business world and easier translation means easier transactions. The Zoi Meet app transcribes a persons speech automatically into text for a person wearing specific AR glasses. Available on the Vuzix Blade Smart Glasses, the app is aimed at businesses holding international and multilingual meetings.\nWe\u0026rsquo;re hoping these have a much higher success rate than Google Glass did.\nRead more here\n4. An app for content creators looking to connect with the right audience Many of us know the struggle of creating content online, wanting to share it with the world and realising we\u0026rsquo;re not reaching the audience we\u0026rsquo;d hoped to. Enter Joynt, an app developed to allow content creators to interact and share with their target audience. Joynt allows you to create closed and secure groups with fans and followers, which in turn gives your followers exclusive access to your projects. There is the option to monetise content, meaning that as a content creator, you\u0026rsquo;re not only reaching your target audience but making money from it too.\nRead more here\n5. Artificial intelligence helps track sharks in the ocean     AI helping to keep track of sharks near California beaches    With summer almost here, this development is crucial for those of us who love to be in the ocean. With the help of AI software, drones in California are being used to monitor and track the whereabouts of sharks in the water, to help protect both us and them from getting into any Jaws-like altercations.\nThe AI has been trained to know what a number of different large shark species look like, which means they can tell the difference between shark species. It can also differentiate between sharks of the same species, meaning Bruce won\u0026rsquo;t get counted twice.\nAn app is available for life guards so they know how many (if any) sharks are lurking about at any given time of day.\nRead more here\nConclusion Please connect with us on LinkedIn, YouTube or Facebook for any comments, questions, or just to keep up to date with the work we do!\nWe are very grateful for your support!\nIf you haven’t yet and are interested in trying out our technology, please try our platform, or drop us an email at hello@videotranslator.ai.\n","permalink":"https://videotranslator.ai/news/the-weekly-roundup-15-oct-2019/","tags":["English"],"title":"Babies teaching us how best to teach AI, glasses made for translation and keeping an eye on our giant fishy friends with AI!"},{"categories":["Retail","Video Translator","Enterprise","Accessibility","Visual Guides","Management"],"contents":"It comes as no surprise that for hard of hearing and deaf people, closed captions are a necessity for being able to watch TV, films and online videos. We\u0026rsquo;ve mentioned before the need for more captions and subtitles to be present in cinemas and as highlighted in this Washington Post article, \u0026ldquo;accessing online material\u0026hellip;can be a challenge for differently abled people.\u0026rdquo;\nThis is one of the reasons we believe it is so important to include open captions in online videos. In a world that is not built for differently abled people, we\u0026rsquo;re hoping that we can make a slight difference. So, how can we (and you!) make that difference? By adding captions and using our Auto-Overlay capabilities to your video.\nHow do you do this? We\u0026rsquo;re so glad you asked! First of all, if you\u0026rsquo;d like to know the technical side of creating and using captions in your videos, read this article first. Now that you\u0026rsquo;re all up to date, it\u0026rsquo;s time to add captions to your content.\nUpload And Transcribe   Upload your video into our video translator application. If you are unsure how to do that, this article will help.\n  Next, select Transcribe from the drop down menu as seen in the image below.\n    Transcribe your video      Make sure you select the right dialect! This helps the AI to correctly transcribe the audio into text. Just remember that the AI can and will make errors, so be sure to check that the captions are all good when transcription is complete.\n    Choose the correct dialect      Once you\u0026rsquo;re happy with your captions, use Auto-Overlay to programmatically add the captions. You\u0026rsquo;ll see in the below image that we\u0026rsquo;ve chosen a yellow text with blue highlight, but feel free to choose the colours that work best for you and your audience.\n    Use our Auto-Overlay feature      And that\u0026rsquo;s it! Now you are ready to go, knowing that you\u0026rsquo;re making someone\u0026rsquo;s day who otherwise, may not have been able to view your video. Well done!\n  Conclusion Please connect with us on LinkedIn, YouTube or Facebook for any comments, questions, or just to keep up to date with the work we do!\nWe are very grateful for your support!\nIf you haven\u0026rsquo;t already and are interested in trying out our technology, please try our platform, or drop us an email at hello@videotranslator.ai.\n","permalink":"https://videotranslator.ai/news/importance-of-open-captions/","tags":["English"],"title":"The Importance of Open Captions for Deaf and Hard of Hearing People"},{"categories":["Video Translator","Enterprise","Weekly Roundup"],"contents":"The art of translation has been a skilled required by humans for over 2000 years, we\u0026rsquo;ve got a few interesting articles that highlight just how important it is and one translator shares with us what she\u0026rsquo;s learnt after being in the business for 20 years. We\u0026rsquo;re also looking at how machine learning is aiding scientists in researching plants, AI writers writing as well as humans can, and we celebrate as Armenia hosts the first ever AI concert.\n1. Pocket Babel: How translation tech and devices are changing business     Sourcenext\u0026#39;s Pocketalk    Japan is often at the forefront of leading technology and it\u0026rsquo;s no different when it comes to translation devices. Despite smartphone apps having similar abilities to these pocket translators; there is a surge of demand for them in Japan for both personal and work use. Smarter and more accurate than a lot of smartphone translation apps, the translation devices are allowing people to have multilingual conversations all across the country.\nRead more here\n2. Hey Siri, write me a book: Turing’s Imitation Game is AI’s highest form of flattery – and it’s writing its own story Alan Turing was questioning whether computers could be intelligent enough to communicate in a way that was indistinguishable from humans back in 1950; now we know the answer. AI is now writing ads and articles that are just as creative and well-written as those written by humans. Could this illiminate the need for human writers and authors? (This writer hopes not\u0026hellip;)\nRead more here\n3. Machine learning helps plant science turn over a new leaf     Machine learning is assisting in important plant research    3D laser scanning is being used by scientists to assist the work in identifying and studying plants and now machine learning tools are making the job all the more easier.\n\u0026ldquo;You give them (the AI software) examples of what a leaf looks like and what a branch looks like, and eventually they can identify a plant they\u0026rsquo;ve never seen before and pick out the leaves and branches.\u0026rdquo; The program then takes measurements to assist in scientific research.\nRead more here\n4. World\u0026rsquo;s First AI Concert Opens WCIT 2019 in Yerevan, Armenia Hosting the 23rd World Conference on Information Technology in Yerevan, Armenia; the World Information Technology \u0026amp; Services Alliance (WCIT) has produced a world first in both the music and AI worlds.\nAs a part of the conferences opening ceremony, WCIT presented a concert that comprised of AI composed music that was performed by the Armenian State Symphony Orchestra.\n\u0026ldquo;This is the first time that symphonic music was composed in real-time by AI technology and performed live by an orchestra of live human musicians.\u0026rdquo;\nRead more here\n5. Translation: 20 things in 20 years     A lot is learned after 20 years as a translator    Translator, Kim Sanderson has given us a list of wisdom after 20 years in the translation game. One particularly interesting point is \u0026ldquo;it\u0026rsquo;s not just about the words - we translate meaning.\u0026rdquo;\nWe find this to be the case when using our Video Translator app too. Using AI to do all the heavy lifting for you, i.e. actually translating your project, it is still necessary for a person to add the final touches to the text. This means that you save time on the task of translating and can focus on adding meaning to your video. Giving you the ability to get across your message the way you want, in the language you want.\n    Video Translator\u0026#39;s Picture in Picture editing tool helps you to translate and convey meaning to your project    Read more here\nConclusion Please connect with us on LinkedIn, YouTube or Facebook for any comments, questions, or just to keep up to date with the work we do!\nWe are very grateful for your support!\nIf you haven’t yet and are interested in trying out our technology, please try our platform, or drop us an email at hello@videotranslator.ai.\n","permalink":"https://videotranslator.ai/news/the-weekly-roundup-08-oct-2019/","tags":["English"],"title":"Translation devices changing the business game, machine learning aiding scientific research and a world first AI concert!"},{"categories":["Retail","Video","Transcription","Translation","Visual Guides","Languages"],"contents":"Este video pertenece al canal de YouTube Mariel de Viaje.\nEl video ofrece consejos básicos para afrontar con facilidad, comodidad y familiaridad cualquier viaje en plan turístico a la República Dominicana, e incluye sugerencias para visitar lugares emblemáticos como Punta Cana y Santo Domingo.\nLa República Dominicana es el segundo país más grande y diverso del Caribe. Cuenta con vuelos directos desde las principales ciudades de Latinoamérica, Estados Unidos, Canadá y Europa, es un país que se destaca por la calidez de su clima y la hospitalidad de su gente. República Dominicana es un destino sin igual que cuenta con una naturaleza extraordinaria, fascinante historia y gran riqueza cultural.\nRodeada por el Océano Atlántico hacia el Norte y el Mar Caribe hacia el Sur, República Dominicana se enorgullece de contar con más de 1,600 Km. de costa y 400 Km. de las mejores playas del mundo, magníficos hoteles y resorts, e infinidad de opciones en deportes, entretenimiento y recreación. Aquí podrás bailar al ritmo contagioso del merengue, renovarte en lujosos y variados hoteles, explorar antiguas ruinas, deleitarte con la mejor gastronomía local, o vivir aventuras ecoturísticas en sus magníficos parques naturales, cordilleras, ríos y playas.\nPasos A Seguir   Abre tu navegador y dirígete a https://videotranslator.ai/ luego, haz click en el botón Login, tras iniciar sesión correctamente ve a es_myTemplate (para traducir un video cuyo audio de origen es en Español) y selecciona New Item, este ítem será llamado RD porque el video en cuestión habla sobre la República Dominicana.\n    Seleccionar nuevo artículo        Guardar artículo como RD y enviar      Carga el video, espera que sea procesado y activa la acción de transcripción. La presentadora es mexicana así que seleccionaremos Español (México) como idioma principal.\n    Seleccione el dialecto español apropiado      Espere mientras se ejecuta el procesamiento y transcripción del video.\n    El artículo se cerrará durante el proceso de transcripción      Una vez transcrito el vídeo, debes revisar la transcripción, ya que a veces nuestra inteligencia artificial puede omitir letras mayúsculas, puntos o comas en algunas oraciones. Esto se debe a que, como todos sabemos, las personas no hablan del mismo modo en que se escribe, por tanto, necesitamos hacer que el contenido transcrito tenga sentido para la inteligencia artificial encargada de hacer la traducción.\n    Verifique y corrija cualquier gramática de transcripción      Incrustamos los subtítulos en el video para obtener nuestro primer resultado, el vídeo con los subtítulos en su idioma original.\n    IIncruste subtítulos en video en idioma original      Una vez realizada la limpieza y todas las correcciones correspondientes a la transcripción, procedemos a iniciar el proceso de traducción de los subtítulos obtenidos en el paso anterior.\n    Comience el proceso de traducción      Luego, tendrás que esperar a que la inteligencia artificial encargada de la traducción del contenido haga su trabajo, según lo solicita el sistema.\n    El artículo se cerrará durante el proceso de traducción      Luego de completar el proceso de traducción, checa la traducción para hacer la limpieza y correcciones necesarias.\n    Verifique la traducción para cualquier corrección gramatical      Una vez ha sido corregida la traducción, podemos incluir los subtítulos traducidos en el video seleccionando la opción Auto-Overlay y aplicando las configuraciones que creas necesarias para personalizar tus subtítulos, aplicarles fondos o efectos de tachado, entre otros.\n    Seleccionar superposición automática        Personaliza subtítulos      Y luego, esperamos a que nuestro video sea procesado para que le sean agregados los atributos que seleccionamos para nuestro video.\n    El artículo se cerrará durante el proceso de superposición automática      Tu video, transcrito y traducido, y subtitulado con atributos especiales está listo.\n    Tu video esta listo      Tips Para Viajar A República Dominicana\n     Muchas gracias por tomarte el tiempo de leer este tutorial “Transcripción y Traducción de Videos de Español a Inglés: Tips Para Viajar A República Dominicana”\n  Conclusión:\nEn este tutorial, hemos transcrito, y posteriormente traducido un video del canal de YouTube Mariel de Viaje, del español al inglés. Logramos esto, transcribiendo el video en español, luego traduciendo los subtítulos al inglés, y finalmente incrustando el contenido de los subtítulos en el video usando la función “Auto-Overlay.”\nEn caso de querer publicar dicho contenido traducido en línea, te recomendamos traducir al inglés también el título, la descripción y otros metadatos en el script final. Esto mejorará tu SEO en inglés, permitiendo a los angloparlantes nativos encontrar tu contenido en línea con mayor facilidad.\nVideo Translator no tiene relación alguna con el canal Mariel de Viaje en YouTube. Usamos contenido públicamente disponible para demostrar un caso de uso interesante de nuestra plataforma.\nSi estás interesado en usar nuestra tecnología, por favor, prueba nuestra plataforma o envíanos un correo electrónico a: hello@videotranslator.ai\n","permalink":"https://videotranslator.ai/news/transcripci%C3%B3n-y-traducci%C3%B3n-de-videos-de-espa%C3%B1ol-a-ingl%C3%A9s/","tags":["Spanish","English"],"title":"Transcripción y Traducción de Videos de Español a Inglés"},{"categories":["Video Translator","Enterprise","Weekly Roundup"],"contents":"There\u0026rsquo;s been a lot going on with AI in particular this week. Read on to get up to date on some of the most interesting things coming out of the world of Artificial Intelligence. There\u0026rsquo;s also top ranking machine learning systems and earbuds that can translate languages as you\u0026rsquo;re hearing them.\n1. Yes Bank creates \u0026lsquo;Yes Robot\u0026rsquo; using Microsoft Cognitive Services     Yes Robot    A bank in India has created AI assistant, \u0026lsquo;Yes Robot\u0026rsquo; to provide 24 hour customer service to its patrons. Chief digital officer at Yes Bank, Ritesh Pai said that \u0026ldquo;increasing use of Yes Robot has taken a significant load from customer service teams and resulted in improved levels of customer satisfaction.\u0026rdquo;\nRead more here\n2. Artificial intelligence will lead to creation of 133 million jobs around the world, says report Many worry about the development in AI and the negative effects it could have on humanity, but the latest report is showing us it\u0026rsquo;s not at all doom and gloom. AI-influenced jobs are already in demand and the need for these skills are continuing to grow globally.\nRead more here\n3. These wireless earbuds can translate languages as you hear them     Aunu Audio M50 headphones    \u0026ldquo;Parlez-vous anglais?\u0026rdquo; Gone are the days of wandering around a foreign country looking for someone who speaks your language. These earbuds by Aunu Audio, translate over 30 different languages so that you can understand what people are saying, as they\u0026rsquo;re saying it.\nRead more here\n4. 10 ways AI and machine learning are improving endpoint security AI and machine learning for the win! This time in combating against cyber attacks and detecting and stopping malware attacks.\nRead more here\n5. Google AI\u0026rsquo;s ALBERT claims top spot in multiple NLP performance benchmarks     Google\u0026#39;s ALBERT is at the top of its game    Leave it to Google to create start-of-the-art technology. This time it\u0026rsquo;s ALBERT, an AI that has ranked first place on NLP leader-boards such as GLUE and SQuAD 2.0. The model achieves results in testing that outperforms human capability.\nConclusion Please connect with us on LinkedIn, YouTube or Facebook for any comments, questions, or just to keep up to date with the work we do!\nWe are very grateful for your support!\nIf you haven’t yet and are interested in trying out our technology, please try our platform, or drop us an email at hello@videotranslator.ai.\n","permalink":"https://videotranslator.ai/news/the-weekly-roundup-01-oct-2019/","tags":["English"],"title":"AI is here to help; translation at the tip of your ears; and Google's ALBERT is receiving top ranks"},{"categories":["Engineering","Video Translator","Video Translation","Support","Patch Notes","Accessibility"],"contents":"It\u0026rsquo;s been a busy month for us so far. There\u0026rsquo;s a lot of new and exciting features we\u0026rsquo;re still developing so watch this space! In the meantime, there are a couple of updates and patches to tell you about.\nEmbedding Captions Previously, to embed captions onto your video it was possible to do so from the captions tab. This tab is now only used to make edits to the captions. To embed captions, it is now done by using the Audio Overlay tab. There you\u0026rsquo;ll find the + button as highlighted in the below picture, which will allow you to embed the captions.\n    Use Audio Overlay to embed captions    Picture in Picture A feature we\u0026rsquo;re quite excited about, picture in picture is now available to use with the video player. This allows you to make real time edits to the captions and simultaneously see how those edits look on the video.\n    The picture in picture feature makes editing videos easy    Working Symbol Previously, it was hard to tell when the app was working and making changes to your video. We\u0026rsquo;ve now added a spinning hourglass to show when your file is being worked on.\n    The spinning hourglass lets you know when the app is working on your video    New Dialects Added We\u0026rsquo;re proud to announce another six dialects have been added! From now on you can add the following dialects to your videos:\nEnglish:\n Singapore  Norwegian Bokmål:\n Norway  Swahili:\n Tanzania  Tamil:\n Singapore Sri Lanka Malaysia  Conclusion Please connect with us on LinkedIn, YouTube or Facebook for any comments, questions, or just to keep up to date with the work we do!\nWe are very grateful for your support!\nIf you haven\u0026rsquo;t yet and are interested in trying out our technology, please try our platform, or drop us an email at hello@videotranslator.ai.\n","permalink":"https://videotranslator.ai/news/patch-notes-september-2019/","tags":["English"],"title":"Patch Notes: September 2019"},{"categories":["Video Translator","Enterprise","Engineering"],"contents":"Welcome to the Weekly Roundup!\nEach week we put together a list of articles featuring some of the most interesting ideas and news in the field. This week we take a look at how AI tools are helping to transform Indian healthcare, machine learning is being used to create new music, plus much more.\nRead on to find out what\u0026rsquo;s been going on in the past week.\n1. Why one media buyer is embracing programmatic linear TV Linear television can be a tough nut to crack when it comes to advertising and brand reach, but Global director of media strategy at PHD Media, Nick Vernola believes new technology can hold the solution. He sits down to explain why his agency have begun adding programmatic linear TV buying as an option for their clients.\nRead more here\n2. Mind, body and AI: High-tech tools using artificial intelligence are transforming Indian healthcare     AI improving healthcare in India    Artificial Intelligence is set to dramatically improve the lives of both doctors and their patients in India. AI tools are currently in progress to be able to non-invasively screen for diseases such a Tuberculosis. Not only costing less money but time too.\nRead more here\n3. Study shows that the Translation Services Market is growing at an incredible rate A recent study, undertaken by Verified Market Research has shown that \u0026ldquo;the Global Translation Services Market was valued at USD 38.04 Billion in 2018 and is expected to witness a growth of 2.02% from 2019-2026 and reach USD 44.67 Billion by 2026.\u0026rdquo;\nThe report focuses on growth rate, advances in translation technologies and strategies that are currently being used by the main current market players.\nRead more here\n4. Machine learning you can dance to!     Photo: Lillie Paquette    “We aren’t just AI enthusiasts applying machine learning to music\u0026hellip;We are musicians who want better tools for making music.”\nTwo MIT grad students, frustrated with the time it took to listen to music samples and find the best beats, have created an app that uses machine learning. Something that will arguably revolutionise one way to make music.\nRead more here\n5. How an AI trained to read scientific papers could predict future discoveries A new system created by researchers has taught an AI to correctly predict and provide insights into data that is far beyond human capabilities. AI are becoming more independent, but fear not! Independency in this context will greatly benefit us as humans.\nRead more here\nConclusion The past week has shown great developments in technology, especially in the AI field where we are seeing just how beneficial AI technology is becoming for us around the world.\nPlease connect with us on LinkedIn, YouTube or Facebook for any comments, questions, or just to keep up to date with the work we do!\nWe are very grateful for your support!\nIf you haven’t yet and are interested in trying out our technology, please try our platform, or drop us an email at hello@videotranslator.ai.\n","permalink":"https://videotranslator.ai/news/the-weekly-roundup-24-sept-2019/","tags":["English"],"title":"AI tools are transforming Indian healthcare, growth in the Translations Market and more"},{"categories":["Retail","Video Translation","Video"],"contents":"With the ever increasing popularity of short video apps amongst iOS users, more and more developers are trying to get their apps to the top. This has resulted in a plethora of short video apps being created with different features based on the users needs and wants. We\u0026rsquo;ve taken a look at the top ranking short video apps in the Apple App Store (as of August 2019) to see what these apps for iPhone have to offer.\n1. Snapchat     Snapchat    Snapchat is a social video, picture and instant messaging platform. Snapchat’s main feature isn’t video editing; it first gained popularity as an instant messaging platform where the content disappears after you view it, but the app has since expanded to allow the option to keep messages and content. Video length limit was recently increased from 10 seconds to 60 seconds. You can modify your video with filters, clipping, audio and the option to add text overlays and stickers.\n Video length: Up to 60 seconds Live streaming: Yes (as a video call with up to 16 contacts) Captioning: Yes  Download Snapchat\n2. iMovie iMovie allows you to create high quality (up to 4K) video and movie trailers from your phone. It comes with movie/trailer templates, visual effects (including greenscreen) and preloaded, licensed soundtrack music.\n Video length: Up to 60 seconds Live streaming: Yes (as a video call with up to 16 contacts) Captioning: Manual  Download iMovie\n3. Boomerang     Boomerang    Boomerang allows you to quickly create short, looped videos. The app takes a burst of 10 photos and loops them together to create a short, repeating video. The disadvantage of this app is that you must create (photograph) the videos in real time, so you can\u0026rsquo;t edit existing media. It integrates with Facebook and Instagram and also allows you to download and share your videos by any means.\n Video length: 10 frames (loops back and forth indefinitely) Live streaming: No Captioning: None  Download Boomerang\n4. Dubsmash Dubsmash is a social video platform for creating and sharing dance videos. You can record lip syncing and dance routines along to your chosen audio. Choose from an audio recording or soundbite from movies, shows, music, and internet trends. Dubsmash comes preloaded with audio, adding new content regularly. You can also add filters, captions, and other embellishments to the video. Dubsmash can share to Instagram, Snapchat, iMessage and more.\n Video length: Unspecified Live streaming: No Captioning: Yes  Download Dubsmash\n5. Splice     Splice    Splice is a video editing software designed to make it easy for you to edit and create video from your smartphone. You can crop and delete frames, merge multiple videos and select individual frames to be displayed as a video preview slideshow. Add text overlay, soundtracks, and narration. You can add your own audio file on Splice, but you cannot upload captioning files.\n Video length: Not Applicable Live streaming: No Captioning: Manually  Download Splice\n6. Twitch Twitch makes it easier for players to live stream their games. The app has a social messaging component, and allows gamers and users watching their stream to chat. Twitch has a live closed captioning feature (automatically-generated), giving viewers the choice to enable subtitles.\n Video length: Unspecified Live streaming: Yes Captioning: Automatic  Download Twitch\n7. Magisto     Magisto    Owned by Vimeo, Inc., Magisto is a video editing app differentiated by its integrated “smart video” editing AI software. The software automatically selects the best parts of your video and selects filters and effects for you, such as stabilization, cropping, facial recognition and filters.\n Video length: 75 seconds (150 seconds for Premium users) Live streaming: No Captioning: Manually  Download Magisto\n8. VivaVideo VivaVideo is used to create short video clips. VivaVideo includes a variety of features, including music, filters, and the option to add subtitles. The short video clips created by users tend to be more artistically-driven than on other apps.\n Video length: Unspecified Live streaming: No Captioning: Manual  Download VivaVideo\nConclusion It is clear that the need for short video editing apps spans across multiple use cases, from text messaging to live streaming video games. Each short video app has a specific set of features catered to a unique user base. With a wide range of short video apps available for iOS, there is most likely an app available for your unique videography needs.\nPlease connect with us on LinkedIn, YouTube or Facebook for any comments, questions, or just to keep up to date with the work we do!\nWe are very grateful for your support!\n","permalink":"https://videotranslator.ai/news/whats-hot-in-short-video-apps-for-ios/","tags":["English"],"title":"What's Hot in Short Video Apps for iOS"},{"categories":["Retail","Video Translator","Video"],"contents":"Short video clips continue to gain in popularity along with social platforms like Instagram and Snapchap. As smartphone video technology has improved along with our access to video media online, there has been a growing need for short video apps on smartphones. TechloMedia recently published a report on trending social video apps. We’ve taken a look at these as well as the top performing video apps in the Google Play Store (as of August 2019). Read on to learn about and compare the features these popular short video apps for Android have to offer.\n1. Instagram     Instagram    Instagram, which is owned by Facebook, is a social photo and video sharing program. You can shoot videos in the app or upload videos from your media library.\nInstagram comes with several filters and the option to mute the video. Captioning must be done manually; the app does not accept SRT files. On Instagram Stories, you have a wider range of options such as linking multiple videos together, splicing photos into your video, and adding captions or stickers. Stories, however, have a length limit of 15 seconds.\nIGTV is another portion of the app, separate from the feed, in which video creators can share videos of up to 60 seconds. Subtitles must be hardcoded for IGTV because of the vertical format of the videos.\n Video length  Feed: up to 60 seconds Instagram stories: up to 15 seconds IGTV: up to 60 minutes   Live streaming: Yes Captioning: Manual  Download Instagram\nDistribute Your Video With Captions To All These Apps!   How to quickly transcribe your video\n   2. TikTok TikTok is a social video app that allows you to create and share short video clips. You can trim, edit, clip and merge multiple videos, as well as add music, sound, filters, and stickers. Captioning must be done manually as text overlays.\nPost videos to TikTok, send them directly to your TikTok contacts, or download them to share on other platforms.\n Video length: up to 15 seconds Live streaming: Yes (as a video call with up to 16 contacts) Captioning: Manual  Download TikTok\n3. Likee     Likee    Likee, winner of the Google Play Awards 2017, is best known for having great special effects for a mobile video editing app (think: changing your hair colour and eyeliner). It is a short video app geared at lip syncing and music videos, having the innate ability to sync video frames with music tempo.\n Video length: Unspecified Live streaming: Yes Captioning: Manual  Download Likee\nClick here for iOS Hot Video Editor Apps in 2021!\n4. Vigo Video Vigo Video is a much like other short video social platforms, with the exception that it has a monetary platform. Videos that perform well have the opportunity to earn “flames,” which are convertible into money.\n Video length: up to 60 seconds Live streaming: Yes Captioning: Manual  Download Vigo Video\nAlso read: 9 of iOS Top Video Editing Apps 2021here.\n5. Twitch     Twitch    Twitch makes it easier for players to live stream their games and chat with their followers, using the integrated instant messaging feature.\nTwitch was created out of a need for gamers live-streaming their games; something that started on YouTube, but Twitch streamlined. Everything you need to live stream and broadcast is there in the app.\nThe live closed captioning feature, which automatically generates subtitles, allows viewers the option to enable or disable them as needed.\n Video length: Unspecified Live streaming: Yes Captioning: Automatic  Download Twitch\n6. VivaVideo VivaVideo is used to create short video clips. VivaVideo includes a variety of features, including music, filters, and the option to add subtitles. The short video clips created by users tend to be more artistically-driven than on other apps. Video resolution is limited to 720p, which is a common comment we’ve seen on the Play Store.\n Video length: Unspecified Live streaming: Yes Captioning: Manual  Download VivaVideo\n7. Magisto Magisto, Google Play Editor’s Choice 2019, is unique because of its “smart video\u0026quot; editing AI software. The software automatically finds the best parts of your video and selects filters and effects for you, such as stabilization, cropping, facial recognition and filters.\n Video length: 75 seconds (150 seconds for Premium users) Live streaming: No Captioning: Manually  Download Magisto\nDo You Care About Video SEO?      Read More: How How Subtitling Can Boost Video ROI    8. Lasso Owned by Facebook, Lasso is a short video editing app that allows you to add music, filters, stickers, and GIFs to your short videos.\nLasso sets itself apart with its large music library. The app claims to have one of the largest music libraries, including everything from “trending pop hits to vintage classics.” This is beneficial (and very different from YouTube!) because you don’t have to worry about licensing rights to music.\nThe app also keeps track of trending content and hashtags, so that you can create tailored videos to viral content. Lasso integrates with Facebook allowing you to share directly to your Facebook Story or Feed, as well as download the videos to share elsewhere.\n Video length: up to 15 seconds Live streaming: No Captioning: Manually  Download Lasso\nConclusion It is clear that the need for short video editing apps spans across multiple use cases, from instant messaging to live streaming music and games. Each short video app has a unique user base and set of features. The wide range of short video apps available for Android means there is likely an app catered to your unique videography needs.\nPlease connect with us on LinkedIn, YouTube or Facebook for any comments, questions, or just to keep up to date with the work we do!\nWe are very grateful for your support!\nIf you are interested in trying out our technology, please try our platform, or drop us an email at hello@videotranslator.ai.\n","permalink":"https://videotranslator.ai/news/the-8-best-short-video-apps-for-android/","tags":["English"],"title":"The 8 Best Short Video Apps for Android"},{"categories":["Retail","Video Translation","Enterprise","Languages","Video"],"contents":"Short video makers are an up and coming category of apps that are really hitting the ground running in China. Short video clips (even less than a second long) have been gaining in popularity along with social platforms like Instagram and Snapchat, and especially in China with Wechat and Weibo. The social component to online video broadcasting has changed how we consume short videos, and what we expect from them.\nA recent research project by Music Ally supposed that the short video app space in China could be a predictor of what is yet to come globally. In this article we give a basic overview of some of the major short video makers in China and what unique features they have to offer.\nWhat is a short video app? It depends on what app you’re using and what you’re using the videos for, but a short video app is essentially, an app that makes short video clips. Some apps have specific use cases such as converting iPhone Live Photos into gif\u0026rsquo;s or short movies so that they can be shared on social media, while others exist to create a slideshow type sequence of photos. Some apps might have this feature built in (like Instagram) whilst others are standalone apps, or can be linked onto social media apps. Most short video makers tend to have some form of social component.\nHow to translate your English video to Chinese? The point of this blog post is to tell you about Chinese video apps. If you don\u0026rsquo;t know how to make these, click here.\n     Clipping Chinese App: How to translate your video into Mandarin Chinese with AI    China’s most popular short video apps 快手 (Kuaishou)     Kuaishou    Kuaishou started as a gif program and then expanded into a short video maker. Users can create both pictures and videos, as well as combinations.\n Video length: up to 17 seconds Live streaming: Yes Captioning: Manual  火山小视频 (Huoshan) Huoshan is a video shooting app, so you must make the short video clips in real-time (rather than using existing photo and video content).\n Video length: up to 15 seconds Live streaming: Yes Captioning: Manual  微视 (Weishi)     Weishi    Weishi is unique in that it has an integrated subtitles feature. Once common use for users to include song lyrics as subtitles if they’re singing the videos.\n Video length: Not specified Live streaming: Yes Captioning: Automated  西瓜视频 (Xigua Video) Xigua Video is a bit more similar to YouTube than others in that it has a searchable platform and uses an AI to recommend videos based on interests.\n Video length: Not specified Live streaming: Yes Captioning: Manual  美拍 (MeiPai)     MeiPai    MeiPai is a social video platform which users can add filters, audio clips, video effects and overlays. The platform started out with a 10 second limit, but now allows for videos up to 5 minutes in length. MeiPai integrates with Weibo, and the videos created by users can be downloaded and shared on other platform as well.\n Video length: up to 5 minutes Live streaming: Yes Captioning: Manual  秒拍 (Miaopai) Miaopai is the most popular short video maker in China, with over 250 million daily views. Users must shoot videos in-app. They have the option to scroll through and view short video clips shared by those they follow (much like Instagram). The big sell for Miaopai is that many Chinese celebrities use it to interact with their fans. Miaopai integrates with Weibo.\n Video length: Not specified Live streaming: Yes Captioning: Manual  小咖秀 (Xiaokaxiu)     Xiaokaxiu    Xiaokaxiu’s main use is the creation of music videos, or users creating videos from existing audio. They can upload the audio and select from included illustrations, animations and text to create a short video clip. Xiaokaxiu has an integrated audio captioning feature.\n Video length: Not specified Live streaming: Yes Captioning: Automated  场库 (Changku) Changku was created by a movie production community in China, and in doing so, has become the go-to platform for sharing high-quality short films. It has global popularity.\n Video length: Not specified Live streaming: No Captioning: Manual  小影 (VivaVideo)     VivaVideo    VivaVideo is used to create short video clips. VivaVideo includes a variety of features, including music, filters and the option to add subtitles. The short video clips created by users tend to be more artistically-driven than on other apps.\n Video length: Up to 10 seconds Live streaming: Yes Captioning: Manual  Conclusion The increasing popularity of short video apps in China are possibly a sign of what\u0026rsquo;s to come globally for how we consume and use these social platforms. The individual abilities on each app allows the user to express their creativity in different ways. We\u0026rsquo;re excited to see what\u0026rsquo;s next in the space of short video apps.\nIf you are interested in trying out our technology, please try our platform, or drop us an email at hello@videotranslator.ai.\nPlease connect with us on LinkedIn, YouTube or Facebook for any comments, questions, or just to keep up to date with the work we do!\nAlso read: 9 of iOS Top Video Editing Apps 2021 here.\n","permalink":"https://videotranslator.ai/news/9-of-chinas-best-short-video-apps/","tags":["Chinese"],"title":"9 of China's Best Short Video Apps"},{"categories":["Retail","Video","Transcription","Translation","Visual Guides","Languages"],"contents":"Este video pertenece al canal de YouTube History Matters. El video habla sobre el personaje histórico ruso con repercusiones en la historia universal, Ivan El Terrible.\nIván IV Vasílievich, llamado Iván el Terrible, fue un gran príncipe de Moscú y de toda Rusia, además de ser el primer monarca ruso en adoptar el título de Zar. Es considerado como uno de los creadores del Estado Ruso.\nPasos A Seguir   Abre tu navegador y dirígete a videotranslator.ai luego, haz click en el botón Login, tras iniciar sesión correctamente ve a en_myTemplate (para traducir un video cuyo audio de origen es en Inglés) y selecciona New Item, este ítem será llamado Ivan por el protagonista del video en cuestión.\n    Iván el Terrible: Selecciona una plantilla        Iván el Terrible: Agregar un nuevo elemento      Carga el video, espera que sea procesado y activa la acción de transcripción. El narrador es británico así que seleccionaremos English (United Kingdom) como idioma principal.\n    Iván el Terrible: Transcribe tu video        Iván el Terrible: Espera mientras el video es procesado y transcrito      Una vez transcrito el vídeo, debes revisar la transcripción, ya que a veces nuestra inteligencia artificial puede omitir letras mayúsculas, puntos o comas en algunas oraciones. Esto se debe a que, como todos sabemos, las personas no hablan del mismo modo en que se escribe, por tanto, necesitamos hacer que el contenido transcrito tenga sentido para la inteligencia artificial encargada de hacer la traducción.\n    Iván el Terrible: Edite la transcripción para mayor precisión      Incrustamos los subtítulos en el video para obtener nuestro primer resultado, el vídeo con los subtítulos en su idioma original.\n  Iván el Terrible: Traducir de inglés a español\n     Una vez realizadas todas las correcciones a la transcripción, procedemos a iniciar el proceso de traducción de los subtítulos obtenidos en el proceso anterior.\n    Iván el Terrible: Traduce del inglés al español usando la Inteligencia Artificial      Luego, debes esperar a que la inteligencia artificial encargada de la traducción haga su trabajo, según lo indica el sistema\n    Iván el Terrible: La traducción del inglés al español está en progreso.      Luego de completado el proceso de traducción, revisa el producto obtenido para hacer las correcciones del caso\n    Iván el Terrible: Edite los subtítulos en español para mayor precisión.      Una vez ha sido corregida la traducción, procedemos a incrustar los subtítulos en el video.\n  Iván el Terrible: Traducir de inglés a español\n     Todo está listo, muchas gracias por tomarte el tiempo de leer este tutorial “Transcripción y Traducción de Videos de Ingles a Español: ¿Qué Tan Terrible Fue Iván el Terrible?”\n  Conclusión En este tutorial, hemos transcrito, y posteriormente traducido un video del canal History Matters en YouTube, del inglés al español. Hicimos esto, primero transcribiendo el video en inglés, luego traduciendo los subtítulos al español, y finalmente incrustando el contenido de los subtítulos en el video usando la función “Auto-Overlay.”\nEn caso de tener que publicar dicho contenido traducido en línea, recomendamos traducir también el título, la descripción y otros metadatos en el script de destino, en este caso el español. Esto mejorará su SEO en español, permitiendo a los hablantes nativos del idioma español encontrar su contenido en línea más fácilmente.\nVideo Translator no tiene relación alguna con el canal History Matters en YouTube. Estamos usando contenido públicamente disponible para mostrar un caso de uso interesante de nuestra plataforma.\nSi estás interesado en usar nuestra tecnología, por favor, prueba nuestra plataforma o envíanos un correo electrónico a: hello@videotranslator.ai\n","permalink":"https://videotranslator.ai/news/transcripci%C3%B3n-y-traducci%C3%B3n-de-videos-de-ingl%C3%A9s-a-espa%C3%B1ol/","tags":["English","Spanish"],"title":"Transcripción y Traducción de Videos de Inglés a Español"},{"categories":["Retail","Video","Transcription","Translation","Visual Guides","Languages"],"contents":"The Sydney Opera House is one of the most well known landmarks in the world. With over 10.9 million people visiting it each year, it\u0026rsquo;s obviously one of Australia\u0026rsquo;s hottest tourist spots.\nWhen searching online, the official videos for the Opera House are all in English, which is great for English speakers, but what about those who aren\u0026rsquo;t?\nUsing the videotranslator.ai app and creating translated videos would be a great way to reach millions of people worldwide who aren\u0026rsquo;t native English speakers. It\u0026rsquo;s quick, easy and extremely cost effective.\nRead on as we show you how to translate this video on the Sydney Opera House from English to French in 8 simple steps.\nSteps: How To Transcribe And Translate A Video From English To French   First off, we\u0026rsquo;ve logged into our videotranslator.ai account and have selected our template. Once selected we then add a new item and name it, in this case we\u0026rsquo;ll name it SydneyOperaHouse.\n    A French Affair: Add a new item \u0026#39;SydneyOperaHouse\u0026#39;      Next we upload our video. Once the upload is complete we select the video and tell the app what English dialect is being originally used in the video. The speakers are from Australia so we select Australian English.\n    A French Affair: Select to transcribe using Australian English      The app then transcribes the video and the transcription will be shown on the screen. Because people don\u0026rsquo;t always speak the way they write, the AI can sometimes miss capitalisation, commas and full stops as well as misuse certain words.\n  Due to this we need to check the transcription ourselves and make any corrections. This in turn helps the written content make sense to the AI when it begins translating. This process is known as post-editing and is super important for quality control.\n    A French Affair: Post-Editing is used to control quality      We then embed the English captions into the video which will produce the below video.\n  A French Affair: Translating your video from English to French\n     Once we\u0026rsquo;ve got the English captions embedded it\u0026rsquo;s time to translate them to French.\n    A French Affair: Translate to French With AI      We select Translate from the Action menu and then select \u0026lsquo;Automatic\u0026rsquo; for the AI translation as well as setting the language to French.\n    A French Affair: Translate to French With AI      Just as before, we want to check the AI translation and make any corrections as needed. Once all is good, we embed the French captions into the video and voila! Our video on the Sydney Opera House can now be viewed in French.\n  A French Affair: Translating your video from English to French\n     Conclusion: We Transcribed And Translated An English Video To French In this post, we have converted a video from the Sydney Opera House from English to French. We did this by, first transcribing the video in English, then translating the captions into French, and finally embedding the caption content into the video.\nIf you were to post such translated content online, it is recommended to also translate the title, description and other metadata into the target script, in this case French. This will improve your French SEO, allowing native French speakers to find your content online.\nVideo Translator makes no representation of a relationship with Sydney Opera House. We are using publicly available content to showcase an interesting use case of our platform.\nPlease connect with us on LinkedIn, YouTube or Facebook for any comments, questions, or just to keep up to date with the work we do!\nWe are very grateful for your support!\nIf you are interested in trying out our technology, please try our platform or drop us an email at hello@videotranslator.ai.\n","permalink":"https://videotranslator.ai/news/translating-your-video-from-english-to-french-a-step-by-step-guide/","tags":["English","French"],"title":"Translating Your Video From English To French: A Step By Step Guide"},{"categories":["Video Translator","Transcription","Translation","Accessibility"],"contents":"Several recent reports show that video content outperforms every other type of post on social media. In other words, using video content in social media marketing is a very good strategy. In this post we look at some numbers, and try to work out what this means for content creators and marketers.\nRenderforest put together an insightful report on social video marketing. Here are some of their statistics:\n 100 million hours of video per day is watched on Facebook. Video posts are shared 1200% more often than text and image posts, combined. 16% of YouTube videos are embedded, linked, or shared. 82% of Twitter users watch videos on Twitter. 45% of all Internet users watch at least 1 hour of video content per week. 4.6 billion video ads are watched online each year.  Are you seeing the value of video marketing on social media?\nBest Facebook Post Format For Engagement BuzzSumo spent a lot of time looking at video on Facebook, the below image is sourced from their 2019 Ultimate Guide to Facebook engagement, and you can clearly see the value of video.\n    BuzzSumo: Best Facebook Post Format    How To Optimise Your Videos For Social Media Before you post your video, there are a few things you should know about video on social media. There are certain traits that a video post must have before it can perform well on social media.\nTip 1: Your Video Should Make Sense On Mute 85% percent of Facebook users watch video on mute. What this tells us is that people who use Facebook are reluctant to want other people to know! They could be using it as a distraction during a dull meeting or class, or maybe they just want to be polite.\nThere is also a strong argument to be made for accessibility as part of your strategy, and the fact that many users like to watch video while multi-tasking, making open captions a requirement.\nWhatever the reason, videos that are easily understood without sound cater best to Facebook’s user base. You should consider embedding open/closed captions into your video.\nTip 2: Aim For Between 180 And 200 Seconds, Or 10+ Minutes Statistics show that for Facebook, videos between 180 and 200 seconds, or about as long as a song on the radio, have the best engagement on social media. Longer than 200 seconds, engagement tends to drop off. This may be a testament to how long people can keep interest, or how much time they want to spend on social media in general.\nThis story is a little different in YouTube-land. The folks at TubeFilter took a fascinating look at what was happening in YouTube, and the below graphic comes from them. Their conclusion, longer equals better for YouTube, with 10+ minutes video\u0026rsquo;s achieving the best life time views.\n    TubeFilter: Life To Date (LTD) Average Views verses aggregated Average View Duration    Tip 3: When Should You Post Your Video Answer: it depends on your audience. No, really, it depends on your audience.\nEvening Posting Works Best On Facebook A study found that posts made between 7pm and 11pm get the most engagement on Facebook. This varies somewhat depending on your audience’s demographic.\nFor example, users in nonprofit industries have some hot spots for engagement earlier in the day⁠—but in general, posting in the evening as opposed to during the morning and afternoon commute tends to fare best.\nTake a look at your Facebook Audience Insights to see where your followers live, and choose convenient times for them to see your posts.\nPosting Around Lunchtime Works Best For Instagram Instagram has been found to have the most engagement between 10am and 3pm on weekdays, with very low engagement on Sundays specifically.\nWe follow the people behind Sprout Social, as they really know what is going on - the below graphic is from their best times for social media post.\n    Sprout Social: Best Times To Post On Social Media - Instagram    Post In The Morning For Twitter The most engagement on Twitter happens at 9am. It greatly drops after 4pm, so plan on posting during the daytime.\nOn LinkedIn, Post On Wednesday Mornings The most engagement on LinkedIn happens between 9am and 11am, as well as 12pm (think lunch time). on Tuesdays through Fridays. The platform has very low engagement on Saturdays, Sundays and Mondays.\nConclusion Posting video on social media on social media has a great return on investment because of how much engagement video posts get. That said, video posts need to have certain traits to perform well. Video posts should be understood with the sound turned off, not longer than about three and a half minutes, and shared at strategic times of day.\nTo summarise, pay attention to who your audience is and where they live, as well as which social media platform you’re posting on. In other words, to get the most engagement, avoid posting on all of your social platforms at the same time.\nPlease connect with us on LinkedIn, YouTube or Facebook for any comments, questions, or just to keep up to date with the work we do!\nWe are very grateful for your support!\nIf you are interested in trying out our technology, please try our platform, or drop us an email at hello@videotranslator.ai.\n","permalink":"https://videotranslator.ai/news/why-post-video-to-social-media-3-tips/","tags":["English"],"title":"Why Post Video To Social Media: 3 Tips"},{"categories":["Video Translation","Transcription","Accessibility"],"contents":"We have been working really hard making a number of changes to our underlying application. Specifically we have (i) added a new architecture to our video processing, (ii) added a few more languages, (iii) large number of changes to the look/feel of the product.\nAll in all, we felt it was time for a new explainer video which covered how to use the platform.\nHere it is\u0026hellip; enjoy!\nHow To Transcribe A Video Using AI   Explainer: How to Transcribe A Video Using AI\n   Conclusion Technology is offering us ways to look at old problems with new eyes. We should look at open captions as a tool - something good for accessibility, and for boosting your bottom line.\nPlease connect with us on LinkedIn, YouTube or Facebook for any comments, questions, or just to keep up to date with the work we do!\nWe are very grateful for your support!\nIf you are interested in trying out our technology, please try our platform, or drop us an email at hello@videotranslator.ai.\n","permalink":"https://videotranslator.ai/news/how-video-transcription-works-explainer/","tags":["English"],"title":"How Video Transcription Works Explainer"},{"categories":["Video Translation","Enterprise","Transcription","Translation","Accessibility","Visual Guides"],"contents":"It started with a Tweet, which was then picked up by the Guardian, re-Tweeted and the rest is history. The post got re-tweeted 70K+ times, and liked 74K+ times. That is clearly something which struck a cord. Why?\nWho is using subtitles or captions, why are they using it, and how can you also use subtitles or captions. For a technical discussion on subtitles or captions, see this. This post is more about the value in subtitles or captions.\n    Subtitling For The Win: @deafgirly    We totally liked the Tweet!\nContext There are two kinds of captions, open captions and closed captions.\n Open Captions are the type of captions which are permanently embedded into the video asset. It is not possible to remove these captions. Closed Captions are generally a separate file from the primary media asset, often in *.srt format. Depending on your video player, it should be possible to switch these on and off.  Open captions are not very popular. We think this is because they are mostly ugly (the old SRT format is from the video cassette recorder days). Open captions are also quite hard to use, in that SRT captions cannot handle much by way of styling, changes in text direction, bold/italic etc.\nClosed captions are popular because it is possible to load up multiple language files. Still, the styling remains less than ideal, and it only works where the player has the capacity for Closed Captioning.\nOpen Captions Make A Comeback Form the article, the reason for the big response is it allows people to consume video content while multi-tasking. Additionally, quoting from the article, an Ofcom study from 2006 estimated that of the 7.5 million UK TV viewers using subtitles, only 1.5 million had a hearing impairment.\nWe think another big reason is the rise of audio-muted auto play social media channels. From Facebook to LinkedIn, people are increasingly consuming video content without the sound turned on, which is a big market.\nOpen Captions are totally making a comeback.\nHow To Add Captions or Subtitles To Your Content The process differs depending on the language(s) you are choosing to work with - assuming your content is in English.\n  Upload your asset into the video translator application. Then select Action -\u0026gt; Transcribe, assuming you do not have any captions.\n    Subtitling For The Win: Trigger Transcription AI      Pick the correct dialect. If you are using another language, pick the correct dialect for the content you have. Trigger the speech to text transcription AI.\n    Subtitling For The Win: Choose Your Dialect!      The Outcome Post Addition Of Open Captions   Once your subtitles or captions are good (you should check!) use Auto-Overlay to programmatically add captions. We used the ever popular yellow text with a blue highlight to get the below effect.\n    Subtitling For The Win: Add Open Captions!      That\u0026rsquo;s it - now go add subtitles on all your social media, and watch your engagement sky-rocket!\nDeafinitely Girly approves, “It would be great if they were mandatory across all streaming services and at least 50% of cinema showings.”\nNotes On Usage The main challenge around Open Captions is you can only embed (or bake, burn, write etc) one set of open captions into an asset. What if your user wants a different language?\nWe think of this as the chicken-egg problem. Effectively, unless your target audience can find your asset, this will never be an issue. The smart way to manage this is to translate your title, description and other social media specific metadata to the language your open captions are in - this way you are optimising for search.\nConclusion Technology is offering us ways to look at old problems with new eyes. We should look at open captions as a tool - something good for accessibility, and for booting your bottom line.\nPlease connect with us on LinkedIn, YouTube or Facebook for any comments, questions, or just to keep up to date with the work we do!\nWe are very grateful for your support!\nIf you are interested in trying out our technology, please try our platform, or drop us an email at hello@videotranslator.ai.\n","permalink":"https://videotranslator.ai/news/subtitling-for-the-win/","tags":["English"],"title":"Subtitling For The Win"},{"categories":["Video Translator","Enterprise","Transcription","Translation"],"contents":"This post is not really about diversity. It is about the granular challenges around governance in an increasingly complex world, and operational solutions which may work going forward.\nWe look at three events which took place in this week. What the problem is, and what a solution might be. These events are:\n Trump Administration’s Deregulation Drive Begins to Impact Language Industry Sometimes Lost In Translation, With Dialects Context Is Key Translating verdicts will help all litigants  Trump Administration’s Deregulation Drive Begins to Impact Language Industry US federal regulations have generally favored the language services industry. In part, due to accessibility regulation, there is legislation which requires government entities to provide services in many different languages.\nFrom the July 3, 2019 article, a judge commenting on the changes said, \u0026ldquo;What if you have an individual that speaks an indigenous language and has no education and is completely illiterate? You think showing them a video is going to completely inform them of their rights? How are they supposed to ask questions of the judge?\u0026quot;\nThe counter comment to this was provided by a Justice Department official saying the shift was due to, \u0026ldquo;part of an effort to be good stewards of (the department’s) limited resources\u0026rdquo;.\nRealistically, these are both really good points. What are you going to do?\nSometimes Lost In Translation, With Dialects Context Is Key In far away Bangkok, deputy leader of the Future Forward Party (FFP), Kunthida Rungruengkiat, was criticised after she put forward a proposal to allow lawmakers to speak in their regional dialects in the chamber.\n    The Growing Pains Of Diversity: Kunthida Rungruengkiat    Here is the interesting part, \u0026ldquo;Proponents lauded her call for preserving cultural and linguistic diversity, while at the same time, critics said her proposal was unrealistic and out of context\u0026rdquo;.\nThen there was more excitement, the House Speaker Chuan Leekpai, opted for the middle ground. \u0026ldquo;Northern, Isan, Southern and Central Thai dialects are beautiful in their own ways,\u0026rdquo; he said. \u0026ldquo;However, I plead with members to use the Central form, or dialects that are comprehensible to everyone, as otherwise the sessions will be difficult to understand.\u0026quot;\nThe key take away here is, much like the above, these are both really good viewpoints. Honestly, what are you going to do?\nTranslating verdicts will help all litigants Meanwhile, the Supreme Court of India took notice of the challenge, and \u0026ldquo;announced that all its judgements will be translated to six regional languages and will be uploaded on the court’s website by the end of July\u0026rdquo;\nFrom the article, there are three main upsides to here:\n Increase awareness of laws specific to folks from rural on backward (read: low literacy) areas of India. Will benefit litigants from rural areas, \u0026rdquo;\u0026hellip; many litigants come from rural areas. If the service and information are given to them in their language, they will feel more comfortable and satisfied. It is better than hearing it from someone else\u0026rdquo;. Will benefit lawyers who do not necessarily practice in English, \u0026ldquo;Only a few lawyers study or practice in metropolitan cities, where English is taught from the primary levels. Many aspiring lawyers study or practise in other districts where English isn’t the primary language and this move will help them.\u0026quot;  But why are they not arguing like the above two cases?\nThis is the main takeaway, \u0026ldquo;Chief Justice of India Ranjan Gogoi has given his nod for a translation software developed by an ‘in-house’ electronic software wing.\u0026quot;\nThey have a solution. This is why there is no argument.\nThe growing pains of diversity. What are you going to do about it? Our viewpoint on this is simple. We could get into arguments about which viewpoint is correct, but this is not so useful.\nThe basic points are:\n We want to offer people access to services in the language they are most familiar with - mostly because it leads to better outcomes when stakeholders understand what is going on. Its really expensive to offer people access to services in their own languages - mostly because operationally, this is hard.  A possible solution We have AI. Lets use it. We can translate audio, video, images, and text. However, this has been around for a while, but is not really used - why?\nOur product is specifically designed to translate nested data structures. If you are translating a video, you also want to translate the title, description and other metadata specific to the social channel you are delivering content to - the point of the entire exercise is for multi-lingual SEO/SEM\nThe problem is a chicken-egg problem. If stakeholders cannot find the answers they are looking for in their own language, the enormous expense of translation does not translate (possibly a terrible pun) into ROI.\nWhat are you going to do about it? Check out an accessibility specific solution here.\nConclusion Technology is offering us ways to look at old problems with new eyes. Fixing the operational problems will fix the politics. Mostly, its hard work, and we should do the work.\nPlease connect with us on LinkedIn, YouTube or Facebook for any comments, questions, or just to keep up to date with the work we do!\nWe are very grateful for your support!\nIf you are interested in trying out our technology, please try our platform, or drop us an email at hello@videotranslator.ai.\n","permalink":"https://videotranslator.ai/news/the-growing-pains-of-diversity-and-a-possible-solution/","tags":["English","Thai","Hindi","Spanish"],"title":"The Growing Pains Of Diversity And A Possible Solution"},{"categories":["Support","Video Translator","Retail","Enterprise","Transcription","Translation","Welcome"],"contents":"Our original name was QBL Media, and our new name is videotranslator.ai. The original name did not really work, and was always a temporary name.\nThis post covers some of the context of where our platform came from, and what changes happened in the course of getting this app to market, including a pivot.\nWe used SEO to determine a new name. Read on to understand why this was done, how it was done, and what benefits we expect to get from the name change.\nWe See The Need For A Product - Late 2016/Early 2017 Our SaaS application started as a simple idea late in 2016. The original idea was to use AI to translate websites.\n It is easiest to come up with an idea by having a requirement. In a previous life, one of our founders had a requirement of translating collateral into a number of European languages. Due to the nature of legal requirements, the cost of translating a single piece of collateral (think 2-4 page corporate brochure\u0026rsquo;s) is high.  This requirement can be converted into a small problem/solution description. Effectively:\n A client has a current website, and our value proposition was creating a micro-site. That is, a simple landing page which has been modified to have really good multi lingual SEO. The value proposition was that a client using our technology would have the ability to service inquiries in a number of languages, and jump to the top of the organic search results.  Actually having a requirement - that is, you are actually the person who needs the product - is step one in coming up with the product.\nIt is of course, possible to come up with a completely new product without yourself needing this product. This is harder to do.\nWe Have No Traction - August 2018 There are several definitions of traction. Largely, when we say \u0026lsquo;We Have No Traction\u0026rsquo; we mean things were not working. Clients were not coming in the door, it was hard to get meetings, and we were definitely not getting paid.\nThe long and short is while we had a working prototype, which clients could use, the sales process was very painful. Every conversation would end in, \u0026lsquo;love the idea, talk to me in 3 months when I have budget\u0026rsquo;.\nThis was less than ideal, but after unpacking the statement, the major issues were:\n There was no way to demonstrate the value upfront to the prospect. That is, if a client does create a landing page in a different language, what will happen - is the client guaranteed additional traction? There was no easy way to allow the client a simple first step - as the value proposition was a few web-pages in another language, there was no easy way to try without impacting the entire client website. The change management process was painful, and even we we offered to do all the work, the client would still need to offer their own resources (that is, a change management team) to even try the offering.  Traction is the lifeblood of any startup, but way more importantly, little/no early traction is telling you something very valuable. When something works easily, this is tell you what to focus on, or in this case what not focus on!\nTraction, we weren\u0026rsquo;t getting any. Really. It was time to pivot.\nWe Need To Pivot - January 2019 We needed to focus on a few things, and we had learnt a few lessons.\n As a startup, you are unlikely to get traction with enterprise without godfathers. This is not good or bad, simply it is what it is. We needed a way simpler value proposition. Its not about having an elevator pitch. Its about being able to answer your \u0026lsquo;what-is-it\u0026rsquo; in a few words. Due to time/runway limitations, we need a very simple initial target audience, which is made up of B2C or B2B where the prospect is as small as you are.  We rebuilt our value proposition based on the simplest, cheapest client we knew we could acquire.\nThe pivot was to leave behind the multi-lingual website, and pivot to simply video translation. Translating video is, in workflow terms, exactly the same as translating a website. It is however, much simpler to do technically and way simpler to sell. The key point is a refocus to find a simpler, tighter, value proposition.\nWe Need A Name - May 2019 The original name, QBL Media, was a working title which had originally been sourced from a popular computer game.\n There was a feeling, from the start, that as the product found its feet, as the functionality was fleshed out, an appropriate name would be found. The idea is, as the value proposition came into being, an obvious name for the product would suggest itself. Once the focus became just video translation, post our pivot and total lack of any traction, this gave us a lead in terms of what needed to happen.  Once our value proposition became obvious, we knew what needed to happen to work out our new name.\nUsing SEO To Generate A New Name - July 2019 One simple trick\u0026hellip; no really. Once we knew what our value proposition was, we used a lot of keyword analysis and playing with various search engines to work out our new name. In the end,\n The simplest use case we had was Video Speech-To-Text. That is, people who wanted the transcripts for video content. Many people do not know that this is known as transcription, this is known as video translation, as in \u0026lsquo;I want to take this video and translate it to get the subtitles\u0026rsquo;. We spent a bunch of time looking at the keywords suggestions on our Google Ads account.  Once we knew the simplest use case of our value proposition, everything was tailored to come up with a name that described how people were looking for that value proposition. This is how to use SEO to come up with a new name\nPeople spend a lot of time looking for how to translate video.\n Sometimes this means getting a transcript of a video. Sometimes this means translating a video they don\u0026rsquo;t fully understand. Sometimes this means how to translate a video into some other language.  This is our \u0026lsquo;what-is-it\u0026rsquo; moment!\nOur end result was simply turning video translation into a verb, and calling our new platform videotranslator.ai, and in terms of our app, app.videotranslator.ai.\nConclusion Our new platform was named by doing research on our simplest value proposition. What search terms to people use to find answers related to our simplest value proposition?\nMore importantly - don\u0026rsquo;t waste time coming up with a cool new name. As your product or service takes shape, as it becomes a thing, a name will turn up. Seriously. The universe works in mysterious ways.\nPlease connect with us on LinkedIn, YouTube or Facebook for any comments, questions, or just to keep up to date with the work we do!\nWe are very grateful for your support!\nIf you are interested in trying out our technology, please try our platform, or drop us an email at hello@videotranslator.ai.\n","permalink":"https://videotranslator.ai/news/how-we-used-seo-to-come-up-with-a-new-name/","tags":["English"],"title":"How We Used SEO To Come Up With A New Name"},{"categories":["Best Practices","Video Translation"],"contents":"These days, there are a large number of video editing tools available. The majority of these can add captions, or add subtitles, to your video. However, to do this we first need a transcript of the audio or video content.\nGiven the number of video transcription services out there, which one should you choose?\nBefore you take on the monotonous task of transcribing audio to text, read this blog post to see the major differences between two transcription platforms, rev.com and videotranslator.ai and what you can expect when selecting a transcription service.\nWhat’s the difference between VideoTranslator.ai and Rev.com? Why choose VideoTranslator.ai verses Rev.com? VideoTranslator.ai VideoTranslator.ai is a Software-as-a-Service (SaaS) application which allows you to use an Artificial Intelligence (AI) to speed up your transcription process.\nIn layman’s terms, this means we use Speech-To-Text AI\u0026rsquo;s to do the busy work of transcribing our audio or video content into text for us.\nWhat you can expect from this is a much faster turnaround time (minutes rather than hours) so you can add open captions to your content very quickly. Additionally, we can transcribe many languages, allowing you to use your valuable staff time for higher value tasks.\nRev.com If you currently use a transcription service, or are evaluating transcription services, you may have heard of Rev.com. Rev.com is a service that uses a mix of human and machine transcription to provide transcription capabilities.\nAs such, the turnaround time tends to be a bit longer, and you may be paying considerably more for the service depending on the length of your video.\nIf you’re looking for a high degree of accuracy, and don’t have the option to post edit the copy in-house, then Rev.com might be the type of service you need.\nThe Difference Between Human Transcribers And Machine Transcribers The difference to all this is that an AI’s tend to be poor writers. Since people speak much differently than they write, AI’s often miss punctuation and grammar nuances that aren\u0026rsquo;t articulated in spoken language.\nSo if you use an AI, you will need someone to edit the copy of the audio or video content. This process is known as post-editing.\nDespite the time taken in post-editing, it is still much faster than transcribing the video manually, as the AI does the bulk of the work with timing and writing out the words.\nWhat If I Need A Translator? If you’re not familiar with the language you are transcribing into, then you’ll want to get a human to look at it. VideoTranslator.ai has the option for you to add users to your account.\nThis could be someone fluent in the language you’re transcribing into, a copy editor, or just a second set of eyes to vet the content. If you are subscribed to our service, you can add unlimited users.\nIf you are using the free-trial, or not yet subscribed, you can add one user per language.\nComparing VideoTranslator.ai to Rev.com           VideoTranslator.ai Rev.com   Pricing (Transcription) $10 per language-month and $0.10 per minute after that. Unlimited content. $1 per minute for English. $3-7 per minute for any other language. Unlimited content.   Turnaround Time Real-Time. Our AI starts working immediately to translate your audio to text. Up to 24 hours for videos under 30 minutes.   Accuracy Medium. We speak differently than we type, so our AI tends to miss punctuation. You’ll need to copy edit the transcriptions, or hire a translator to do so. High. Since Rev hires translators, they take much longer to do the transcription. However, you can expect a much higher degree of accuracy from a human being.   Support Multiple Dialects? Choose from several dialects from each language for your transcriptions. Spelling can vary between dialects within the same language, so this ensures readability for your audience. Not specified.   Support Multiple Languages? Over 60+ languages and 150+ dialects. No. According to rev.com, only English is currently supported for video transcription services.   Auto Overlay Feature? Yes. Since most mobile users watch video without audio, adding captions to social content is critical. Auto overlay allows you to customise the text colour, highlight colour, and opacity of your video captions. Not specified.   Who Transcribes the Text? You have ownership and control over the content of the captions. Someone else. This may be ideal if you don’t know the language or need someone to edit copy for you.   Add Additional Users Yes Yes    Should I use VideoTranslator.ai or Rev.com? Ultimately, it is up to you to decide. Each platform has its advantages and disadvantages. If you think you can do your own post-editing of the copy, and budget is really important to you, VideoTranslator.ai may be preferable.\nWe encourage you to research and try video transcription services to find the one that works best for you. We welcome you to try our service for free—and let us know how we can improve.\nConclusion If you are interested in trying out our technology, please try our platform, or drop us an email at hello@videotranslator.ai.\nPlease connect with us on LinkedIn, YouTube or Facebook for any comments, questions, or just to keep up to date with the work we do!\n","permalink":"https://videotranslator.ai/news/comparison-between-rev-dot-com-and-videotranslator-dot-ai/","tags":["English"],"title":"Comparison Between Rev.com And VideoTranslator.ai"},{"categories":["Transcription","Video","Subtitles","Captions"],"contents":"Many clients ask how us about subtitles. Generally, this is the first question a prospect asks us about our platform. In practise, they mean a few different things.\n We want subtitles for our audio/video content. We have subtitles, but want to make changes to the timing. We want to embed our subtitles into our video file, for use in Social Media.  Let us look at these questions in detail.\nWhat Are Subtitles or Closed Captions? Subtitles are text derived from either a transcript or screenplay of the dialogue or commentary in films, television programs, video games, and the like, usually displayed at the bottom of the screen.\nOne of a series of subtitles, accessible through a decoder, is known as a \u0026lsquo;closed caption\u0026rsquo;. The term \u0026lsquo;closed\u0026rsquo; is because the captions are not visible until activated by the viewer. On the other hand, \u0026lsquo;open\u0026rsquo;, \u0026lsquo;burned-in\u0026rsquo;, or \u0026lsquo;hard-coded\u0026rsquo; captions are visible to all viewers.\nWhat Subtitle File Formats Exist? The most common subtitle/closed caption file format used is *.srt. An SRT file (otherwise known as a SubRip Subtitle file) is a plain-text file that contains critical information regarding subtitles, including the start and end timecodes of your text to ensure your subtitles match your audio, and the sequential number of subtitles.\nThere are a large number of subtitles or closed captions formats available, see here and here for details.\nSample Subtitle File We use the video translator to produce a subtitles file. The following image is what a subtitle file, a *.srt looks like, click here to download the sample SRT file.\n    Example of an SRT file    How Do I Make My Own Subtitles?  (Manual) Using a notepad tool, such as Notepad++, Sublime Text or your own computers default text editor, you can create your own SRT files. (Automatic) Use a video translator to transcribe your content using a Speech-To-Text AI which (a) automatically works out your captions, and (b) create the SRT file.  Remember: If you are using the AI, please check/edit the transcript after usage. Both text and timestamps can be edited in the platform.\n    Use a Speech-To-Text AI to automatically create a SRT file    How Can I Add Subtitles To A Video File? How Can I Add Subtitles To A Video File For Free? If you are looking to do an \u0026lsquo;open caption\u0026rsquo;, or embed/burn the captions into your asset, use the Auto-Overlay function in your video translator.\n  Once you have the captions, click on the Action button and select the Auto-Overlay.\n    Action -\u0026gt; Auto-Overlay      Select the asset. Then choose a font, font-size and font-colour. In the below, we use Noto Sans, 30 and a strong blue. Click Next.\n    Auto-Overlay -\u0026gt; Font, Font-Size and Colour      In the below, we choose a Highlight, and a yellow for the colour of the highlight. Click Confirm.\n    Auto-Overlay -\u0026gt; Highlight      The final asset with the Auto-Overlay. Change the styling on your own video to make it look nice!\n  Video Translator: Pricing: Subscription vs. Pay-As-You-Go\n     Conclusion Making subtitles is straightforward. First, get the transcript of your video. Second, make the SRT file, and once this is ready (a) embed the SRT into your asset, or (b) manually upload the SRT into the social media service you are using.\nPlease connect with us on LinkedIn, YouTube or Facebook for any comments, questions, or just to keep up to date with the work we do!\n","permalink":"https://videotranslator.ai/news/how-do-i-make-subtitles-and-closed-captions/","tags":["English"],"title":"How Do I Make Subtitles And Closed Captions?"},{"categories":["Engineering","Video Translation","Support","Patch Notes","Accessibility"],"contents":"We have been putting in for a number of grant applications in the innovation space. One of the applications needed a small video as part of the application process.\nThe video covers the basic use cases, and we added the captions to the asset.\nMay 2019: Product update   Product Update: May 2019 (English)\n   Conclusion Please connect with us on LinkedIn, YouTube or Facebook for any comments, questions, or just to keep up to date with the work we do!\nWe are very grateful for your support!\nIf you are interested in trying out our technology, please try our platform, or drop us an email at hello@videotranslator.ai.\n","permalink":"https://videotranslator.ai/news/product-update-may-2019/","tags":["English","Hindi"],"title":"Product Update: May 2019"},{"categories":["Engineering","Video Translator","Video Translation","Support","Patch Notes","Accessibility"],"contents":"There are a number of bug fixes and patches, which may affect your user experience. Fixes include (a) and upload bug, (b) a naming convention enhancement, (c) a UI timing bug, (d) UI help bug, and (e) UI folder bug.\nMay 2019: Upload Bug Previously, if you uploaded certain files, and exceeded certain file sizes, the application would error without notifying the user.\nSpecifically, on the operational side, we setup all client with file and size permissions at enrolment. In the below, *.bmp was removed from the image list, and *.mov was added to the video list.\n Generic: *.pdf only, maximum 100mb. Image Files: *.png, *.gif, *.jpg, and *.jepg only, maximum 100mb. Audio Files: *.mp3 only, maximum of 100mb. Video Files: *.mp4, *.avi, and *.mov only, maximum 250mb.  The error handler had a bug so the failure would error out and not be communicated to the user. This has now been addressed with the bottom-centred snack-bar and message.\n    Patch Notes May 2019: Upload Bug    May 2019: Naming Convention Enhancement Previously, on uploading assets, the asset would be rename to include a unique identification code which would be reflected in the name. This has been improved upon, and now the asset names should not include special characters, and are mostly transparent to users.\n    Patch Notes May 2019: Before Naming Convention Enhancement        Patch Notes May 2019: After Naming Convention Enhancement    The only difference is the extra characters at the start of the asset have been removed.\nMay 2019: Timing Bug Previously, there used to be a bug where changing the times within the *.srt files would cause the application to crash. There was a bug regression, and this bug showed up again. This has now been fixed.\nShould you belive you are seeing this issue, please contact us so we can address it. The workaround was to highlight and replace the character (when the bug was not patched).\nMay 2019: Help Bug Previously, on first load of the application, the help modal (clicking on the question mark icon) would get cut off at the bottom of the screen. Exiting the modal and reopening the modal would solve this issue.\n    Patch Notes May 2019: UI Help Bug 1        Patch Notes May 2019: UI Help Bug 2    Conclusion Please connect with us on LinkedIn, YouTube or Facebook for any comments, questions, or just to keep up to date with the work we do!\nWe are very grateful for your support!\nIf you are interested in trying out our technology, please try our platform, or drop us an email at hello@videotranslator.ai.\n","permalink":"https://videotranslator.ai/news/patch-notes-may-2019/","tags":["English"],"title":"Patch Notes: May 2019"},{"categories":["Retail","Video","Transcription","Translation","Languages"],"contents":"यह वीडियो मैडम तुसाद सिडनी यूट्यूब पृष्ठ से है और यह मैडम तुसाद सिडनी में मोम के हाथ बनाने के बारे में है, जहां वे तरल मोम से लोगों के हाथ के नक्से, कुछ सरल चरणों का पालन करके बनाते है।\nप्रक्रिया के अनुसार ठंडे पानी में लोगों के हाथों को डुबोना, और फिर तरल मोम में उनके हाथ डुबोने शामिल है । यह करीब 5 बार दोहराया जाता है, हाथों का सांचा बनाने के लिए ।\n  मोम का हाथ बनाने की कला: अंग्रेजी से हिंदी मे वीडियो अनुवादित\n   क़दम   कृपया अपना ब्राउज़र खोलें और यहां पर जाएं, और फिर लॉगिन बटन पर क्लिक करें । अनुप्रयोग में सफलतापूर्वक लॉगिन करने पर, माईटेम्पलेट का चयन करें और एमटीएस फ़ाइल बनाएं।\n    मोम का हाथ बनाने की कला: एक नया आइटम जोड़ें \u0026#39;एमटीएस\u0026#39;      वीडियो अपलोड करें और ट्रांस्टाइप क्रिया का चयन कर। वीडियो के लिए पसंदीदा भाषा का चयन करें । इस वीडियो में लोगों में सामान्य ऑस्ट्रेलियाई लहज हैं । तो हम अंग्रेजी (ऑस्ट्रेलिया) के रूप में भाषा का चयन करते है ।\n    मोम का हाथ बनाने की कला: प्रतिलेखन दबाए      एक बार प्रतिलेखन पूरा हो गया है तो, हम जल्दी इसकी जांच करते है ।\n    मोम का हाथ बनाने की कला: अंग्रेज़ी में सुधार के लिए मानव त्वरित जाँच      हम यहां ओवरले जोड़ सकते हैं, जैसा कि नीचे दिखाया गया है। जब आप प्रतिलेखन से खुश हो जाते हैं, तब अगले चरण पर आगे बढ़ें, और अनुवाद क्रिया को ट्रिगर करें। यह अंग्रेजी से हिंदी में कैप्शन का अनुवाद करेगा।\n  मोम का हाथ बनाने की कला: ऑटो ओवरले हाइलाइटर के साथ (अंग्रेजी)\n     अनुवाद प्रक्रिया के सफल समापन पर अनुवादित फाइल को खोलें और अनुवाद कैप्शन को देखें, बदलाओ करे अगर जरूरी है तो।\n    मोम का हाथ बनाने की कला: हिंदी में सुधार के लिए मानव त्वरित जाँच      एक बार यह हो गया तो, हम अंतिम चरण में जाते है कैप्शन के लिए \u0026lsquo;ऑटो-ओवरले\u0026rsquo; का चयन करते हुएैं। इस मामले में हमने एक हाइलाइट चुना जैसा कि नीचे देखा जा सकता है।\n    मोम का हाथ बनाने की कला: ओवरले दबाए पीले हाइलाइटर के साथ      सब कर लिया गया! इस प्रक्रिया को पढ़ने के लिए धन्यवाद और अंतिम ऑटो-ओवरले वीडियो यहां देखें।\n  मोम का हाथ बनाने की कला: अंग्रेजी से हिंदी मे वीडियो अनुवादित\n     निष्कर्ष इस पोस्ट में हमनेे मैडम तुसाद सिडनी के एक वीडियो को अंग्रेजी से हिंदी में परिवर्तित किया। पहले वीडियो का अंग्रेजी में प्रतिलेखन, और फिर अंग्रेजी से हिंदी में कैप्शन का अनुवाद करके किया गया है।\nक्यूबीएल मीडिया मैडम तुसाद सिडनी (एमटीएस) के संग्रहालय के साथ रिश्ते का कोई प्रतिनिधित्व नहीं करता है । हम अपने प्लेटफ़ॉर्म के एक दिलचस्प उपयोग को प्रदर्शित करने के लिए सार्वजनिक रूप से उपलब्ध सामग्री का उपयोग कर रहे हैं ।\nयदि आप हमारी तकनीक को आजमाने में रुचि रखते हैं, कृपया हमारे प्लेटफार्म का प्रयोग करे या हमें ईमेल भेजे यहां ।\n","permalink":"https://videotranslator.ai/news/%E0%A4%AE%E0%A5%8B%E0%A4%AE-%E0%A4%95%E0%A4%BE-%E0%A4%B9%E0%A4%BE%E0%A4%A5-%E0%A4%AC%E0%A4%A8%E0%A4%BE%E0%A4%A8%E0%A5%87-%E0%A4%95%E0%A5%80-%E0%A4%95%E0%A4%B2%E0%A4%BE-%E0%A4%85%E0%A4%82%E0%A4%97%E0%A5%8D%E0%A4%B0%E0%A5%87%E0%A4%9C%E0%A5%80-%E0%A4%B8%E0%A5%87-%E0%A4%B9%E0%A4%BF%E0%A4%82%E0%A4%A6%E0%A5%80-%E0%A4%AE%E0%A5%87-%E0%A4%B5%E0%A5%80%E0%A4%A1%E0%A4%BF%E0%A4%AF%E0%A5%8B-%E0%A4%85%E0%A4%A8%E0%A5%81%E0%A4%B5%E0%A4%BE%E0%A4%A6%E0%A4%BF%E0%A4%A4/","tags":["English","Hindi"],"title":"मोम का हाथ बनाने की कला: अंग्रेजी से हिंदी मे वीडियो अनुवादित"},{"categories":["Retail","Video","Transcription","Translation","Languages"],"contents":"This video is from Madame Tussauds Sydney\u0026rsquo;s Youtube page and it is about making wax hands at Madame Tussauds Sydney, where they make moulds of people hands out of liquid wax, by following a few simple steps.\nThe process involves dipping people hands into cold water, and then dipping their hands in liquid wax. This is repeated about 5 times, to make a mould of the hands.\n  The Art Of Making Wax Hands: English Video Translation From English To Hindi\n   Steps   Please open your browser and go to videotranslator.ai, and then click on the Loginbutton. On successfully log-In into the application, select myTemplate, and create a new item MTS.\n    The Art Of Making Wax Hands: Add a new item \u0026#39;MTS\u0026#39;      Upload the video, and trigger the transcribe action. Select the language preferred for the video. People in this video have Australian accent, so we select language as English (Australia).\n    The Art Of Making Wax Hands: Trigger Transcription      Once transcription is complete, we quickly check it.\n    The Art Of Making Wax Hands: Human quick check for correction in English      We could add an overlay here, as shown below. Once you are happy with the transcript, move forward to the next step, and trigger the translation action. This will translate the captions from English to Hindi.\n  Final output The Art Of Making Wax Hands: Auto Overlay with Highlight (English)\n     After translation is complete, open translated item and check the translated caption, making edits as needed.\n    The Art Of Making Wax Hands: Human quick check for correction in Hindi      Once this is done, we move to final step selecting \u0026lsquo;Auto-Overlay\u0026rsquo; for the captions. In this case we chose a highlight as can be seen below.\n    The Art Of Making Wax Hands: Auto-Overlay with yellow highlight      That’s all. Thank you for reading this process and check out the final Auto-Overlay video here.\n  The Art Of Making Wax Hands: English Video Translation To Hindi\n     Conclusion In this post we converted a video from Madame Tussauds in Sydney from English into Hindi. This was done by first transcribing the video in English, and then translating the captions from English to Hindi.\nVideo Translator makes no representation of a relationship with Madame Tussauds Sydney. We are using publicly available content to showcase an interesting use case of our platform.\nPlease connect with us on LinkedIn, YouTube or Facebook for any comments, questions, or just to keep up to date with the work we do!\nWe are very grateful for your support!\nIf you are interested in trying out our technology, please try our platform or drop us an email at hello@videotranslator.ai.\n","permalink":"https://videotranslator.ai/news/the-art-of-making-wax-hands-english-to-hindi-video-translation/","tags":["English","Hindi"],"title":"The Art Of Making Wax Hands: English To Hindi Video Translation"},{"categories":["Retail","Video","Transcription","Translation","Languages"],"contents":"हमें यह वीडियो म्यूजियम ऑफ कंटेम्पररी आर्ट् ऑस्ट्रेलिया के वेबसाइट के यूट्यूब पृष्ठ से मिला है ।\nयह वीडियो एमसीए कलेक्शन के बंगू यिलबारा कला के बारे में है । बंगू यिलबारा शब्द अपने आप में कला के प्रयास का वर्णन है, और उस काम को बनाने का इरादा के लिए , प्रदर्शनी के लिए काम का वर्णन करने पर ज्यादा ध्यान केंद्रित नहीं करना है।\nप्रदर्शनी कुछ अतिरिक्त लेबल के बिना जीवन की वास्तविकता के साथ संपर्क में लाने के लिए, प्रयास और दृष्टि के लिए कलाकार अभ्यास से संबंधित कला को प्रदर्शित करने पर केंद्रित है।\nनीचे, हमारे पास मुख्य वीडियो है, अंग्रेजी में प्रतिलेखन के बाद, और हिंदी में अनुवादित।\n  एक प्रकृति की कला बंगू यिलबारा संग्रह: अंग्रेजी से हिंदी वीडियो प्रतिलेखन और अनुवाद\n   क़दम   कृपया अपना ब्राउज़र खोलें और यहां पर जाएं, और फिर लॉगिन बटन पर क्लिक करें । अनुप्रयोग में सफलतापूर्वक लॉगिन करने पर, माईटेम्पलेट का चयन करें और एमसीए फ़ाइल बनाए ।\n    एमसीए : एक नया आइटम जोड़ें \u0026#39;एमसीए\u0026#39;      वीडियो अपलोड करें और प्रदर्शन आकार समायोजित करें जैसा आप प्रदर्शित करना चाहते है ।\n    एमसीए : वीडियो समायोजन      जब आपने कर लिया तो । ट्रांस्टाइप क्रिया का चयन कर । वीडियो के लिए पसंदीदा भाषा का चयन करें । इस वीडियो में लोगों में सामान्य ऑस्ट्रेलियाई लहज हैं । तो हम अंग्रेजी (ऑस्ट्रेलिया) के रूप में भाषा का चयन करते है ।\n    एमसीए : प्रतिलेखन दबाए      एक बार प्रतिलेखन पूरा हो गया है तो, हम जल्दी से इसकी मानव प्रयास के साथ जांच करते है । और अंग्रेज़ी से हिंदी में कैप्शन का अनुवाद करने के लिए अनुवाद कार्रवाई का चयन कर दूसरे चरण पर आगे बढ़ते है ।\n  एक प्रकृति की कला बंगू यिलबारा संग्रह: अंग्रेजी से हिंदी वीडियो प्रतिलेखन और अनुवाद\n     एक बार अनुवाद की कार्रवाई की और पूरा किया, तो उस हिंदी अनुवाद फ़ाइल के लिए फ़ाइल नाम के साथ एक पॉप अप बॉक्स दिखाई देता है । फ़ाइल का नाम भरे और अनुवाद को सुरक्षित रखने के लिए सबमिट बटन दबाए।\n    एमसीए : नाम अनुवादित फ़ाइल      अनुवाद प्रक्रिया के सफल समापन पर अनुवादित फाइल को खोलें और वाक्यों को ठीक करने के लिए अनुवाद कैप्शन को देखें। एक बार यह हो जाने के बाद, हम वीडियो पर कैप्शन ओवरले के लिए अंतिम चरण \u0026lsquo;ऑटो-ओवरले\u0026rsquo; पर जाते हैं।\n    एमसीए : हिंदी में सुधार के लिए मानव त्वरित जाँच        एमसीए : ऑटो ओवरले दबाए      सब कर लिया गया! इस प्रक्रिया को पढ़ने के लिए धन्यवाद और अंतिम ऑटो-ओवरले वीडियो यहां देखें।\n  एक प्रकृति की कला बंगू यिलबारा संग्रह: अंग्रेजी से हिंदी वीडियो प्रतिलेखन और अनुवाद\n     निष्कर्ष इस पोस्ट में हमने \u0026lsquo;म्यूजियम ऑफ कंटेम्पररी आर्ट् ऑस्ट्रेलिया\u0026rsquo; के हिंदी कैप्शन के लिए अंग्रेजी से हिंदी वीडियो प्रतिलेखन और अनुवाद किया है ।\nजैसा कि वीडियो में अब हिंदी कैप्शन है, यह हिंदी कैप्शन वीडियो म्यूजियम ऑफ कंटेम्पररी आर्ट् ऑस्ट्रेलिया (एमसीए) को बढ़ावा देने में मदद करेगा और लोगों को बंगू यिलबारा कला के बारे में ज्यादा जानकारी देगा ।\nक्यूबीएल मीडिया म्यूजियम ऑफ कंटेम्पररी आर्ट् ऑस्ट्रेलिया (एमसीए) के संग्रहालय के साथ रिश्ते का कोई प्रतिनिधित्व नहीं करता है । हम अपने प्लेटफ़ॉर्म के एक दिलचस्प उपयोग को प्रदर्शित करने के लिए सार्वजनिक रूप से उपलब्ध सामग्री का उपयोग कर रहे हैं ।\nयदि आप हमारी तकनीक को आजमाने में रुचि रखते हैं, कृपया हमारे प्लेटफार्म का प्रयोग करे या हमें ईमेल भेजे यहां ।\n","permalink":"https://videotranslator.ai/news/%E0%A4%8F%E0%A4%95-%E0%A4%AA%E0%A5%8D%E0%A4%B0%E0%A4%95%E0%A5%83%E0%A4%A4%E0%A4%BF-%E0%A4%95%E0%A5%80-%E0%A4%95%E0%A4%B2%E0%A4%BE-%E0%A4%AC%E0%A4%82%E0%A4%97%E0%A5%82-%E0%A4%AF%E0%A4%BF%E0%A4%B2%E0%A4%AC%E0%A4%BE%E0%A4%B0%E0%A4%BE-%E0%A4%B8%E0%A4%82%E0%A4%97%E0%A5%8D%E0%A4%B0%E0%A4%B9-%E0%A4%85%E0%A4%82%E0%A4%97%E0%A5%8D%E0%A4%B0%E0%A5%87%E0%A4%9C%E0%A5%80-%E0%A4%B8%E0%A5%87-%E0%A4%B9%E0%A4%BF%E0%A4%82%E0%A4%A6%E0%A5%80-%E0%A4%B5%E0%A5%80%E0%A4%A1%E0%A4%BF%E0%A4%AF%E0%A5%8B-%E0%A4%AA%E0%A5%8D%E0%A4%B0%E0%A4%A4%E0%A4%BF%E0%A4%B2%E0%A5%87%E0%A4%96%E0%A4%A8-%E0%A4%94%E0%A4%B0-%E0%A4%85%E0%A4%A8%E0%A5%81%E0%A4%B5%E0%A4%BE%E0%A4%A6/","tags":["English","Hindi"],"title":"एक प्रकृति की कला बंगू यिलबारा संग्रह: अंग्रेजी से हिंदी वीडियो प्रतिलेखन और अनुवाद"},{"categories":["Retail","Video","Transcription","Translation","Languages"],"contents":"We got this video from Museum of Contemporary Art Australia\u0026rsquo;s Youtube page This video is about Bangu Yilbara collection at the MCA. The collection is focused on art produced by the Aboriginal and Torres Straits Islander cultures.\nThe exhibition focuses on the diversity of Aboriginal and Torres Straits Islander culture, primarily by looking to the artists to define their work, as opposed to labelling the work \u0026lsquo;Aboriginal\u0026rsquo; and boxing it into any particular style.\nBelow, we have the final video, after transcription into English, and translation into Hindi.\n  A Nature Of Art Bangu Yilbara Collection: English To Hindi Video Transcription And Translation\n   Steps   Please open your browser and go to videotranslator.ai, and then click on the Login button. On successfully log-In into the application, select myTemplate, and create a new item mca.\n    MCA: Add a new item \u0026#39;MCA\u0026#39;      Upload the video and adjust it\u0026rsquo;s display size you want to display.\n    MCA: Video Adjustment      Once you are done. Trigger the transcribe action. Select the language preferred for the video. People in this video has Australian accent, so we select language as English (Australia).\n    MCA: Trigger Transcribe      Once transcription is complete, we quickly check it with human effort. And move forward to other step to Trigger Translate action to translate captions from English to Hindi.\n  MCA: Trigger Translation\n     Once the Translate action is performed and complete, a pop up box appear with file name you want for that Hindi translation file. Input file name and click on Submit button to save the Translation.\n    MCA: Name Translated file      On successful completion of translation process open translated file and human check the Translation captions, to fix the sentences. Once this is done, we move to final step \u0026lsquo;Auto-Overlay\u0026rsquo; for the captions to Overlay on video.\n    MCA:Human quick check for correction in Hindi        MCA: Trigger Auto-Overlay      That’s all. Thank you for reading this process and check out the final Auto-Overlay video here.\n  MCA: Original Video with Hindi Overlay\n     Conclusion In this post, we have Transcribe and Translated English video content for Hindi Caption of \u0026lsquo;Museum of Contemporary Art Australia\u0026rsquo;. As the video now has Hindi captions, This Hindi Captions video will help to promote Museum Contemporary Art (MCA) and let people know more about Bangu Yilbara works.\nVideo Translator makes no representation of a relationship with Museum of Contemporary Art Australia (MCA). We are using publicly available content to showcase an interesting use case of our platform.\nIf you are interested in trying out our technology, please try our platform, or drop us an email at hello@videotranslator.ai.\nPlease connect with us on LinkedIn, YouTube or Facebook for any comments, questions, or just to keep up to date with the work we do!\n","permalink":"https://videotranslator.ai/news/a-nature-of-art-bangu-yilbara-collection-english-to-hindi-video-transcription-and-translation/","tags":["English","Hindi"],"title":"A Nature Of Art Bangu Yilbara Collection: English To Hindi Video Transcription And Translation"},{"categories":["Retail","Video","Video Transcription","Video Translation","Languages"],"contents":"ये वीडियो है म्यूजियम ऑफ एप्लाइड आर्ट्स एंड साइंसेज यूट्यूब चैनल। यह वीडियो म्यूजियम ऑफ एप्लाइड आर्ट्स एंड साइंसेज (मॉस) के परिधान और डिजाइन संग्रह के बारे में है।\nपरिधान संग्रह 18 वीं सदी से वर्तमान उदाहरण के टुकड़े को दर्शाता है। इन्हें मॉस के नए सेंटर फॉर फैशन में दिखाया गया है । कुल मिलाकर लगभग 30,000 अद्भुत टुकड़े हैं, जो मॉस, आशा करता हैं कि भविष्य की पीढ़ियों के फैशन डिजाइनरों को प्रभावित और प्रेरित करेंगे।\nमॉस के सेंटर फ़ॉर फ़ैशन में प्रदर्शित परिधान ऑस्ट्रेलिया में सबसे व्यापक है। इस नए प्रदर्शन के पीछे आशा है कि फैशन के सांस्कृतिक प्रभाव का मानचित्रण करना, और ऑस्ट्रेलिया के सांस्कृतिक इतिहास को लोगों द्वारा पहनने के माध्यम से प्रलेखित करना।\n  ऑस्ट्रेलियाई फैशन के माध्यम से एक यात्रा: अंग्रेजी से हिंदी में वीडियो प्रतिलेख और अनुवाद\n   क़दम   कृपया अपना ब्राउज़र खोलें और यहां पर जाएं, और फिर \u0026lsquo;लॉगिन\u0026rsquo; बटन पर क्लिक करें । अनुप्रयोग में सफलतापूर्वक लॉगिन करने पर, \u0026lsquo;माईटेम्पलेट\u0026rsquo; का चयन करें और \u0026lsquo;मॉस\u0026rsquo; फ़ाइल बनाएं।\n    मॉस : एक नया आइटम जोड़ें \u0026#39;मॉस\u0026#39;      वीडियो अपलोड करें, और प्रतिलेखन कार्रवाई का चयन करें। वक्ताओं में सामान्य ऑस्ट्रेलियाई लहज हैं । तो हम अंग्रेजी (ऑस्ट्रेलिया) के रूप में भाषा का चयन करते है ।\n    मॉस : प्रतिलेखन दबाए      एक बार प्रतिलेखन कार्रवाई १०० प्रतिशत पूरा हो गया तो, हम प्रतिलेखन की जांच करते है । ध्यान दें * कृत्रिम बुद्धिमत्ता कभी कभार मूल बनाना, अल्पविराम और वाक्यों में पूर्णविराम करना छोड़ देता है । ऐसा इसलिए है क्योंकि लोग अपने लिखने के तरीके को नहीं बोलते हैं, और इस मामले में हमें कृत्रिम बुद्धिमत्ता के अनुवाद का समझ बनाने के लिए लिखित सामग्री की आवश्यकता होती है ।\n    मॉस: अंग्रेजी में सुधार के लिए मानव त्वरित जांच      एक बार प्रतिलेखन में सुधार हो गया तो, हम अनुवाद कि कार्रवाई करते है ।\n  मॉस: अंग्रेजी कैप्शन\n     \u0026lsquo;वीडियो\u0026rsquo; के लिए \u0026lsquo;हिंद\u0026rsquo; पसंदीदा भाषा के रूप में अनुवाद के लिए \u0026lsquo;स्वचालित\u0026rsquo; चुनें ।\n    मॉस : अनुवाद दबाए      अनुवाद की प्रक्रिया पूरी होने के बाद, हम जल्द से जल्द अनुवाद की जांच करते हैं और शब्दों को ठीक करते हैं ।\n    मॉस: हिंदी में सुधार के लिए मानव त्वरित जाँच      एक बार अनुवाद ठीक हो गया! तो। हम वीडियो पर शब्दों को अनुबादित करने के लिए अंतिम चरण \u0026lsquo;ऑटो-ओवरले\u0026rsquo; पर जाते हैं ।\n  ऑस्ट्रेलियाई फैशन के माध्यम से एक यात्रा: अंग्रेजी से हिंदी में वीडियो प्रतिलेख और अनुवाद\n     सब कर लिया गया! आप को ऑस्ट्रेलियाई फैशन के माध्यम से एक यात्रा: अंग्रेजी से हिंदी में वीडियो प्रतिलेख और अनुवाद की इस प्रक्रिया को पढ़ने के लिए धन्यवाद ।\n  निष्कर्ष इस पोस्ट में हमने म्यूजियम ऑफ एप्लाइड आर्ट्स एंड साइंसेज (मॉस) के एक अंग्रेजी वीडियो को बदल दिया है । हमने, पहले अंग्रेजी में वीडियो प्रतिलेख किया, फिर हिंदी में अनुवाद, और अंत में शब्दों को वीडियो के ऊपर अनुबादित कर वीडियो में कैप्शन सामग्री जोड़ दिया ।\nयदि आप ऐसी अनुवादित सामग्री को ऑनलाइन पोस्ट करते हैं, तो इस मामले में शीर्षक, विवरण और अन्य मेटाडेटा को लक्ष्य स्क्रिप्ट में अनुवाद करने की सिफारिश की जाती है, इस मामले में यह आपके हिंदी एसईओ में सुधार करेगा, जिससे देशी हिंदी बोलने वालों को आपकी सामग्री की समझ ऑनलाइन मिल सकेगी ।\nक्यूबीएल मीडिया ऑस्ट्रेलिया में एप्लाइड आर्ट्स एंड साइंसेज के संग्रहालय (मॉस) के साथ संबंध का कोई प्रतिनिधित्व नहीं करता है । हम सार्वजनिक रूप से उपलब्ध सामग्री का उपयोग कर रहे है हमारे मंच के एक दिलचस्प उपयोग के मामले को प्रदर्शित करने के लिए ।\nयदि आप हमारी तकनीक को आजमाने में रुचि रखते हैं, कृपया हमारे प्लेटफार्म का प्रयोग करे या हमें ईमेल भेजे यहां ।\n","permalink":"https://videotranslator.ai/news/%E0%A4%91%E0%A4%B8%E0%A5%8D%E0%A4%9F%E0%A5%8D%E0%A4%B0%E0%A5%87%E0%A4%B2%E0%A4%BF%E0%A4%AF%E0%A4%BE%E0%A4%88-%E0%A4%AB%E0%A5%88%E0%A4%B6%E0%A4%A8-%E0%A4%95%E0%A5%87-%E0%A4%AE%E0%A4%BE%E0%A4%A7%E0%A5%8D%E0%A4%AF%E0%A4%AE-%E0%A4%B8%E0%A5%87-%E0%A4%8F%E0%A4%95-%E0%A4%AF%E0%A4%BE%E0%A4%A4%E0%A5%8D%E0%A4%B0%E0%A4%BE-%E0%A4%85%E0%A4%82%E0%A4%97%E0%A5%8D%E0%A4%B0%E0%A5%87%E0%A4%9C%E0%A5%80-%E0%A4%B8%E0%A5%87-%E0%A4%B9%E0%A4%BF%E0%A4%82%E0%A4%A6%E0%A5%80-%E0%A4%AE%E0%A5%87%E0%A4%82-%E0%A4%B5%E0%A5%80%E0%A4%A1%E0%A4%BF%E0%A4%AF%E0%A5%8B-%E0%A4%AA%E0%A5%8D%E0%A4%B0%E0%A4%A4%E0%A4%BF%E0%A4%B2%E0%A5%87%E0%A4%96-%E0%A4%94%E0%A4%B0-%E0%A4%85%E0%A4%A8%E0%A5%81%E0%A4%B5%E0%A4%BE%E0%A4%A6/","tags":["English","Hindi"],"title":"ऑस्ट्रेलियाई फैशन के माध्यम से एक यात्रा: अंग्रेजी से हिंदी में वीडियो प्रतिलेख और अनुवाद"},{"categories":["Retail","Audio","Transcription","Visual Guides"],"contents":"This post covers how to transcribe audio content. We will use a podcast as our sample audio content, and assume you are on a free trial. This post covers:\n Sign into the application. Create an audio specific template. Create a new item, with our audio specific template as parent. Upload our podcast, and then use an Artificial Intelligence (AI) to transcribe our content.  On reviewing this visual guide, you will be able to upload your own audio content, and transcribe using an AI.\nA quick summary of the process below is, to start with we create a new template audioTemplate which we setup specifically for podcasts as a once off. Then, we will use this to create an audio item, myFirstPodcast of type audioTemplate, for transcription.\nSteps - Create An Audio Template   Please open your browser and go to videotranslator.ai, and then click on the Login button. Assuming you just registered for the free trial, the below is what you should see when you sign into the application.\n    Audio To Text: Register for the Free Trial, then Login      Normally, we could just use myTemplate. However, as this is a visual guide, we will make a new template, and do this the long winded way. Click on the New Template button, and use audioTemplate for the name as shown in the below image and Submit.\n    Audio To Text: New Template \u0026#39;audioTemplate\u0026#39;      This is a new template, and we are going to add an Audio component. Click the Add Fields button, then select Audio, as shown below.\n    Audio To Text: Add an audio component (field)      Once added, expand the audio component using the highlighted + button. The other highlight is what the audio component will look like once we create a new item.\n    Audio To Text: Audio component expanded      Use the action bar to Publish the template. This makes the template usable to create new items. We have also changed the Information to be Please upload the podcast?, this change is purely cosmetic.\n    Audio To Text: Publish \u0026#39;audioTemplate\u0026#39;      Exit the template editor. Your Root will now look like the below image. The green is a visual indicator indicating that this template was just created. You have successfully created your \u0026lsquo;audioTemplate\u0026rsquo;.\n    Audio To Text: \u0026#39;audioTemplate\u0026#39; is now ready      Why am I doing this? The template editor provides you the flexibility to tailor your template to your specific use case. Specifically, in addition to the \u0026lsquo;audio component\u0026rsquo; we added into our template, you could add:\n Image Fields: Assuming you were uploading your content into a third party audio sharing service, you can add a poster or banner image, which should boost engagement. Text Fields: Assuming you were uploading your content into a third party audio sharing service, you can add a title, description and other metadata as additional text fields. Uploading these increases SEO substantially, and this effect is magnified if we were to also translate the audio content.  Should I do this every time? No - absolutely not. The entire idea of a template is to create a data structure which meets your specific use case and reuse it every time.\nSteps - Create An Audio Item, and Transcribe   Click audioTemplate, and then click Add New Item to create an item of type audioTemplate as shown below.\n    Audio To Text: Create \u0026#39;myFirstPodcast\u0026#39;      Today, we will use a podcast from the Creative Commons team, known as Plays Well With Others. We are big fans of the work Creative Commons does, and you should check them out if you are not familiar with the contribution of CC to modern open source software.\n  Upload the *.mp3, and you should see something like the below image.\n    Audio To Text: Upload your podcast      Now, trigger the transcription. We used American English in this case. Accept to start the process. The item will exit, and lock itself until the AI completes the transcription process.\n    Audio To Text: Transcribe your podcast      You are done! Click on the Captions to see the results of the AI. We recommend checking/editing to make sure the AI has transcribed your podcast properly. Remember, check grammar and capitalisation. In the below, 'plays well with others' is not capitalised. The AI did not pick this up, because it was spoken normally, not especially pronounced. People do not speak like the rules of English require us to write unfortunately.\n    Audio To Text: Transcript of your podcast      Conclusion In this visual guide, we used the application to transcribe an English podcast with AI assistance.\nPlease connect with us on LinkedIn, YouTube or Facebook for any comments, questions, or just to keep up to date with the work we do!\nWe are very grateful for your support!\nIf you are interested in trying out our technology, please try our platform or drop us an email at hello@videotranslator.ai.\n","permalink":"https://videotranslator.ai/news/visual-guide-audio-to-text/","tags":["English"],"title":"Visual Guide: Audio To Text"},{"categories":["Retail","Video","Transcription","Translation","Visual Guides","Languages"],"contents":"This video is from Museum of Applied Arts and Sciences Youtube channel. This video is about the garments and design collection at the Museum of Applied Arts and Sciences (MAAS).\nThe garment collection covers pieces from the 18th century to present day examples. These are shown at the new Centre For Fashion at MAAS. There are around 30,000 amazing pieces in total, which MAAS hopes will impact and inspire future generations of fashion designers.\nThe garment exhibit at MAAS\u0026rsquo;s Centre For Fashion is among the most comprehensive in Australia. The hope behind this new exhibit is to map the cultural impact of fashion, and to document the cultural history of Australia through what people wear.\n  A Journey Through Australian Fashion: English To Hindi Video Transcription And Translation\n   Steps   Please open your browser and go to videotranslator.ai, and then click on the Login button. On successfully logging into the application, select my template, and create a new item maas.\n    MAAS: Add a new item \u0026#39;maas\u0026#39;      Upload the video, and trigger the transcribe action. The speakers are from Australia, so we use the Australian English option.\n    MAAS: Trigger Transcription      Once the transcribe action is 100% complete, we check the transcription. The AI sometimes misses to capitalisation, comma\u0026rsquo;s and full stop in sentences. This is because people do not speak the way they write, and in this case we require the written content to make sense to the translation AI.\n    MAAS: Quick check of English captions      We embed the English captions to produce the below.\n  MAAS: English captions\n     Once the correction in transcription is done, we move to translate the captions. Select \u0026lsquo;Automatic\u0026rsquo; for AI translation with language selected to \u0026lsquo;Hindi\u0026rsquo; for \u0026lsquo;Video\u0026rsquo;.\n    MAAS: Trigger Translation      After the translation process is complete, we quickly check the translation and make any corrections.\n    MAAS: Check Translation      Once this translation is good, we embed the captions into the video.\n  Now with Hindi Open Captions\n     All done! Thank you for reading this process of \u0026lsquo;A Journey Through Australian Fashion: English To Hindi Video Transcription And Translation\u0026rsquo;.\n  Conclusion In this post, we have converted a video from the Museum of Applied Arts and Sciences (MAAS), from English to Hindi. We did this by, first transcribing the video in English, then translating the captions into Hindi, and finally embedding the caption content into the video using the Auto-Overlay function.\nIf you were to post such translated content online, it is recommended to also translate the title, description and other metadata into the target script, in this case Hindi. This will improve your Hindi SEO, allowing native Hindi speakers to find your content online.\nVideo Translator makes no representation of a relationship with Museum of Applied Arts and Sciences. We are using publicly available content to showcase an interesting use case of our platform.\nIf you are interested in trying out our technology, please try our platform or drop us an email at hello@videotranslator.ai.\nPlease connect with us on LinkedIn, YouTube or Facebook for any comments, questions, or just to keep up to date with the work we do!\n","permalink":"https://videotranslator.ai/news/a-journey-through-australian-fashion-english-to-hindi-video-transcription-and-translation/","tags":["English","Hindi"],"title":"A Journey Through Australian Fashion: English To Hindi Video Transcription And Translation"},{"categories":["Transcription","Translation","Retail","Video","Visual Guides"],"contents":"आज का वीडियो हयडे पार्क बैरक्स म्यूजियमस से है। यूटूब पेज, विशेष रूप से यह वीडियो है । हम इस वीडियो को अंग्रेजी से हिंदी में बदल देंगे ।\nहाइडल पार्क बैरक्स म्यूजियम नवीनीकरण के दौर से गुजर रहा है । इस 2019 के अंत तक पूरा होने की उम्मीद है । क्यूरेटर और शोधकर्ताओं द्वारा नए शोध की एक बड़ी मात्रा हाइड पार्क बैरक में स्थित संग्रहालय को फिर से खोलने के बाद दिखाए जाने की उम्मीद है। यह नया प्रदर्शन ऑस्ट्रेलिया की सिद्धदोष विरासत के बारे में है । प्रारंभिक औपनिवेशिक ऑस्ट्रेलिया में अपराधियों के प्रभाव का दस्तावेजीकरण किया गया है, आंखों के माध्यम से देखा स्थानीय आदिवासी लोगों, और बसने वाले दोनों ने।\n  वीडियो अनुवाद किया गया अंग्रेजी से हिंदी में: एक कोन्विक्ट हेरिटेज\n   क़दम   अपने ब्राउज़र को निर्देशित करें videotranslator.ai, और उसके बाद लॉगिन बटन पर क्लिक करें । सफलतापूर्वक लॉगिन होने पर, माईटेम्पलेट का चयन करें और बर्रैकस1 नामक एक नया आइटम बनाएं ।\n    एक कोन्विक्ट हेरिटेज : एक नया आइटम जोड़ें \u0026#39;बर्रैकस1\u0026#39;      वीडियो अपलोड करें, और ट्रांसक्रिप्शन का चयन करे। अधिकांश वक्ताओं में सामान्य ऑस्ट्रेलियाई लहजे हैं। तो हम प्रतिलेखन करने की भाषा के रूप में अंग्रेजी (ऑस्ट्रेलिया) का चयन करते है।\n    एक कोन्विक्ट हेरिटेज : \u0026#39;दबाए प्रतिलेखन\u0026#39;      एक बार प्रतिलेखन पूरा हो गया तो, हम जल्दी से प्रतिलेखन की जांच करते है। यह मूल बनाना जोड़ें और व्याकरण ठीक करे के लिए है।\n    एक कोन्विक्ट हेरिटेज : मूल बनाना जोड़ें और व्याकरण ठीक करे      अब हम संपत्ति में कैप्शन जोड़ने के लिए + बटन पर क्लिक करते है। परिणाम नीचे दिखाया गया है ।\n  एक कोन्विक्ट हेरिटेज : अंग्रेजी शीर्षक जोड़ें\n     अब हम हिंदी में अनुवाद करना चाहते हैं । जैसा कि हमारे पास कैप्शन है, हम हिंदी में अनुवाद की कार्रवाई शुरू कर सकते हैं। एक बार अनुवादित होने पर हम हिंदी अनुवाद की जांच करते हैं और किसी भी त्रुटि को ठीक करते हैं ।\n    एक कोन्विक्ट हेरिटेज : हिंदी में अनुवादित      अब, हमारे वीडियो में हिंदी कैप्शन जोड़ने के लिए ऐड कैप्शन करे। यह निष्कर्षित परिणामी है।\n  वीडियो अनुवाद किया गया अंग्रेजी से हिंदी में: एक कोन्विक्ट हेरिटेज\n     सब हो गया! इस पोस्ट को पढ़ने के लिए अपना समय देने का धंयवाद।\n  निष्कर्ष इस पोस्ट में, हम ने हाइड पार्क बैरक्स का एक वीडियो अंग्रेजी से हिंदी में परिवर्तित किया। कैप्शन का मूल्य केवल हिंदी बोलने वाले किसी व्यक्ति की सहायता के रूप में नहीं है। यह एसईओ के लिए भी है । आप शीर्षक, वर्णन और अंय मेटाडेटा का भी अनुवाद कर सकते है। इसके बिना भले ही अब वीडियो में हिंदी कैप्शन हो, लेकिन कोई भी व्यक्ति बिना उचित हिंदी एसईओ के उसे ढूंढ नहीं पाएगा।\nक्यूबीएल मीडिया हाइड पार्क बैरक्स संग्रहालय के साथ एक रिश्ते का कोई प्रतिनिधित्व नहीं करता है। हम सार्वजनिक रूप से उपलब्ध सामग्री का उपयोग कर रहे है, हमारे मंच के एक दिलचस्प उपयोग के मामले को प्रदर्शित करने के लिए।\nयदि आप हमारी तकनीक को आजमाने में रुचि रखते हैं, तो कृपया हमारे प्लेटफार्म का प्रयोग करे या हमें ईमेल भेजे यहां hello@videotranslator.ai।\n","permalink":"https://videotranslator.ai/news/%E0%A4%B5%E0%A5%80%E0%A4%A1%E0%A4%BF%E0%A4%AF%E0%A5%8B-%E0%A4%85%E0%A4%A8%E0%A5%81%E0%A4%B5%E0%A4%BE%E0%A4%A6-%E0%A4%95%E0%A4%BF%E0%A4%AF%E0%A4%BE-%E0%A4%97%E0%A4%AF%E0%A4%BE-%E0%A4%85%E0%A4%82%E0%A4%97%E0%A5%8D%E0%A4%B0%E0%A5%87%E0%A4%9C%E0%A5%80-%E0%A4%B8%E0%A5%87-%E0%A4%B9%E0%A4%BF%E0%A4%82%E0%A4%A6%E0%A5%80-%E0%A4%AE%E0%A5%87%E0%A4%82-%E0%A4%8F%E0%A4%95-%E0%A4%95%E0%A5%8B%E0%A4%A8%E0%A5%8D%E0%A4%B5%E0%A4%BF%E0%A4%95%E0%A5%8D%E0%A4%9F-%E0%A4%B9%E0%A5%87%E0%A4%B0%E0%A4%BF%E0%A4%9F%E0%A5%87%E0%A4%9C/","tags":["English","Hindi"],"title":"वीडियो अनुवाद किया गया अंग्रेजी से हिंदी में: एक कोन्विक्ट हेरिटेज"},{"categories":["Transcription","Translation","Retail","Video","Visual Guides"],"contents":"Today\u0026rsquo;s video is from the Hyde Park Barracks Museum\u0026rsquo;s Youtube page, specifically this video. We will convert this video from English to Hindi.\nHyde Park Barracks Museum is undergoing a refurbishment. This is expected to be complete late 2019. A large amount of new research by curators and researchers based at Hyde Park Barracks is also expected to be shown once the museum is reopened.\nThis new exhibit is about Australia\u0026rsquo;s convict heritage. The impact of convicts in early colonial Australia is documented, seen through the eyes of both the local aboriginal people, and the settlers.\n  A Convict Heritage: English To Hindi Video Translation\n   Steps   Please direct your browser to videotranslator.ai, and then click on the Login button. On successfully logging into the application, select myTemplate and create a new item called barracks1.\n    A Convict Heritage: Add a new item \u0026#39;barracks1\u0026#39;      Upload the video, and trigger the transcription action. Most of the speakers have generic Australian accents. So we select language need to transcribe as English (Australia).\n    A Convict Heritage: Trigger Transcription      Once transcription is complete, we quickly check the transcription. This is to add capitalisation and grammar.\n    A Convict Heritage: Add Capitalisation and Grammar      We now click the + button to add the captions into the asset. The result is shown below.\n  A Convict Heritage: Add English Captions\n     Now we want to translate to Hindi. As we have the captions, we can trigger a translation action to Hindi. Once translated, we check the Hindi translation and fixed up any errors.\n    A Convict Heritage: Translate To Hindi      Now, we Add Caption to add the Hindi captions to our video. This is the resulting output.\n  A Convict Heritage: English To Hindi Video Translation\n     All Done! Thank you for taking the time to read this post.\n  Conclusion In this post, we converted a video from Hyde Park Barracks from English to Hindi.\nThe value of the captions is not simply as an assist for someone who speaks Hindi. It is also for SEO. You would also translate the title, description and other metadata. Without this, even though the video now has Hindi captions, no one would be able to find it without proper Hindi SEO.\nVideo Translator makes no representation of a relationship with Hyde Park Barracks Museum. We are using publicly available content to showcase an interesting use case of our platform.\nPlease connect with us on LinkedIn, YouTube or Facebook for any comments, questions, or just to keep up to date with the work we do!\nWe are very grateful for your support!\nIf you are interested in trying out our technology, please try our platform or drop us an email at hello@videotranslator.ai.\n","permalink":"https://videotranslator.ai/news/video-translation-from-english-to-hindi-a-convict-heritage/","tags":["English","Hindi"],"title":"Video Translation From English To Hindi: A Convict Heritage"},{"categories":["Video Translator","Retail","Video","Visual Guides"],"contents":"Everyone likes to try before they buy. This post is a visual guide to how to sign up for the free trial, and logging into the Video Translator platform. This post covers:\n Sign up for the free trial Select your preferred languages Verify your email address, and log into the application  On reviewing this visual guide, you should be able to sign up to Video Translator platform for free, and transcribe and translate up to 20 minutes of video content.\nSteps   Go to videotranslator.ai, and you should see the something like the below. Click on the Try Now button.\n    Video Translator website, with \u0026#39;Try Now\u0026#39; highlighted      This will take you to the free-trial page. Type in your email address, and select your preferred languages. You will be able to transcribe and translate content in these languages.\n    Free Trial: Language selector expanded to potential language choices      Select up to three (3) secondary languages during your trial period. You will be able to choose many languages. We recommend you choose a maximum of 3 languages to start with, in addition to English. It is possible to change your language choices, including adding/reducing available languages, prior to subscribing to the platform. In the below image, we have picked French and Chinese, in addition to English (our applications primary language).\n    Free Trial: English, French and Chinese have been selected      Click Sign Up, then Accept and Submit on the Terms Of Service. What are you getting?\n We pre-load your account with credits. Depending on your usage of the available Artificial Intelligences (AI\u0026rsquo;s), this will allow you to transcribe and translate 5 minutes of content. Assuming you subscribe at a later date, you will be prompted to add in your billing information within the platform. We use Stripe for our billing systems. We will not sell your email address to third-parties.      Free Trial: Terms Of Service      Congratulations! You have successfully sign up to the free trial. We will send you an email with your log in details.\n    Free Trial: Congratulations! You have successfully signed up!      You will receive an email, click on the link within to verify your account and set your password. Note, in the below image, we have used a test user email. When you sign up, the email will have your own address and a different token.\n    Free Trial: Successful sign up email - use the link to log into your account      On clicking the link, type in your name and a password as below. Then click Enroll.\n    Free Trial: Type in your name and password, then click Enroll      You are all logged in! You can now begin using AI to transcribe and translate your content.\n    Free Trial: Welcome to the Video Translator platform      Once you have logged in, you will receive a login confirmation email. Thank you for trying out our platform.\n  Conclusion Please connect with us on LinkedIn, YouTube or Facebook for any comments, questions, or just to keep up to date with the work we do!\nWe are very grateful for your support!\nIf you are interested in trying out our technology, please try our platform, or drop us an email at hello@videotranslator.ai.\n","permalink":"https://videotranslator.ai/news/visual-guide-free-trial-registration/","tags":["English","French","Chinese"],"title":"Visual Guide: Free Trial Registration"},{"categories":["Video Translation","Enterprise","Video","Dialects","Visual Guides"],"contents":"We got this video from OSL Brokerage\u0026rsquo;s LinkedIn page. We are not suggesting that we have any relationship with OSL, and largely, we are using this content to demonstrate the process by which video content can be translated.\nThis specific video already has captions, so we don\u0026rsquo;t need these per se. However, we will be adding Chinese captions as an overlay, as opposed to captions.\nThe final output is shown below. The video covers news in a specialist topic, so the translation below is not accurate, but will be close. I have yet to meet an AI that understands the word 'Ethereum'. Additionally, the stripe shown in the video has not been optimised, it cuts 1/2 way through so that the process makes sense. In practise, you would edit further to make it look nice.\n  OSL: Chinese captions \u0026#43; blue overlay\n   Steps   Please direct your browser to videotranslator.ai, and then click on the Login button. On successfully logging into the application, select the template, and using the highlighted button, Edit Template: myTemplate.\n  Check your template has the languages we need, English, and Chinese.\n    Template showing Language and Structure Options      Upload the video, and trigger the transcription action. In this case, the speaker has a generic English accent, and often the best option here is to use either American English or British English. In the below, we used the American English. Note, its a reasonable bet that the AI does not understand terms like Ethereum, so always get a subject matter expert to eyeball the results.\n    Trigger the Transcription with American English specified as the preferred dialect      Now, because we have the captions, trigger a translation to Chinese. In this case, we choose to translate into Simplified Chinese.\n    Trigger the Translation from English to Simplified Chinese      This give us the following output. It works, but is not exactly very good because this video already had captions. Note, this is just an AI - much like the above step, please have a subject matter expert eyeball the content and fix it up. Many of the words used in this context are specific, and it is a reasonable bet the AI will make mistakes.\n  OSL: Now with Chinese captions\n     How do we make this better? We use the Auto-Overlay function. Trigger the auto-overlay, and in this case, select the stripe option, as shown below.\n    OSL: Changing Captions -\u0026gt; Overlays      This is the resulting output. You can see that this is obviously NOT optimised, but both the Chinese overlay, and the original captioning can be seen for demonstration purposes.\n  OSL: Chinese captions and a blue overlay\n     Conclusion In this blog post we have covered how to add an audio overlay into your content. Please note, Video Translator makes no representation of a relationship with OSL Brokerage, we are simply using a publicly available content to do marketing on, because it allows us to showcase an interesting use case of the product.\nPlease connect with us on LinkedIn, YouTube or Facebook for any comments, questions, or just to keep up to date with the work we do!\nWe are very grateful for your support!\nIf you are interested in trying out our technology, please sign up here for a free trial. Alternately, drop us an email at hello@videotranslator.ai for questions, comments or feedback.\n","permalink":"https://videotranslator.ai/news/how-to-use-auto-overlay-to-simplify-transcription/","tags":["English","Chinese"],"title":"How To Use Auto Overlay To Simplify Transcription"},{"categories":["Video Translation","Retail","Enterprise","Management","Welcome","Translation Professionals","Translation Services"],"contents":"For the last 2 years or so, we have been working on a new platform which we think will be super useful for content creators. This includes marketers for exporters, tourism concerns, media shops and everyday folks looking to build brands and businesses using tools like YouTube and LinkedIn.\nJust for some background, we are a tiny software company, and think of ourselves as basically an independent studio, trying to craft the best tools we can. How tiny? Two and half men tiny. No, literally.\nIf you give our platform a shot, and think it is useful, do let us know. Most of this work was made possible by us digging deep, behind which was mostly normal folk being super engaged with our ideas and giving us heaps of encouragement.\nVideo Translator\u0026rsquo;s translation platform (\u0026ldquo;the application\u0026rdquo;) is an Internet-enabled SaaS (Software as a Service) platform which assists content creators (\u0026ldquo;the client\u0026rdquo;) to engage with stakeholders (\u0026ldquo;the audience\u0026rdquo;) from different linguistic backgrounds. The application is used to convert hypermedia content from one language to another, using an Artificial Intelligence (AI).\nLaunch We are super excited that we finally have our platform out there. The platform does only one thing really, and that is it uses AI in a sequence, to translate audio and video content. Effectively:\n Upload your audio/video content. Use a Speech-To-Text AI to transcribe the content. Use a Text-To-Text AI to translate the content. Use a Text-To-Speech AI to speak the content out in the target language.  Each of these AI\u0026rsquo;s can be used independently, or in a chain. The thinking behind this is optionality (the quality or state in which choice or discretion is allowed).\nWe do not know exactly what sequence each of these steps should be used in, for any specific use case. We want users to have the choice in how this could work.\n Do you want to use the Speech-To-Text AI only, just in English because your content is destined for a LinkedIn profile? Do you want to use the Text-To-Text AI only, because you have stakeholders who are trying to do a survey in several languages [the use case for multi lingual forms]? Maybe you are a social enterprise, looking to raise awareness in a rural area where people are not very educated or computer literate?  Let us know how you choose to use our product - we would be very excited to learn about the various use cases!\nWe would be very grateful if you tried out product, and let us know what you think!\nConclusion Please connect with us on LinkedIn, YouTube or Facebook for any comments, questions, or just to keep up to date with the work we do!\nWe are very grateful for your support!\nYou should try our product! And then let us know what we can do better! Feedback or Questions? We\u0026rsquo;d love to hear from you. Do let us know at hello@videotranslator.ai.\n","permalink":"https://videotranslator.ai/news/we-just-launched-and-we-need-luck/","tags":["English"],"title":"We Just Launched And We Need Luck"},{"categories":["Video Translator","Retail","Enterprise","Video","Visual Guides"],"contents":"We are a Sydney based, media focused technology platform provider, looking to make the world a more accessible place. Our primary value proposition is a transcription and translation platform, with a focus on audio and video content.\nVideo Translator\u0026rsquo;s translation platform (\u0026ldquo;the application\u0026rdquo;) is an Internet-enabled SaaS (Software as a Service) platform which assists content creators (\u0026ldquo;the client\u0026rdquo;) to engage with stakeholders (\u0026ldquo;the audience\u0026rdquo;) from different linguistic backgrounds. The application is used to convert hypermedia content from one language to another, using an Artificial Intelligence (AI) assisted process.\nExplainer Video We are super excited to announce that we have an explainer video finally, all thanks to the wonderful Tarryn Myburgh at TMCreates.\n  Video Translator: Explainer Video\n   Did you like it? Let us know what you think!\nConclusion Please connect with us on LinkedIn, YouTube or Facebook for any comments, questions, or just to keep up to date with the work we do!\nWe are very grateful for your support!\nWe hope you enjoyed our explainer video. Feedback or Questions? We\u0026rsquo;d love to hear from you. Do let us know at hello@videotranslator.ai.\n","permalink":"https://videotranslator.ai/news/we-have-an-explainer-video/","tags":["English"],"title":"We Have An Explainer Video"},{"categories":["Transcription","Translation","Video","Dialects"],"contents":"Video translation is all the rage in Sydney currently. It sounds hard to believe, but this is honestly the case at the moment. The controversy revolves around a secret video, which the current Australian Prime Minister, Scott Morrison has (apparently) recorded.\nThe gist of the news is that the Australian Prime Minister has recorded a video, which will be translated into a number of languages. Once translated, the video will be broadcast in the media in different countries including Indonesia, Malaysia, Thailand, Pakistan, Bangladesh, Sri Lanka, Afghanistan and Iraq. Obviously this is a concerning message, but it can well be argued we live in concerning times.\nWhat we would like to do in today's post is show that sometimes, the stories are not all bad. Specifically, in this case we took a video from BorderTV, which is run by the Department of Home Affairs.\nToday we will do the following:\n We will use the Speech-To-Text AI Transcription to transcribe the video. In this case, the subject of the video Aliir Mayom Aliir is a professional football player (Australian Football League) who was born in South Sudan in a refugee camp. Once the transcription is complete, we will use the results and manually fix up the transcription. Following this, we will use the second AI to translate the content into Swahili, which the government is trying to popularise in South Sudan to encourage integration into the East African Economic Community.  The end result is shown below, please play to see the Swahili translation in the captions. Note, for a client facing asset, you would also translate the title, filename and associated metadata into Swahili, the idea being search engines can properly index the content.\n  Aliir’s story: Swahili captions\n   Context Globally human trafficking is a serious law enforcement challenge. We do not particularly have ideas about how to combat this challenge. We think that serious people are looking into this, and if it makes sense for PM Morrison to make this video, there is probably good reason behind it, seeing as he has better access to information from law enforcement. Snippets from this video have surfaced on the Internet, below is from ABC News sourced from here.\n  Operation Sovereign Borders: Warning to People Smugglers\n   We picked our choice of video to translate below to show that not all stories fit in boxes, and solutions need to include this reality. It is possible to notice that people of African descent are over represented in the crime statistics, and to simultaneously recognise that having African genes can be an advantage for a sports person.\nThese issues are complicated, but we think more stories need to be heard, and maybe we get lucky and our product helps someone find their voice.\nSteps  The original video was sourced from the Border TV\u0026rsquo;s channel. Cynical minds may consider this a public relations exercise by the Department Of Home Affairs. However, these stories are real, and the information is well worth understanding before coming to conclusions on this very contentious topic.  Steps - Setting Up Swahili   So the first issue is that we need to add Swahili into our list of languages. Here we are assuming that you do not usually translate video content from English into Swahili, so you may need to add in this language.\n  Click into Finance, and check you have an appropriate set of languages. In the below image, we unfortunately do not have Swahili available. However, we are only using 4/5 of our available languages, so click and add Swahili and it will become available. To check you have successfully added Swahili, the tile should be green.\n    Finance: Language Settings shows we do not have Swahili available      The next step is to make sure our template is setup to handle Swahili. Click on myTemplate and then click to edit as shown below.\n    Edit the Template      Now, open up your Language Settings and Add Swahili. Note this is only required if you did not select Swahili when you signed up. This will already be in place if you signed up with Swahili. Here, we are assuming you need to translate a video into Swahili as a once off.\n    Edit the Template: Before Swahili is added        Edit the Template: After Swahili is added      Save and Exit your template. Then add a new item for the video content as shown below.\n    New Item: Using myTemplate now that Swahili has been added      Steps - Transcription, and Translation into Swahili   Upload the video, and click Transcribe. We used Australian English for the dialect here, as shown below.\n    Transcription: Australian English      After transcription, the below result is shown below. There was quite a lot of correction/addition after 1:30 -\u0026gt; 1:40. This is because Aliir is talking about a fairly emotional time for himself and his family, so the intonation is quite different, and the AI struggled with this.\n  Aliir’s story: English captions\n     Now we translate. Using the same Action -\u0026gt; Translation, we can translate from Australian English to Swahili.\n    Translation: Australian English to Swahili      The end result after the translation from English to Swahili is shown below. Note, for your own projects, always have someone who speaks the target language eyeball the results. The process shows an AI, which is likely to be very close to correct, but probably wrong in a few small ways.\n  Aliir’s story: Swahili captions\n     Conclusion In this post we tested the flow into Swahili. We are also hoping that you were able to see that most complicated stories have many sides, and any solution is likely to need both empathy and hard-headedness in equal measure.\nThe reality is that global human trafficking is a major law enforcement challenge. We do not know how to combat this challenge. However, we think a tool such as this could be used to provide more people with better access to information, in a language they understand. As part of a larger strategy, with any luck, this might be useful.\nPlease connect with us on LinkedIn, YouTube or Facebook for any comments, questions, or just to keep up to date with the work we do!\nWe are very grateful for your support!\n","permalink":"https://videotranslator.ai/news/how-to-reach-refugees-and-combat-people-smugglers-with-ai/","tags":["English","Swahili"],"title":"How To Reach Refugees, And Combat People Smugglers, With AI"},{"categories":["Transcription","Translation","Video","Conservation","Dialects"],"contents":"As part of our process for testing the platform prior to go live, one of the things we look to do is test a large number of different languages. Part of it is good fun, the other objective is to try to change things around to see if we can break the platform and find bugs.\nRealistically, this means looking for cool videos, and then trying things out with the videos. As an added bonus, we can reach out to the people who made the original video, and normally, people are only too happy for us to experiment with their content.\nToday, we look at this video from the Kevin Richardson Foundation, starring Bongani the Lion, and Kevin. If you don\u0026rsquo;t know who these folks are, you should totally go check out their Youtube channel, because the work they are doing is amazing.\nIn today\u0026rsquo;s post, we are going to take this video from the LionWhispererTV and:\n Use the Speech-To-Text AI Transcription to transcribe the video. We will choose English (South Africa) for our dialect as part of the video transcription process. Fix up the results of the transcription. Use the AI Translation from English to Afrikaans to translate the video.  Please note we have not cleaned up the Afrikaans text. The below video from LionWhispererTV is Bongani's Birthday. Bongani is the friendly male lion this video is about. In the video, Kevin refers to Bongani the lion as, 'a nice old man, but full of beans'.\n  LionWhispererTV: English (South Africa) with Afrikaans captions\n   We choose this video for two purposes, first the work that the Kevin Richardson Foundation is doing is pretty amazing. You only have to look at the video titled Lion Kisses here, to see what we are talking about. Trust me on this one.\nSecondly, a large part of their work is in raising awareness. While we have no idea what the exact level of awareness in South Africa relating to conservation efforts is, we do know South Africa has a large number of languages, and getting information out remains a challenge.\nSteps   The original video was sourced from the LionWhispererTV\u0026rsquo;s channel. We are big fans of their work, and you should absolutely subscribe to their channel.\n  Please direct your browser to videotranslator.ai, and then click on the Login button. Select myTemplate, or your preferred template, and create a new item. Note to follow this visual guide you will require only a video component in your template.\n  Once in the new item, please upload your video. In this example, we upload the LionWhispererTV video, and your screen should look like below.\n    Upload the LionWhispererTV video      Next, click on Actions -\u0026gt; Transcribe, and you should see something like the below. We have selected English (South Africa) here. Obviously, Kevin is South African, and the Kevin Richardson Foundation reserve is in South Africa, so this makes sense and we would expect the AI transcription to be pretty much on point.\n    Transcription with English (South Africa) as our dialect choice      After triggering this action, the platform will close this item, and lock it. Once transcription is complete, this will automatically unlock.\n  Open up the item, and have a look at the captions. The main task here, is to fix up the transcription. The notes section below covers some of the issues around this specific video. After fixing up, the end result is below.\n  Bongani’s Birthday! Post transcription with English captions\n     Now that we have our transcription sorted, we can translate. Click Action -\u0026gt; Translation, to trigger the video captions being translated. This is a pretty simple process, and can be seen in the image below.\n    Translation of Bongani’s Birthday! from English to Afrikaans      Once the translation process is complete, the below result is available. In the application, this looks like below. Also, please note the Origin toggle, allowing a user to flick back and forth - this functionality is for use when a human translator is checking the work of the AI.\n    Captions post translation, in Afrikaans      The final version of the video is shown below. In a real workflow, please ask your subject matter expert to eyeball the translation and verify suitability for your stakeholders.\n  Bongani’s Birthday! Captions translated from English to Afrikaans\n     Notes How do you work with many different dialects, specifically which AI should we use? In this video, we see the following features:\n Kevin Richardson is speaking in clear South African English. So in this case, we obviously choose English (South Africa). It should be noted, that the clean up process was very short in the case of this particular video. One issue of note in Bongani’s Birthday! At 1:10 Kevin says, \u0026lsquo;there go Suja and Bongani\u0026rsquo;. The AI completely missed this line. In the end, we did not add it in, because it does not make a lot of sense in the context of what content will be translated, but the change in tone made a huge difference to the output of the transcription AI.  Conclusion In this post we tested the flow into Afrikaans, and with some luck, will be able to add more African languages in the future. We have Swahili in the translation AI, but Xhosa and Zulu currently require manual translation.\nPlease connect with us on LinkedIn, YouTube or Facebook for any comments, questions, or just to keep up to date with the work we do!\nWe are very grateful for your support!\nThe platform is currently in closed beta, while we work with early users to test/iron out issues. If you are interested in trying out our technology, please drop us an email at hello@videotranslator.ai.\n","permalink":"https://videotranslator.ai/news/how-to-use-ai-to-save-lions-in-afrikaans/","tags":["English","Afrikaans"],"title":"How To Use AI To Save Lions, In Afrikaans"},{"categories":["Transcription","Translation","Video","Dialects"],"contents":"Today, we will look at how to transcribe many different accents correctly. First off, what does this question even mean in terms of AI?\nThe video we are working with is from Institute for Communication in Health Care (ICH) at the Australian National University (ANU).\nLooking at the ICH\u0026rsquo;s mission statement, \u0026ldquo;The ICH’s mission is to build an international, collaborative research and training hub in healthcare communication to improve patient safety and quality of healthcare practice around the world\u0026hellip;\u0026rdquo;\nThis goal aligns with what Video Translator is doing, but from the point of view of this post, there is a number of different English accents being spoken in their video, which makes it an ideal test for this post.\nThe following process was followed to get the output:\n Use the Speech-To-Text AI Transcription to transcribe the video. Fix up the results of the transcription. Use the AI Translation from English to Chinese to translate the video.  Please note, we will not be fixing up the Chinese language translation post AI translation, as this post covers the process itself. For a client facing output, please work with a language aware subject matter specialist to ensure a high quality artefact at the end of your process.\n  ICH: English Original With Chinese Captions\n   First we will look at the process by which this video translation was completed. Then, a discussion on challenges and options around the video translation. Finally, some extra options and how they can be used to meet your client\u0026rsquo;s requirements.\nSteps   The original video was sourced from the ICH website.\n  Please direct your browser to videotranslator.ai, and then click on the Login button. Select myTemplate, or your preferred template, and create a new item. Note to follow this visual guide you will require a video component only in your template.\n  Once in the new item, please upload your video. In this example, we upload the ICH video, and your screen should look like below.\n    Upload the ICH video      Next, click on Actions -\u0026gt; Transcribe, and you should see something like the below. We have selected English (United Kingdom) here. Why exactly will be addressed in the discussion below.\n    Trigger the Transcription, with UK English for our dialect choice      After triggering this action, the platform will close this item, and lock it. Once transcription is complete, this will automatically unlock.\n  Open up the item, and have a look at the captions. The main task here, is to fix up the transcription. The heuristics section below covers some of the issues around this specific video. After fixing up, the end result is below.\n  ICH: English Original With English Captions\n     Sweet! Now that we have our transcription sorted, we can translate. Now, click Action -\u0026gt; Translation, to trigger the video captions being translated. This is a pretty simple process, and can be seen in the image below.\n    Trigger the Translation, with Simplified Chinese for our language/dialect choice      Once the translation process is complete, the below result is available. In the application, this looks like below. Also, please note the Origin toggle, allowing a user to flick back and forth - this functionality is for use when a human translator is checking the work of the AI.\n    Captions post translation, in Simplified Chinese      The final version of the video is shown below. In a real workflow, please ask your subject matter expert to eyeball the translation and verify suitability for your stakeholders.\n  ICH: English Original With Chinese Captions\n     Heuristics/Notes How do you work with many different dialects, specifically which AI should we use? In this video, we see the following features:\n There are five people speaking using the following accents, Australian English, American English, English as spoken in Hong Kong, and English as spoken by a person of European descent. This is the crux of the problem, which AI should we use? While experimenting, we tried both English (Australian) and English (UK). The results were different, but it seemed liked the English (UK) worked a little bit better - this is probably because the first speaker, Professor Diana Slade, does not have a classic Australian accent, but more of a mix of Australian English and British English. For each of the speakers, the AI had trouble during a transition from one speaker to another. The first instance of this is at 0:18 seconds, which is a simple (and nifty) cut scene, but totally threw the AI. In essence, the AI likes monotone and the same person speaking. Dr Elizabeth Rider, speaking from 1:11 worked fairly well. This is because the underlying AI has been trained on a significant volume of American content. The exact opposite was true for the voice over by Dr Angela Chan. Additionally, switching between the HK English dialect, and the European English dialect, was ugly. All in all using the UK English worked better, in terms of number of post AI translation changes required. This is likely because if there is a mix of accents, going with base English, for lack of better descriptors, is probably the way to go.  Conclusion In this post we looked at some of the trade off\u0026rsquo;s between using different dialect AI\u0026rsquo;s for transcription. This is a valid concern for English, Arabic and Spanish, because these languages have the largest number of possible dialects.\nThe platform is currently in closed beta, while we work with early users to test/iron out issues. If you are interested in trying out our technology, please drop us an email at hello@videotranslator.ai.\nPlease connect with us on LinkedIn, YouTube or Facebook for any comments, questions, or just to keep up to date with the work we do!\nWe are very grateful for your support!\n","permalink":"https://videotranslator.ai/news/how-to-transcribe-lots-of-different-accents-accurately/","tags":["English","Chinese"],"title":"How To Transcribe Lots of Different Accents Accurately"},{"categories":["Transcription","Translation","Video","Visual Guides","Languages"],"contents":"Today, we will cover simple heuristics to get the most out of your AI. As always, use the AI to do the heavy lifting, and use a human subject matter expert to finesse the results, producing a superior outcome with less time/effort.\nThe process followed is:\n Transcribe the Gram Marg (literally, \u0026lsquo;road map\u0026rsquo; in Hindi) video using Indian English. Clean up the transcribed Gram Marg video, and present simple heuristics to the the most out of your AI. Translate the video from English to Hindi.  The final result is below. Please note, we have not cleaned up the Hindi result, this post is specifically about the limitations of AI, and where the human subject matter expert needs to take stewardship over the AI.\n  Gram Marg: An English video translated into Hindi\n   For context from the website, Gram Marg's main aim is to empower rural India digitally by first and foremost bringing in Internet connectivity thereby empowering rural citizens digitally and in the due course, bringing rural India on board as a major contributor to economic growth and development.\nSteps   Please direct your browser to videotranslator.ai, and then click on the Login button. Select myTemplate, or your preferred template, and create a new item. Note to follow this visual guide you will require a video component in your template.\n  The original video was sourced from Mozilla\u0026rsquo;s YouTube channel, and was produced under the auspices of their Equal Rating project. The team behind Gram Marg won the competition, and you should check out their work here - it is a very interesting programme that could improve the lives of millions of people.\n  As a first step, create a new item 'gm_en' and upload the video. This should look like the below when you have finished uploading.\n    Gram Marg: Upload the video      Now, use Action -\u0026gt; Transcribe, and select Indian English as the dialect of choice.\n    Gram Marg: Transcribe the video in Indian English      This was then corrected manually as described in the heuristics section below. This gives us the same video with English captions, shown below.\n  Gram Marg: English captions\n     After that process, the content was translated using the Action -\u0026gt; Translate modal shown below.\n    Gram Marg: Translate the video from Indian English to Hindi      After the translation, we did not fix up the Hindi text. In a normal workflow, you would have a Hindi speaker eyeball and clean up the text for a superior result. The results are shown below.\n  Gram Marg: An English video translated into Hindi\n     Heuristics   Now, we have the captions - but how good were the actual captions? The following observations can be made:\n The quality of the captions was mixed- for example the transcription from 0:20 -\u0026gt; 0:30 was not good. The AI did not transcribe Gram Marg properly in any instance. The quality of transcription from 1:24 -\u0026gt; 1:32 was not particularly good. Memorably, the word 'broadcaster' was transcribed to 'Brock Lesnar'. The narrator uses extra words, in terms of saying 'the' and 'a', and also a few other words which had to be manually removed. Capitalisation was incorrect in a number of places, and grammar also had to be corrected in some spots.    Why did these errors occur, and what can the human subject matter expert do to address these challenges? Some simple fixes, and their context, employed were:\n Quite simply, an AI is only as good as its training. The Gram Marg video was explicitly chosen to show the limitations of the AI. The training of the underlying Indian English AI is not very good - so whose fault is that? The training issue is no error. The simple truth is there is not enough video content in Indian English about this subject matter - the conversion of UHF (Ultra High Frequency) band white spaces into carriers for mobile hotspots. Because the content does not already exist the AI cannot be trained enough to provide a high level of accuracy. Incidentally this is the primary reason why Gram Marg exists, to provide a platform for increasing digital literacy in rural India. Specific to the broadcaster issue, at a very simple level - how many times is the AI likely to have heard the word 'broadcaster' in Indian English during training - probably not that many. How many times has the AI heard the word 'Brock Lesnar' during training - many more. The AI defaulted to what it knows. More broadly, this is explicitly what we mean by use the human subject matter expert to do the high value tasks.    Ok - sometimes the AI gets confused. What about the other errors?\n The narrator - Prof Abhay Karandikar - like anyone without extensive media training, speaks in a normal fashion. He is trying to explain the idea, and is thinking about his answers as he speaks. This is normal, but not entirely appropriate for the next step of AI translation, hence needed correction. But why is it not appropriate for AI translation? People speak in a different way to how they write, especially different to how they write formally. The translation AI is trained primarily on text, and a lot of that text is written in formal styles. Hence, the various idiosyncrasies of how people talk, simply do not translate well into other languages.    Conclusion The actual fixes are quite simple - do not use the platform as a one and done solution. The platform, and the AI\u0026rsquo;s are very good at doing the heavy lifting, but in the end, both are simply software.\n Once the AI has finished, have a human subject matter expert eyeball and fix the results. For the majority of content the changes are likely to be minor, because most video\u0026rsquo;s are made of simple concepts so that they can reach a wide audience. Mostly, add grammar and capitalisation. Also remove extra capitalisation.  Video Translator\u0026rsquo;s platform provides a client with the ability to transcribe and translate video content to/from a number of languages, as discussed here.\nPlease connect with us on LinkedIn, YouTube or Facebook for any comments, questions, or just to keep up to date with the work we do!\nWe are very grateful for your support!\nThe platform is currently in closed beta, where it is being tested. If you are interested in trying out our technology, please drop us an email at hello@videotranslator.ai.\n","permalink":"https://videotranslator.ai/news/how-to-get-the-most-out-of-your-ai-english-to-hindi-video-translation/","tags":["English","Hindi"],"title":"How To Get The Most Out Of Your AI: English To Hindi Video Translation"},{"categories":["Transcription","Translation","Video","Right-To-Left","Visual Guides","Languages"],"contents":"Video Translator\u0026rsquo;s platform provides a client with the ability to transcribe and translate content to/from a number of languages, as discussed here. Today, we will be using the video translation platform on a video from our friends at ChangePlan. We will do the following:\n Transcribe ChangePlan\u0026rsquo;s video using Australian English. Fix up spelling/grammar in our captions. Translate ChangePlan\u0026rsquo;s video from English -\u0026gt; Hebrew.  If you are looking to replicate this process, please note, after the translation step, it is highly recommended that you have a Hebrew qualified subject-matter expert finesse the captions. As always, use the AI to do the heavy lifting, and your own subject-matter experts to do the high value tasks.\nThe end result is shown below. Please note we are using captions, and not text overlays, to produce the below. In captions, we cannot control the details quite as well - in this example, had we used text overlays, we could have set the Hebrew text to be right-to-left, but in captions we have simply set to centred.\n  ChangePlan: English, with Hebrew captions\n   A quick viewing of the video will show that certain words, such as ChangePlan, are not translated. This is due to the fact that there is no translation of ChangePlan in Hebrew, as this is a proper noun (technically, a named entity, for the NLP folks). In such cases, it is expected that the asset owner user phonetic transliteration, literally spell the sounds out in Hebrew. The Video Translator platform can be used for transliteration, see here for more information.\nSteps   Please direct your browser to videotranslator.ai, and then click on the Login button. Select myTemplate, or your preferred template, and create a new item. Note to follow this visual guide you will require a video component only in your template.\n  The original video was sourced from Gavin Wedell, the brains behind ChangePlan. You should totally check out his work if ChangePlan seems relevant to your use case.\n  Once in the new item, please upload the video, your screen should look similar to the below. In the below image, we have also scaled the size of the video.\n    Upload the ChangePlan video      Next, click on Actions -\u0026gt; Transcribe, and you should see something like the below. We have selected Australian English here, as we are in Sydney and the narration is in Australian English.\n    Trigger the Transcription, with Australian English for our dialect choice      After triggering this action, the platform will close this item, and lock it. Once transcription is complete, this will automatically unlock. We recently made this change after a testing period, to handle transcriptions for long video\u0026rsquo;s. If you have a video longer than 15 minutes or so, it is advised to trigger the transcription, and then do something else for a while.\n  Open up the item, and have a look at the captions. The main task here, is to fix up the transcription. Practically, this means:\n Add grammar, in terms of comma's and full stops, in the correct places. The Speech-To-Text AI tries to use intonation to work this out and this does not work. People, when speaking, use intonation to denote importance. People do not use intonation in a \u0026lsquo;grammatically correct\u0026rsquo; fashion, making the AI\u0026rsquo;s attempts interesting. Add capitalisation - it was important to capitalise ChangePlan, this is what triggers the AI to tread this as a named entity, and not attempt to translate ChangePlan as two different words. Remove capitalisation - in certain places, where the narration was important, the AI treated this as named entities. In this video, that meant the word 'agile' ended up incorrectly capitalised in various places. One must ensure these are removed, other wise the translation AI in the next step gets confused.    It took a few minutes to make the above changes. Once complete, click Action -\u0026gt; Translation, to trigger the video captions being translated. This is a pretty simple process, and can be seen in the image below.\n    Trigger the Video Translation, with Hebrew for our to-language choice      The translation process will run in the background, and a few seconds later the Hebrew clone appears. Looking at the captions, we can see the below.\n    Hebrew Translations populated in the ChangePlan video      Please note, if you are looking for more options, including right to left text, you could use the Text Overlays, as opposed to Captions, which look something like below. It is also possible to change fonts, colour and opacity. In addition, add animated image overlays, or full video overlays, is also possible.\n    Hebrew Translations populated as Text Overlays in the ChangePlan video      On completion, the original video looks like below. Note, the Hebrew text has not been cleaned up in the below, mostly so the process can be fully documented.\n  ChangePlan: English, with Hebrew captions\n     Conclusion In this post we have covered how to translate your video from English to Hebrew.\nThe platform is currently in closed beta, while we work out bugs in the code. If you are interested in trying out our technology, please drop us an email at hello@videotranslator.ai.\nExtra Gavin Wedell, and the folks at ChangePlan, are good guys. Go on, give their product a look!\nPlease connect with us on LinkedIn, YouTube or Facebook for any comments, questions, or just to keep up to date with the work we do!\nWe are very grateful for your support!\n","permalink":"https://videotranslator.ai/news/how-to-transcribe-english-into-hebrew-changeplan/","tags":["English","Hebrew"],"title":"How To Transcribe English Into Hebrew: ChangePlan"},{"categories":null,"contents":" OVERVIEW We look at the number of languages which you can use with your content. Remember, each languages is potentially a new market, and care needs to be taken to properly target your preferred leads.\nThere are two kinds of transcription, listed below. In both cases, speech is involved, hence these are referred to as transcription AI\u0026rsquo;s.\n Speech-To-Text Transcription AI Text-To-Speech Transcription AI  Similarly, with translation, what we are actually using is a Text-To-Text Translation AI.\nSPEECH-TO-TEXT TRANSCRIPTION: LANGUAGES The following languages are available within the Speech-To-Text AI. The context here is, (i) upload video, (ii) trigger transcription, (iii) select dialect as required, and the transcription AI will do the rest.\n    Example: Select a dialect to transcribe a French video    Please remember to check the captions and make corrections are required. The rule of thumb here is, use the AI to do the heavy lifting, and get a (human) subject matter expert to check the results for your subject matter\u0026rsquo;s (i.e. your industry) specific acronyms/words.\n           Afrikaans Aramaic Arabic Armenian Azerbaijani   Bulgarian Bengali Catalan Chinese Czech   Danish Dutch German English Spanish   Basque Filipino Finnish French Galician   Georgian Greek Gujarati Hebrew Hindi   Croatian Icelandic Indonesian Italian Japanese   Javanese Kannada Khmer Korean Lao   Latvian Lithuanian Hungarian Malay Malayalam   Marathi Nepali Norwegian Persian Polish   Portuguese Romanian Russian Serbian Sinhala   Slovak Slovenian Sundanese Swahili Swedish   Tamil Telugu Thai Turkish Urdu   Ukrainian Vietnamese Zulu      HOWS DOES VIDEO TRANSLATION WORK? AN EXAMPLE      Translate Your English Video Into Filipino And Chinese: How to translate your video into Filipino and Mandarin Chinese with AI    TEXT-TO-SPEECH TRANSCRIPTION: LANGUAGES The following languages are available within the Text-To-Speech AI. The context here is, (i) add audio, (ii) add the .srt or simply the text, (iii) trigger the transcribe.\nPlease note, additional voices are available, but use a less advanced AI (i.e. the synthetic voices feel more robotic).\n           Arabic Czech Danish Dutch English   Filipino Finnish French German Greek   Hindi Hungarian Indonesian Italian Mandarin   Japanese Korean Portuguese Spanish Swedish   Turkish Vietnamese Slovak Russian Polish   Portuguese Norwegian       SHOW ME THE MONEY? HOW SUBTITLING CAN BOOST ROI      AI Internationalization: How Subtitling Can Boost ROI    TEXT-TO-TEXT TRANSLATION: LANGUAGES The following languages are available within the Text-To-Text AI. The context here is, (i) upload content, (ii) trigger translation, (iii) select dialect as required, and the translation AI will do the rest. Below, the Automatic is the AI, while Human 1 is a in-house or external resource.\nIn practise, it is far more effective use of the translators time, allowing them to focus on the high value content, and be less involved in the simple translations.\n    Example: Select a language to translate a French video               Afrikaans Arabic Bengali Bosnian Bulgarian   Cantonese Catalan Chinese Croatian Czech   Creole Danish Dutch English Estonian   Fijian Filipino Finnish French German   Greek Creole Hebrew Hindi Hmong Daw   Hungarian Icelandic Indonesian Italian Japanese   Swahili Korean Latvian Malagasy Malay   Maltese Norwegian Persian Polish Portuguese   Romanian Russian Samoan Serbian Slovak   Slovenian Spanish Swedish Tahitian Tamil   Thai Tongan Turkish Urdu Ukrainian   Vietnamese Zulu       CONCLUSION Should you have any questions, or just want to drop us a note saying hello, please feel free to send us an email at hello@videotranslator.ai.\n","permalink":"https://videotranslator.ai/available-languages/","tags":null,"title":"Available Languages"},{"categories":null,"contents":" WHAT IS TRANSCRIPTION? Transcription is a process which converts speech (either live or recorded) into a written or electronic text document. Transcription services are often required for business, legal, or medical purposes.\nThe most common type of transcription is from a spoken-language source into text such as a computer file suitable for printing as a document such as a report.\nWHO ARE TRANSCRIPTS FOR?  Transcripts are very useful for people who are deaf, hard of hearing, or have some other hearing related disability. Adding transcripts to your content makes your content much more accessible. Making your content accessible is a good thing, but can also benefit you in unexpected ways. Hearing impaired people will often listen to your content, simply because transcripts are available, because they may not have many other choices! Many language learners find transcripts very useful, and would like to use your content to learn a foreign language. Reading the transcripts while they listen to the audio, or watch the video enables these listeners to enjoy your content. Transcripts are very good for Search Engine Optimisation (SEO). For audio, this could mean show notes or episode descriptions. For video this could mean title, description and other social media specific metadata. In certain social media channels, where the video is mute-played, open captions may be very useful.  Many people find transcripts very useful.\nWHAT IS TRANSCRIBING AUDIO? HOW MANY KINDS OF AUDIO TRANSCRIPTIONS ARE THERE? Transcribing audio is the process of converting an audio file from speech to text. For the most common case of podcasting, when transcribing audio there are three different approaches:\nSHOW NOTES (ALSO KNOWN AS EPISODE DESCRIPTIONS) It is very useful to add comprehensive show notes or episode descriptions. For good SEO we highly recommend:\n Write a thorough description making sure you spell check and grammar check. Highlight topics covered in the podcast while being mindful of commonly used search terms and topics. Add relevant links and resources, this will help your podcast rank better on search engines.  TRANSCRIPTS If done correctly transcripts of your podcast can be very useful. Follow the below guidelines:\n Post Edit your transcript to ensure accuracy. Remove unscripted banter such as \u0026lsquo;umms\u0026rsquo; and \u0026lsquo;ahhs\u0026rsquo; to make the transcript more suitable for search engines to index. Avoid repeated content which may be present in the introduction and closing portions of your podcast. If available, add a pdf or epub to the social media channel you are using to describe your podcast.  If you are looking to make your podcast accessible to hearing impaired, or otherwise disabled people, closed captioning should be added directly to the media file. Note that transcripts often do not syndicate with the underlying media object directly.\nCLOSED CAPTIONING Closed captioning is similar to transcripts. However, it will often include additional information for accessibility requirements, such as [CLAPPING] or [LAUGHTER] to describe events in the podcast.\n Add closed captions if you wish to make your podcast more accessible. Closed captions can be inserted into audio files like mp3/m4a audio and mp4/m4v video. Closed captions are generally inserted using ID3 tags in mp3 files for example. Depending on your use case, it may also be useful to provide a pdf transcript of your podcast.  WHAT MAKES FOR AN EFFECTIVE AUDIO TRANSCRIPTION? For much more effective audio transcription we recommend you consider the below suggestions.\nSPELLING AND GRAMMAR It is very important you do post-editing after any machine transcription. Even if you have manually transcribed your content, it is highly recommended you check the work prior to publishing.\nBad spelling and grammar makes reading your content harder, and any transcripts may not get indexed appropriately by search engines due to reduced accuracy.\nAnother Artificial Intelligence/Machine Language limitation is that people do not speak the same as they write. It is often required to add appropriate spelling edits (such as capitalisation for proper nouns) and grammar (the most common case is full-stops) post AI transcription.\nSIGNIFIERS It is quite important that you add signifiers to your transcript. This is doubly important for audio or podcast transcripts. This includes the number of speakers, names of the speakers, any characters the speakers may be playing, background noise, manner of speech etc.\nFORMATTING Formatting is often overlooked. There are two cases where this is quite important.\n In audio transcripts, consistency in marking speaker tags, indentation as well as font, and maintaining the same pattern throughout the whole document, are all very important to get right. The idea is that a nicely formatted audio transcript should be easy to read and make the experience a pleasurable one. In video transcription, use technology such as auto-overlay to use a nice font, font-size, font-colour to make it easy for the viewer to follow along. This is especially important in social media where the underlying video may be likely to be played in a audio-mute environment.  SUMMARISING, VERBATIM OR SHOW NOTES The idea here is to add appropriate information, both for your audience and for search engines (so your audience can find your content!).\n Summarising: This is very useful for short description fields in various social media channels. Verbatim: Use this for closed captions to promote accessibility for your content. Show Notes: Use this for long form social media search indexing. Ensure you do keyword searches and optimise for SEO/SEM.  HOW DO YOU TRANSCRIBE AUDIO? To transcribe audio content, follow the below process.\n Select your preferred language template, and create a new item. Upload your video and click Actions \u0026gt; Transcribe. Select the language and dialect of the video and click the accept button to trigger the transcription. The transcription process will run in the background. Once the transcription is complete, go through and check the transcription for proper grammar e.g. capitalisation and full stops. Embed the captions into the asset, or download the srt file separately.  HOW LONG DOES IT TAKE TO TRANSCRIBE AUDIO? While there is no official metric for how long transcription takes, when transcribing manually, it is generally accepted that transcription will take 4:1, or about four (4) times as long as the underlying content being transcribed.\nSo, for a fifteen (15) minute audio file, it would take about one (1) hour to transcribe manually. This is good for slow, clear speakers, with not much muffled or garbled audio and no one speaking over each other.\nMachine transcription is much quicker, but is affected by different factors. File size, bit rates, Internet speed, all these factors affect translation speeds. An easy approach is to use small files (video) optimised for the social media channel you are looking to deploy to, and not worry too much as AI is very quick.\nIn machine translation, you can use the rule of thumb as 1:4, or about quarter (1/4) times as long as the underlying content being transcribed. So, for a one (1) hour audio file, it would take about fifteen (15) minutes to transcribe with an Artificial Intelligence (AI), assuming a relatively high quality video file.\nWHAT FACTORS THAT AFFECT TRANSCRIPTION TIME FOR PEOPLE? Several factors can affect transcription time for people. We recommend you use Video Translator to do the first pass of the transcription, and then spend your time post-editing the result for maximum effectiveness.\nHowever, you may need to spend more time editing, under the following circumstances.\n Audio quality Single speaker or many? A worked example here. Background noise Coherence: Do the different speakers talk over each other? Are they emotional when they speak, and is it easy to understand? Do they speak quickly or slowly? Regional dialects: Make sure you choose the correct dialect from the available options to improve the transcription accuracy. Nomenclature: Names, places, specialised terminology, subject matter specific shorthand etc.  HOW MUCH DOES IT COST TO TRANSCRIBE AUDIO? The cost varies depending on the length of your audio. If you you are using Pay-As-You-Go, this costs 30 cents/minute, and 15 cents/minute if you subscribe. Learn more about our pricing structure here.\nCAN I TRANSCRIBE AUDIO WITHOUT A VIDEO? Yes. If you have a separate audio file, you do not need a video to use Video Translator to transcribe audio. Simply upload the audio file into an audio component, and use the AI to transcribe you preferred language and dialect.\nHOW CAN I ADD CAPTIONS TO A VIDEO? How to add captions to a video using Video Translator:\n Select your preferred language template, and create a new item. Upload your video and click Actions \u0026gt; Transcribe. Alternately, if you already have captions, copy and paste this into the Captions tab. Click the \u0026lsquo;Add Captions\u0026rsquo; button to add to embed captions to a video. Alternately, for additional styling options, use the Auto-Overlay functionality.  HOW TO EMBED SUBTITLES INTO VIDEO USING OUR AUTO-OVERLAY FEATURE? Our Auto Overlay feature allows you to embed subtitles into a video rather than keeping them separately in an srt file. Here’s how:\n Once you\u0026rsquo;ve transcribed your captions, click Action \u0026gt; Auto-Overlay. Then select your video asset. From here, you can customise the font, font-size, font-color, and opacity. Next you can add a striped background behind your text, or a proportionally inserted highlight. You can choose the colour and opacity of your highlight. Click confirm. Your video asset is now ready to download with embedded subtitles and your preferred styling. You can see more detailed instructions on how to embed subtitles into video using our auto overlay feature on our blog here.  HOW TO EMBED SUBTITLES INTO MP4? We see this question a lot as it is the most common video type across social media platforms. As long as you have the transcription text or srt file, you can embed subtitles into your mp4 or any format video file.\nHOW CAN I TRANSLATE A VIDEO? It is simple to translate any video with Video Translator.\nTRANSCRIBE THE AUDIO  Select myTemplate and create a new item. Upload your video and click Actions \u0026gt; Transcribe. Select the language and dialect of the video. Click Accept. The transcription process will run in the background. Once the transcription is complete, go through and check the transcription for proper grammar e.g. capitalization and full stops. Click the + button to add it to your video.  TRANSLATE THE CAPTIONS OR SUBTITLES  Once you have the captions, click Action \u0026gt; Translation. Select your preferred language. Click Accept. The translation process will run in the background. After the translation is complete, a new file will appear with transcription in the new language. We recommend having someone who speaks the language copy edit it. Now you can add captions to your video. We have detailed instructions on translating a video from English here.  TRANSCRIBE THE NOW TRANSLATED CAPTIONS INTO SPEECH  Open your translated text file and copy paste the captions into the audio file. Click Transcribe File and select from the available voices. Add the audio into the original video asset as an overlay. Remember to mute the original audio so that you can hear only the translated language when the video plays. You can see an example of translating audio into German here.  HOW LONG DOES IT TAKE TO TRANSLATE A VIDEO? There are several factors which can impact translation time.\n The AI translation will happen very quickly in seconds. It is highly recommended that you engage a human for post-editing.  A normal workflow is (a) use the AI to do the first pass, (b) use a human subject matter expert for post editing.\nDO YOU HAVE A FILE SIZE LIMIT? Yes - by default there is a limit of 100mb on the Free-Trial to avoid abuse. On subscribing this increases to 500mb. Larger file sizes are available on request.\nHOW MUCH DOES IT COST TO TRANSLATE A VIDEO? The cost varies depending on the length of your video. If you you are using Pay-As-You-Go, this costs 30 cents/minute, and 15 cents/minute if you subscribe. Learn more about our pricing structure here.\nHOW MANY LANGUAGES CAN VIDEO TRANSLATOR TRANSLATE? WHICH LANGUAGES ARE SUPPORTED BY VIDEO TRANSLATOR? The Video Translator supports over 60+ languages and 150+ dialects.\n Speech-to-text transcription: 63 languages. Text-to-text translation: 57 languages. Text-to-speech transcription: 11 languages.  A full overview of our language capabilities is available here.\nHOW MUCH DOES VIDEO TRANSLATOR COST TO USE? The cost varies depending on the length of your video. If you you are using Pay-As-You-Go, this costs 30 cents/minute, and 15 cents/minute if you subscribe. Learn more about our pricing structure here.\nWe also offer Managed Services and Enterprise Solutions for additional cost.\nCAN I TRY VIDEO TRANSLATOR FOR FREE? Yes. You can trial Video Translator for up to 5 minutes of content transcribed and translated video free of charge. Click here for more details. Need more time? Drop us an email.\n","permalink":"https://videotranslator.ai/frequently-asked-questions/","tags":null,"title":"Frequently Asked Questions"},{"categories":null,"contents":" GETTING STARTED HOW TO REGISTER / HOW TO REGISTER FOR A FREE TRIAL To register please use the Free-Trial option.\n Navigate to videotranslator.ai/free-trial/ Fill out your email address and select up to 4 languages from the drop-down menu (you can add more later). Click Sign Up A dialogue box will appear with the Terms of Service. You must accept the Terms of Service before hitting Submit. You will be redirected to a page to fill out your name and password. Once doing so, click Enroll. You are ready to go! Check your email for a verification email. Click the link in the verification email. Once on that page, click the button that says Verify.  The free trial gives you 5 minutes of AI video transcription/translation. Once you reach 5 minutes, enter your payment information to subscribe to the service.\nYou can see a detailed review of the process here. If you want more time to evaluate our platform, send us an email.\nLANGUAGES HOW TO ADD A LANGUAGE You will automatically have English set as your primary language. Add up to an additional three (3) secondary languages in the Sign Up process.\n Login to your account and click on the ⋮ menu in the upper-right. Select Finance from the ⋮ menu. In General Settings, scroll down to where it says Quantity of Languages. Increase that number to your desired total number of languages (note that this will increase your subscription costs). Click the Upgrade button. A dialogue box will appear asking you to confirm your language quantity. Click Submit. Switch to the Language Settings tab, and select your new language(s) from the Secondary Languages section.  You now have access to additional languages. You can see a more detailed guide on adding languages here.\nHOW TO REMOVE A LANGUAGE You can swap out the languages you subscribe to at any time from your profile.\n Login to your account and click on the ⋮ menu in the upper-right. Select Finance from the ⋮ menu. Switch to the Language Settings tab, and remove your language(s) from the tab. Important: you must decrease the amount of languages you are subscribed to in order to decrease your monthly subscription costs. On the General Settings tab, scroll down to where it says “Quantity of Languages:” in the form. Decrease that number to your desired total number of languages (note that this will decrease your subscription costs). Click the Upgrade button. A dialogue box will appear asking you to confirm your language quantity. Click Submit.  TEMPLATES AND ITEMS HOW TO CREATE A TEMPLATE To create a template, login to your account.\n Click the + button on the bottom-left to add a new template. Select your desired template type from Video, Audio, Image and Text. Input your desired name under Template Name and hit Submit. This will become your new template. Click the right-hand + button in the bottom left and select your asset’s file type. This will open a dialogue box which asks you to confirm. Click Submit. Note: you can add multiple file types and file fields to your template (your template can support Video, Audio, Image and Text). Once confirmed, a form will appear where you can upload audio. To publish the template, click on the globe 🌎 button and select Publish from the drop-down menu. A confirmation dialogue box will appear. Click Submit and then Close once the process is complete.  Once your template is created, you can create items of this type of template. A detailed overview of this process is described here.\nHOW TO EDIT AN EXISTING TEMPLATE To edit an existing template, please follow the below steps.\n Login to your account. Click on a template to select it. The template will highlight green. Click the Edit (a pencil button) ✏️ to edit your template. A dialogue box will appear, hit Submit. Click the right-hand + button in the bottom left and select from the options your desired file type (Audio, Video, Image, or Text). This will open a dialogue box which asks you to confirm. Click Submit. To publish the template, click on the globe 🌎 button and select Publish from the drop-down menu. A confirmation dialogue box will appear. Click Submit and then Close once the process is complete.  More information on working with templates is available here.\nHOW TO UPLOAD AN ASSET INTO AN ITEM To upload an asset, you must first create a template which supports the asset’s file type (Video, Audio, Image or Text). See how to create a template for more information.\n Select your preferred language template. It will be highlighted green and a line of icons will appear underneath. Click on the + button to add a new item. A dialogue box will appear. Type in a name for your item, and hit Submit. The new item will open, and you can now upload your asset. Click the ⬆️ button in the bottom-left to upload your asset. A pop-up will appear. Under the My Files tab, you can drag-and-drop your asset file into the upload box, or you can click Browse to open your file manager. Under the Web Address tab, enter the direct web url (must include file extension) to your asset file and click the right-arrow ➡️ to upload. Click Done. You will see a blue circle under your audio file indicating the upload is in progress.  TRANSCRIPTION In order to transcribe content, you must have a template which supports that specific file type. You can edit an pre-existing template, or create a new one.\nHOW TO TRANSCRIBE AUDIO Before You Begin\nYou will need an audio template in order to complete these step. If you do not have an audio template, please see the steps described in the create a template.\nUpload Audio Asset\n Select your audio template. It will be highlighted green and a line of icons will appear underneath. Click on the + icon to add a new item. A dialogue box will appear. Type in a name for your Audio file, and hit Submit. Your new item will open, and you can upload your audio file. Click the upload ⬆️ icon in the bottom-left to upload your audio file. A pop-up will appear. Under the My Files tab, you can drag-and-drop your audio file into the upload box, or you can click Browse to open your file manager. Under the Web Address tab, enter the direct web url (must include file extension) to your audio file and click the right-arrow ➡️ to upload. Click Done. You will see a blue circle under your audio file indicating the upload is in progress. Once that is done you can trigger the transcription.  Transcribe Audio Asset\n Click on the Action button on the icon, and click transcribe. A dialogue box will appear. Select your audio file from the content you wish to transcribe. Select the language you wish your captions to be transcribed into, and hit Accept. Note that the cost of the transcription will be displayed in red text. A second dialogue box will appear that says This item will close, while transcription is completed. Click Close. Your Audio item will be greyed out until transcription is complete. 1.Once the process is complete, you will be able to click to select your Audio template. Click the Edit ✏️ to edit your asset. Your audio transcription is ready! Click on Captions in the bottom left to view your captions.  It is strongly encouraged to copy edit them for clarity before using them.\nHOW TO TRANSCRIBE VIDEO Before You Begin\nYou need a video template in order to complete this step. If you do not have a video template, please see the steps described in the create a template.\nUpload Video Asset\n Select your video template. It will be highlighted green and a line of icons will appear underneath. Click on the + icon to add a new item. A dialogue box will appear. Type in a name for your video file, and hit Submit. Your new item will open. Here you can upload your video file. Click the arrow ⬆️ icon in the bottom-left to upload your video file. A pop-up will appear. Under the My Files tab, you can drag-and-drop your video file into the upload box, or you can click Browse to open your file manager. Under the Web Address tab, enter the direct web url (must include file extension) to your video file and click the right-arrow ➡️ to upload. Click Done. You will see a blue circle under your video file indicating the upload is in progress. Once that is done, you can trigger the transcription.  Transcribe Video Asset\n Click on the Action button on the icon, and click transcribe. A dialogue box will appear. Select your audio file from the content you wish to transcribe. Select the language you wish your captions to be transcribed into, and hit Accept. Note that the cost of the transcription will be displayed in red text. A second dialogue box will appear that says This item will close, while transcription is completed. Click Close. Your video template will be greyed out until transcription is complete. Once the process is complete, you will be able to click to select your video template. Click the Edit (pencil icon) ✏️ to edit your asset. Your video transcription is ready! Click on Captions in the bottom left to view your captions. It is strongly encouraged to copy edit them for clarity before using them.  You can see additional detailed instructions on transcribing video here.\nTRANSLATION Translation can be a multi-step process. First, you must transcribe speech to text. Second, the text must be translated. Finally, if you are using a supported language, you can do text-to-speech transcription. A visual guide to text-to-speech transcription is available.\nHOW TO TRANSLATE TEXT  Login to your account. Select the item with your transcribed audio, and click the Edit ✏️ to edit your item. Click the Actions icon on the top menu and select Translate. A dialogue box will appear. Select Automatic to use the AI to translate, and select the language you want to translate into from the Preferred Language section. Click Accept to trigger the translation. This process will take a few seconds. Once your translation is complete, it is highly encouraged to have a subject-matter expert edit the copy.  You can see a visual guide on text to text translation here.\nHOW TO TRANSLATE SPEECH Our text-to-speech AI supports a number of languages. Our AI can speak in both a male and female voice, and depending on the language, multiple dialects are available.\n Select the item with your transcribed asset, and click the Edit (pencil icon) ✏️ to edit your item. Select the audio component and copy+paste your translated caption file into it. Click the Actions icon on the top menu and select Transcribe. A dialogue box will appear. Choose from the available dialects. Only select the component you want to translate. Click Accept to trigger the transcription. This process will take a few minutes.  You can now add the audio into the original video asset as an overlay . Be sure to mute the original audio to achieve the desired outcome.\nA detailed visual guide on text-to-speech translation is available.\nPUBLISH AUTO-OVERLAY You can use the Auto Overlay feature to embed captions into your video file. This allows a more customisable outcome than an .srt file, and gives you the option to share a captioned video independently of a publishing platform that shows the SRT (like YouTube), for example if you want to attach it to an email.\n Select the item with your transcribed audio, and click the Edit (pencil icon) ✏️ to edit your item. Go to the the video component. On the bottom where it says Captions, you will also see Underlay and Text Overlay options. This is what we will use. Click on the Action button, and select Auto-Overlay You can customise the font, font color, font size, and transparency. You can also customise where on the video your captions appear (on the bottom is typical). Hit Next. Here you can customise a stripe or highlight, if you want to add a background colour behind your text. Hit Submit You can now download your video file with embedded captions.  DOCUMENTATION Please download printable documentation below. We will add more collateral over time, please let us know if there is specific documentation you require.\n Overview: 1-Sided Printable File Overview: 2 Page Printable File Quick-Start: 4 Page Printable File  ","permalink":"https://videotranslator.ai/help-and-documentation/","tags":null,"title":"Help And Documentation"},{"categories":null,"contents":" ","permalink":"https://videotranslator.ai/people/","tags":null,"title":"People"},{"categories":null,"contents":" OVERVIEW Video Translator uses a Business to Customer (B2C) subscription plan loosely modelled on a mobile phone contract.\n  Video Translator: Pricing: Subscription vs. Pay-As-You-Go\n   PRICING MODEL BASICS Note that $10 = 1000 credits, and charges are in USD.\n sign up for the free-trial and get 100 credits, pay 30 cents/minute for AI usage with no commitments, alternately subscribe for a minimum of $10/month and pay 15 cents/minute for AI usage. if you run out of credits top up any time, all unused credits roll forward to the next month  Download *.srt, *.vtt, or your original video asset with Open Captions, and deploy to your social channels once you are done.\nPRICING MODEL NOTES  AI usage refers is transcription, translation and dubbing Use the Finances tab to add/remove languages  For a visual guides, please have a look at the here.\nFEE STRUCTURE Fees are charged according to a Subscription Model.\n A subscription fee is charged by Video Translator to the Client per month in advance as nominated by Client; An additional fee is calculated which is based upon the use of Third Party Tools in excess of the subscription fee for a specific Client Video. A Client’s account must hold sufficient credit for services requested. If insufficient credit is held in Client’s account, Video Translator reserves the right to charge Client’s account in a subsequent month to make up the shortfall and Client consents to this.  The Fee is expressed as exclusive of GST. Where required by law, GST is added to the Fee. Fees will be clearly described in the Order Form.\nBASE FEE Under the Subscription Model the base fee is a per month fee of $10. You can increase this as required.\nUnder the Pay-As-You-Go Model there is no base fee.\nBoth give you access to the AI\u0026rsquo;s in available languages. For a full list of languages, and a description of how to use the different AI\u0026rsquo;s, please click here.\nUSAGE FEE The usage fee mechanic is dependent on which AI you are looking to deploy for your project. All pricing below is in USD.\nTranscription (Artificial Intelligence)\n 15 USD cents per minute under subscription model. 30 USD cents per minute under pay-as-you-go model.  Translation (Artificial Intelligence)\n 15 USD cents per minute under subscription model. 30 USD cents per minute under pay-as-you-go model.  Dubbing (Artificial Intelligence)\n 15 USD cents per minute under subscription model. 30 USD cents per minute under pay-as-you-go model.  Transliteration (Natural Language Programming)\n Text To Text - Free  What is transliteration? See more details here.\nCONCLUSION Should you have any questions/concerns, please contact us via web form, or send us an email at: hello@videotranslator.ai\n","permalink":"https://videotranslator.ai/pricing/","tags":null,"title":"Pricing"},{"categories":null,"contents":" BENEFITS OF MANAGED SERVICE     Service Internationalization has three components, app, website and marketing    Benefits Of A Managed Service Video Translator provides managed services to assist clients to localize/internationalize their value proposition.\nWe offer a managed service aimed at meeting custom requirements.\nShallow Use Cases The majority of governments, non-profits and businesses have what we think of as shallow use cases. That is, they require translation services as an adjunct to their core concerns. The requirement might be one-off/event driven, a very specific but relatively small requirement, or have legislative/regulatory drivers.\nSo the requirement exists, but there is no reason to rebuild operations to offer multilingual support. A very common use case is one-off requirements for translation, say to support a pitch to a client who is overseas. Post pitch, this is often reused in a multilingual website for the SEO benefits. Read a case study.\nPart Of A Larger Process Everyone understands the inherent power of language. If you can successfully move your service into another language - show me the money!\nBut how to do this right? Its expensive, complex and has an uncertain ROI.\nA number of our clients use our managed services as a stop gap while they build out the in-house capability for the ongoing production of translated content.\nOutside Core Competence The core of our value proposition is ROI. As in, for content spend of X, spend an additional small amount and now your content is multilingual.\nA number of innovative firms want to spend their time focused on their own value proposition, and do not want to build up a multilingual team. In this case, we offer bespoke solutions ranging from the Internationalization of apps, research into keywords in different languages and market research around language sensitivities.\nCHALLENGES AROUND SERVICE LOCALIZATION AND INTERNATIONALIZATION     Challenges around service localization and internationalization    Challenges Around Service Localization And Internationalization While localization and internationalization initiatives generally have executive backing, bringing the entire team along - development, marketing and sales - is required to execute successfully.\nSo the question becomes, what small / low cost steps can you take to start the project, and how to show a positive ROI every step of the way.\nQ: Where do we start? We have several websites, some apps and our billing is on two systems! We would recommend starting with a few short video\u0026rsquo;s. You will be required to provide the video, any background music and select the languages you want to target.\nWhy? Because the hard thing about service delivery in other languages is bringing your team along.\nHow do you get from only English all the way to an translated value proposition. Book a call today!\nQ: My development team is too busy and does not have the bandwidth for another project! We understand.\nThe key thing to remember is the majority of your value proposition does not have to be translated.\nThe parts that bring in new business, those HAVE TO BE translated.\nWe are here to help. Book a call today!\nEXOTIC LANGUAGES     We can advise you on website translation to maximise SEO    Exotic Languages Multiple languages are hard to work with operationally. We take the view that the smart way to do this is to try a number of different options.\nGive your sales people and marketing staff something to work with!\n    Source: Think with Google, YouTube Internal Data, U.S., March 2019–May 2019    Lets say that your business has sales people in English only. How would you create Spanish collateral? We are essentially doing the same thing just with video.\nAs you have outsourced the heavy lifting, this collateral can be provided to a Spanish speaking colleague to work with directly. But more importantly, once deployed online provides an ongoing set of leads from the Spanish SEO.\nBut Spanish is not exotic? Exactly, irrespective of the target culture, there is no way to work out how much demand your product has unless you try the market. Our value proposition is that you can now try a very large number of potential markets with a very low starting cost.\nTalk to us to learn more about our capabilities in unusual languages.\nACCESSIBILITY Regulatory drivers are quite important for a large number of our clients. In Australia for example, there is a focus on providing options for sight and hearing impaired people.\nA standard solution here is to use open captions. This covers the disability use cases, providing support to older people, and is also related to people who prefer open captions.\nAn added benefit of open captions is the providing a simple way to deploy content into social media channels (like LinkedIn or Facebook) where video content auto-plays but is muted.\nCONCLUSION  Use our experts to quickly evaluate a non-English prospect market. Who are the players, who is the competition? Build out a micro-site in the target language, limiting your offering to known opportunities. If it works, then spend the money setting up a local presence. Reuse your prior/current investment in content, by scaling across languages. This includes text, image, audio or video content. Use capabilities like multi-lingual forms to manage complex workflow.  ","permalink":"https://videotranslator.ai/services/","tags":null,"title":"Services"},{"categories":null,"contents":" INTRODUCTION If you’re planning to post your video to social media, it’s important to make sure your video meets social channel specific formatting requirements.\nNot doing this can affect your users experience, from looking distorted, to unreadable captioning, to simply not playing, the below simple tips and tricks will make your content convert faster!\n Video Formats, Size And Recommendations Video Lengths, Preferred Quality And Resolution Ratio\u0026rsquo;s Subtitles And Caption Options - Open Or Closed Metadata Heuristics  RECOMMENDATIONS If you are aiming for maximum exposure use: an MP4 file, less than 180 seconds, aspect ratio of 16:9, at 720p and remember to add open captions for muted auto-play social media.\nOnce you have the basics in place, spend your time creating valuable content, and get the title, description and metadata correct. Getting search engines to index your content properly is half the battle.\nWant more information? Read on below.\nFACEBOOK WHAT VIDEO FORMAT DOES FACEBOOK USE / WHAT VIDEO FORMATS DOES FACEBOOK RECOMMEND Facebook recommends using MP4 or MOV formats for your video. Other supported formats are listed below.\n         3g2 (mobile video) gif (Graphics Interchange Format) mpg (MPEG video)   3gp (mobile video) m2ts (M2TS video) mts (AVCHD video)   3gpp (mobile video) m4v (MPEG-4 video) nsv (Nullsoft video)   asf (Windows Media video) mkv (Matroska format) ogm (Ogg media format)   avi (AVI video) mod (MOD video) ogv (Ogg video format)   dat (MPEG video) mov (QuickTime movie) qt (QuickTime movie)   divx (DIVX video) mp4 (MPEG-4 video) tod (TOD video)   dv (DV video) mpe (MPEG video) ts (MPEG transport stream)   f4v (Flash video) mpeg (MPEG video) vob (DVD video)   flv (Flash video) mpeg4 (MPEG-4 video) wmv (Windows Media video)    WHAT VIDEO LENGTHS DOES FACEBOOK RECOMMEND / FACEBOOK VIDEO LENGTH The maximum Facebook video length depends on where you are posting the video.\n Facebook Newsfeed: 240 minutes Facebook Marketplace: 240 minutes Facebook Instant Articles: 240 minutes Facebook Stories: 120 seconds Facebook Audience Network: 120 seconds Facebook In-Stream: 15 seconds (minimum of 5 seconds)  WHAT VIDEO QUALITY DOES FACEBOOK RECOMMEND / FACEBOOK VIDEO QUALITY Regarding Facebook video quality, you need to consider the maximum file size. For short content, you can aim for the best quality possible.\n Frame rate: up to 30 frames per second.  WHAT VIDEO SIZES DOES FACEBOOK RECOMMEND Facebook allows for up to 4 gigabytes for any video you upload. Therefore, for long content, you may need to reduce the quality.\n Maximum video file size for Facebook: up to 4 gigabytes.  Please note, with videotranslation.ai, we enforce a maximum of 100mb in the Free-Trial. Once subscribed, we allow uploads of 500mb by default and larger on request. These limitations exist to avoid abuse.\nWHAT VIDEO RESOLUTION DOES FACEBOOK RECOMMEND / FACEBOOK VIDEO RESOLUTION Facebook recommends uploading the highest resolution video available that meets file size and ratio limits.\n Video resolution: up to 1080p (720p recommended).  WHAT ASPECT RATIO DOES FACEBOOK RECOMMEND / FACEBOOK VIDEO ASPECT RATIO Supported aspect ratio\u0026rsquo;s on Facebook vary depending on where you post them to the platform. In general:\n 16:9 / 9:16: supported everywhere. 1:1 (square): supported everywhere. 4:5 (vertical): supported everywhere except for Facebook In-Stream Audience Network.  A complete list of different aspect ratio\u0026rsquo;s supported by Facebook. In general, we recommend formatting your video so that it works for everyone. Go with 16:9 or 1:1 for your Facebook video content because it will work everywhere.\nINSTAGRAM Videos on Instagram must be uploaded from the Instagram app on a mobile device, or from a third party social media sharing platform.\nWHAT VIDEO FORMATS DOES INSTAGRAM USE Videos on Instagram must be uploaded from the Instagram app on a mobile device, or from a third party social media sharing platform.\n Instagram feed: MP4 or MOV. Instagram stories: MP4, MOV or GIF.  WHAT VIDEO LENGTHS DOES INSTAGRAM RECOMMEND? Instagram video length limit depends on whether you’re recording in-app, or uploading existing content.\n In-app recording: 60 seconds (minimum of 3 seconds). Upload: 120 seconds (minimum of 1 second).  WHAT VIDEO QUALITY DOES INSTAGRAM RECOMMEND / INSTAGRAM VIDEO QUALITY Instagram recommends you upload videos with the below quality settings.\n Instagram Feed: up to 30 frames per second. Instagram Stories: up to 30 frames per second.  Instagram has no constraints on minimum quality.\nWHAT VIDEO SIZES DOES INSTAGRAM RECOMMEND? Instagram recommends you upload videos with the below maximum sizes.\n Instagram Feed: up to 4 GB. Instagram Stories: up to 4 GB.  WHAT VIDEO RESOLUTION DOES INSTAGRAM RECOMMEND / BEST VIDEO RESOLUTION FOR INSTAGRAM Instagram makes the below recommendations for video resolution.\n Instagram Feed: minimum of 600p up to 1080p, with a recommended frame rate of 30 FPS. Instagram Stories: minimum of 720p up to 1080p, with a recommended frame rate of 30 FPS.  WHAT ASPECT RATIO DOES INSTAGRAM RECOMMEND? The aspect ratio depends on whether you’re posting to the Instagram feed or to Instagram stories. Adjust your video and audio transcription so that it fits within the below constraints.\n Instagram Feed: between 1.91:1 and 4:5 Instagram Stories: between 16:9 and 4:5 (note: will display vertically).  We recommend a 1:1 aspect ratio for your Instagram Feed because your Instagram Profile will crop everything into 1:1 tiles.\nIGTV (INSTAGRAM TV) IGTV, a service offered by Instagram, has its own video standards which are different from Instagram. IGTV is designed for long vertical content viewed on mobile devices. You can share IGTV content to your Instagram story. The original announcement with more information is available here.\nWHAT VIDEO FORMATS DOES IGTV (INSTAGRAM TV) USE? Currently IGTV recommends MP4 videos.\nWHAT VIDEO LENGTHS DOES IGTV (INSTAGRAM TV) RECOMMEND? The length limit of your IGTV video depends on whether you have a verified account with Instagram.\n Regular accounts: 10 minutes (minimum of 15 seconds). Verified accounts: 60 minutes (minimum of 15 seconds).  WHAT VIDEO QUALITY DOES IGTV (INSTAGRAM TV) RECOMMEND? IGTV recommends a minimum frame rate of 30 FPS.\nWHAT VIDEO SIZES DOES IGTV (INSTAGRAM TV) RECOMMEND? File size also depends on the type of account you have. This is to avoid abuse.\n Regular accounts: 650 MB Verified accounts: 3.6 GB  WHAT VIDEO RESOLUTION DOES IGTV (INSTAGRAM TV) RECOMMEND? The recommended resolution for IGTV is from 720p up to 1080p.\nWHAT ASPECT RATIO DOES IGTV (INSTAGRAM TV) RECOMMEND? The recommended aspect ration for IGTV is 16:9 or 9:16.\nTWITTER WHAT VIDEO FORMATS DOES TWITTER USE / TWITTER VIDEO FORMAT The supported video formats for Twitter depend on whether you’re using the mobile app or desktop. We recommend MP4 as it is supported by both mobile and desktop.\n Mobile: MP4 and MOV. Desktop: MP4 (with H264 and AAC audio).  WHAT VIDEO LENGTHS DOES TWITTER RECOMMEND / TWITTER VIDEO LENGTH LIMIT The Twitter video length limit is 140 seconds (2 minutes 20 seconds).\nWHAT VIDEO QUALITY DOES TWITTER RECOMMEND / TWITTER VIDEO QUALITY Twitter recommends up to a maximum of 40 frames per second.\nWHAT VIDEO SIZES DOES TWITTER RECOMMEND? Twitter recommended size is a maximum of 512 MB.\nWHAT VIDEO RESOLUTION DOES TWITTER RECOMMEND? Twitter supports a range of video resolutions starting at a minimum of 32p and a maximum of 1080p.\n Maximum resolution: 1080p (a maximum 1920x1200 pixels, either vertical or horizontal). Minimum resolution: 32p (must have a minimum of 32 pixels in both dimensions).  WHAT ASPECT RATIO DOES TWITTER RECOMMEND Twitter supports a range of aspect ratios between 1:2.39 to 2.39:1. Most common ratios, such as 16:9 or 1:1 are supported by Twitter. It is likely a video that you created for another social media will work for Twitter.\nYOUTUBE WHAT VIDEO FORMATS DOES YOUTUBE USE YouTube supports a range of video file formats, including some that are not supported on most social media platforms.\n         mov (QuickTime movie) mpegps (MPEG program stream) ProRes   mpeg4 (MPEG-4 video) flv (Flash video) CineForm   mp4 (MPEG-4 video) 3gpp (Mobile video) HEVC (h265)   avi (AVI video) WebM (HTML 5 video format)    wmv (Windows Media video) DNxHR     YouTube recommends using MP4.\nWHAT VIDEO LENGTHS DOES YOUTUBE RECOMMEND / YOUTUBE VIDEO LENGTH LIMIT YouTube video length limit depends on whether you have a verified Google account.\n Unverified Google account: up to 15 minutes. Verified Google account: up to 12 hours or 128 GB, whichever comes first.  WHAT VIDEO QUALITY DOES YOUTUBE RECOMMEND? YouTube recommends a frame rate minimum of 24FPS up to 60FPS.\nWHAT VIDEO SIZES DOES YOUTUBE RECOMMEND / YOUTUBE VIDEO QUALITY YouTube recommends a file size of up to 128 GB (cannot exceed 12 hours).\nWHAT VIDEO RESOLUTION DOES YOUTUBE RECOMMEND? 16:9 is the default ratio at which YouTube will display. If you use another ratio, the video player will automatically change to match your ratio.\n Resolution: minimum 240p up to 2160p.  Mobile: Vertical format videos will automatically display at full width on Android and iOS, but not full height. The video will display as a 1:1 with top portion cut off. The user will have to enter full screen to see the full height of the video. Thus, we recommend putting audio transcriptions on the bottom of your video. More information here.\nWHAT ASPECT RATIO\u0026rsquo;S DOES YOUTUBE RECOMMEND? YouTube recommends an aspect ratio of 16:9. For different quality numbers, the below should be applied.\n 2160p: 3840x2160 1440p: 2560x1440 1080p: 1920x1080 720p: 1280x720 480p: 854x480 360p: 640x360 240p: 426x240  CONCLUSION Did you know many people scroll through social media with the sound off? To understand the uses of captions in video, have a look at this post.\nThat’s why adding captions to your video is so important. Learn more about using the Video Translator app to add subtitles and captions.\n","permalink":"https://videotranslator.ai/social-media-guide-to-video-facebook-twitter-instagram-igtv-twitter-youtube/","tags":null,"title":"Social Media Guide To Video 1"},{"categories":null,"contents":" INTRODUCTION If you’re planning to post your video to social media, it’s important to make sure your video meets social channel specific formatting requirements.\nNot doing this can affect your users experience, from looking distorted, to unreadable captioning, to simply not playing, the below simple tips and tricks will make your content convert faster!\n Video Formats, Size And Recommendations Video Lengths, Preferred Quality And Resolution Ratio\u0026rsquo;s Subtitles And Caption Options - Open Or Closed Metadata Heuristics  LINKEDIN Formats for video on LinkedIn depends on whether the video is an advertisement.\nWHAT VIDEO FORMAT DOES LINKEDIN USE / WHAT VIDEO FORMATS DOES LINKEDIN RECOMMEND  For LinkedIn Ads allowed video format is MP4 only. For LinkedIn Newsfeed allowed video formats are provided below.           asf (Windows Media video) mpeg-4 H264/AVC   avi (AVI video) mkv (Matroska format) mp4   flv (Flash video) QuickTime VP8/VP9   mpeg-1 WebM wmv2/wmv3    WHAT VIDEO LENGTHS DOES LINKEDIN RECOMMEND / LINKEDIN VIDEO LENGTH LIMIT  LinkedIn feed: 10 minutes (minimum 3 seconds). LinkedIn ad: 30 minutes (minimum 3 seconds).  WHAT VIDEO QUALITY DOES LINKEDIN RECOMMEND / LINKEDIN VIDEO QUALITY  For LinkedIn Newsfeed: Frame rate of 10-60 frames per second. For LinkedIn Ad: Frame rate of up to 30 frames per second.  WHAT VIDEO SIZES DOES LINKEDIN RECOMMEND  For LinkedIn Newsfeed: File Size of 5 GB (minimum 75 KB).. For LinkedIn Ad: File Size of up to 200 MB (minimum 75 KB).  WHAT VIDEO RESOLUTION DOES LINKEDIN RECOMMEND / VIDEO RESOLUTION FOR LINKEDIN  LinkedIn Newsfeed: 144p-2304p LinkedIn Ads: 360p-1080p  WHAT ASPECT RATIO DOES LINKEDIN RECOMMEND / LINKEDIN VIDEO ASPECT RATIO LinkedIn Newsfeed: 1:2.4 (horizontal or vertical)\nNote: vertical videos are automatically cropped as squares in the Newsfeed. Make sure your audio transcription is on the bottom of the video.\nLinkedIn Ad: 16:9 (horizontal only). Please see recommended resolution and sizing below.\n 360p (480 x 360; wide 640 x 360) 480p (640 x 480) 720p (960 x 720; wide 1280 x 720) 1080p (1440 x 1080; wide 1920 x 1080)  PINTEREST You will need a Pinterest business account to upload a video on Pinterest. For regular Pinterest accounts, you will need to create a new pin of existing content.\nWhen you add a video on Pinterest, it will need to be reviewed by Pinterest. Uploaded videos are reviewed and approved (or denied) within 24 hours. According to their website, only English videos are currently supported.\nIf you want to share content in another language, you will want to translate and transcribe your video, and then add captions or subtitles to your video.\nNote: according to the Pinterest website, uploading a video to a pin from a regular account is only supported by iOS. For all other operating systems, you will need a business account.\nWHAT VIDEO FORMAT DOES PINTEREST RECOMMEND / PINTEREST VIDEO FORMAT Video on Pinterest supports only the mp4 or mov formats.\nWHAT VIDEO LENGTHS DOES PINTEREST RECOMMEND / PINTEREST VIDEO LENGTH Pinterest supports video lengths up to 15 minutes (minimum of 4 seconds).\nWHAT VIDEO QUALITY DOES PINTEREST RECOMMEND / PINTEREST VIDEO QUALITY  File size: up to 2 GB. Frame rate: no limits specified.  PINTEREST VIDEO RESOLUTION AND ASPECT RATIO For Pinterest\u0026rsquo;s recommended resolution no limits specified as long as the video is under 2 GB.\nAspect ratio: 16:9, 1:1, 4:5, and 2:3 (both vertical and horizontal).\nTUMBLR Tumblr has very limited constraints when it comes to hosting videos on Tumblr itself. It does however, allow for embedding videos (e.g. on YouTube) with no limitations on size or length.\nWHAT VIDEO FORMAT DOES TUMBLR USE / TUMBLR VIDEO FORMAT Only MOV or MP4 files are currently supported.\nWHAT VIDEO SIZES DOES TUMBLR RECOMMEND / TUMBLR VIDEO UPLOAD LIMIT  File size: up to 100 MB per day or 5 minutes per day (whichever comes first). Frame rate: no limits specified.  VIDEO QUALITY ON TUMBLR No listed constraints, so long as it is under 100 MB and 5 minutes total.\nTUMBLR VIDEO RESOLUTION Up to 500x700 px. While the maximum is a unique aspect ratio in and of itself, it supports any aspect ratio within those size constraints.\nHOW TO UPLOAD VIDEO TO VIEW IN CHINA It is very hard to upload video to Youtube in China. China’s great firewall makes it very difficult for users to access Google, and by extension, YouTube⁠—as well as social media networks such as Facebook, Twitter and Pinterest.\nIf you want to share videos on social media in China, you will need to use Chinese services. Baidu is China’s most popular search engine and also has a social media aspect to it. You may wish to upload your video content to YouKu, which is China’s most popular video sharing site. It is searchable from Baidu.\nYOUKU WHAT VIDEO FORMAT DOES YOUKU USE / WHAT VIDEO FORMATS DOES YOUKU RECOMMEND          .wmv .mov .divx   .avi .mp4 .cpk   .dat .m4v .fli   .asf .dvix .flc   .rm .dv .mod   .rmvb .dat    .ram .mkv    .mpg .flv    .mpeg .vob    .3gp .ram     Additionally, no constraints to length are listed, the maximum upload is 200MB (without using YouKu\u0026rsquo;s software), and no listed resolution recommendations.\nFor more information on how to upload a video you YouKu, read this article.\nCONCLUSION Did you know many people scroll through social media with the sound off? To understand the uses of captions in video, have a look at this post.\nThat’s why adding captions to your video is so important. Learn more about using the Video Translator app to add subtitles and captions.\n","permalink":"https://videotranslator.ai/social-media-guide-to-video-linkedin-tumblr-pinterest-youku/","tags":null,"title":"Social Media Guide To Video 2"},{"categories":null,"contents":" BENEFITS OF SAAS SOLUTIONS     Benefits of Saas Solutions: VideoTranslator.AI app    Benefits Of Saas Solutions Video Translator provides a Software-As-A-Service (SaaS) application to deliver real time Artificial Intelligence (AI) transcription and translation to clients.\nWith our Saas application, there are no software setup costs and the entire application is deployed via your Internet browser.\nUsing this application clients are able to:\n Upload their text, image, audio and video content into the application. Use an AI to transcribe their audio or video content into a number of languages. Use an AI to translate text content, allowing for caption translation. Use an AI to speak out text content, allowing for full video translation. Manually translate up to 180+ languages, using the transliteration functionality.      Text translation becomes simple - Arabic    All this and more, in a self service cloud application, giving you access to AI when you need it, with a usage based with a pricing model.\nRETAIL: AI AUDIO/VIDEO TRANSCRIPTION AND TRANSLATION     Add subtitles or open captions in any language - Telegu    Retail: AI Audio/Video Transcription And Translation Recommended for content creators looking to quickly start reaching new markets.\n Best for adding captions automatically into your video content. Do you use YouTube, LinkedIn or other social media for video marketing? Instead of a manual transcription process, use our AI to radically reduce time spent. Use our platform to turn your content creation and translation life cycle into a scalable workflow, with the ability to Bring Your Own (BYO) translator to add that human touch.  Try out the platform for free here.\nENTERPRISE: COMPLEX USER MANAGEMENT     Fine grained control over permissions to manage your workflow    Enterprise: Complex User Management The primary difference between the retail offering and the enterprise offering is the ability to create collections of users with different access levels, including different access to specific language sets.\n Recommended if you have a distributed team with complex processes. Control staff, client and other stakeholders actions at a granular level. Forms can be set with user specific read, write and edit capability, across languages. White-label capability and ability use your own cloud. Perfect for healthcare enterprises where you require your client information to be in a country specific cloud.  Please contact us if you require an enterprise quote.\nMULTI LINGUAL FORMS     Multilingual forms for your global team    Multilingual Forms  Only available in the enterprise subscription. Translate your processes and offer this to staff, clients and stakeholders, allowing them to work in a language they understand. Once the forms are filled out in the target language, translate back to English allowing your staff to close out the process, and handle negative workflow, across languages. Control staff, client and other stakeholders actions at a granular level. Forms can be set with user specific read, write and edit capability, across languages.  CONCLUSION  If you want to add captions to your social media content, without having to pay for manually transcription, use the AI to transcribe. If you want to translate your social media content, use our platform to do the heavy lifting, and pay your staff to do higher value tasks. Build multi-lingual forms, reducing losses from miscommunication and cultural misunderstanding. Audit every interaction and iterate.  ","permalink":"https://videotranslator.ai/solutions/","tags":null,"title":"Solutions"},{"categories":["Video Translation","Engineering","Retail","Languages","Artificial Intelligence"],"contents":"If you didn\u0026rsquo;t catch it, last Thursday January 24, 2019 DeepMind\u0026rsquo;s new AI, AlphaStar beat a Team Liquid player Grzegorz Komincz, also known as MaNa in a professional game of StarCraft II.\nWhat are we talking about? StarCraft II is a real-time strategy game by Blizzard Entertainment, which has become a staple of the eSports community. Professional play has been ongoing since the game\u0026rsquo;s initial release in 2010, following on the success of StartCraft and StarCraft: Brood Wars, both of which had substantial eSports fan bases.\nThat is, StarCraft II is a computer game which has been played competitively for ~ 20 years. Major leagues in this include the Korean eSports Association (KeSPA), Intel Extreme Masters (IEM) World Championships and BlizzCon, with professionals making 250K+ on prize money alone. Find the global rankings here.\nDeepMind's latest/greatest AI AlphaStar, just beat a top ranked StarCraft II player. This post is about what happened, what it means and how to think about AI sensibly. AlphaStar is the evolution of other Alpha- projects,AlphaZero for Chess and AlphaGo for Go.\nStarCraft II - Basic Rules for Humans and Machines The StarCraft franchise has a large/complex storyline (lore in gamer-speak) which sets up the games, but that isn\u0026rsquo;t terribly important. Here is what you need to know:\n  There are three main factions, Protoss (advanced alien), Terran (future human) and Zerg (bugs ala Starship Troopers), each with unique units. The way to think of this from a game theory perspective is as a complex version of Rock-Paper-Scissors.\n    StarCraft II game play: Protoss (Gold), Terran (Blue) and Zerg (Red)      The play is generally between 2 players and takes places on tournament maps. Tournament maps are generally modified to include multi level terrain with high ground advantage, strategic choke points, terrain modifiers which impact unit speed, range and hit points among others. A standard complexity 1v1 map is shown below.\n    StarCraft II (1v1) map, normal start would be at top left and bottom right      There are two basic resources, minerals and gas. Some maps also have a special minerals which translates to quicker unit production. The other major issue is fog of war which translates to incomplete knowledge of the map, necessitating scouting, cheesing and other assorted mind-games.\n  The players actions are basically, build mining units to get resources, use resources to make weapon units, and kill other players weapon units while surviving yourself. As such, the build order (the order in which you build units and structures to maximise chances of winning) becomes super important, not least because the times for specific strategies are well known, leading to timing attacks.\n  StarCraft II - Micro and Macro Game   Micro refers to the ability of the player to perfectly control their units. Units in StarCraft II often have abilities. A simple example is something like a MedEvac unit allows other units to load up, and also heals. Being proficient in micro allows a player to perform better in ground level engagements.\n  Macro refers to the ability of the player to match their opponent in building bases and drones, the idea being to successfully min/max unit production.\n  Another consideration around macro refers to strategy transitions. Each race whether Protoss, Terran or Zerg has a technology tree which allows players to make unit composition choices. An example of this in Terran, is the choice between bio - which refers to units like marines and snipers (Ghost) or mech - which refers to tanks etc.\n  To understand the differences, please have a look at this guide. This is important, because to think about the relative strengths of the AI, the real test is AlphaStar's ability to balance Micro and Macro game.\n  Visually in the below example, red goes hard on unit production early attempting to win with good micro, but blue focuses on macro game, and wins. Note, the graph is of Army Value (think unit count hence micro focus).\n    Red focuses on unit production, while Blue focuses on macro game to win      AlphaStar - Abilities + Limitations Well described in the original blog post, are the challenges that the DeepMind team faced when training their AI. These include: game theory - no single best strategy, imperfect information, long term planning, real-time and large action space. Also included in that post is the basic process of how the training worked. What you need to know:\n  The AI was trained using an advanced generative adversarial network (GAN) AI. This is a fancy way of saying they took multiple AI's (agents) and made them play against each other. So the final AI has the equivalent of 200 years of StarCraft II gaming experience.\n  The AI was trained on (and can only play) Protoss vs Protoss - that is one faction against itself only, and on Catalyst shown below.\n    StarCraft II (1v1) map Catalyst, where AlphaStar played MaNa from Team Liquid      The AI was limited to control the units in a way which emulates human limitations. So the AI was limited to under 300 APM (actions per minute). This is on the low end compared to professional players, the world champion Serral averages ~450 APM.\n  Additionally, the AI is also limited see the map like a human, it cannot just flick around and see everything, it is limited using a screens per minute to simulate human reaction times. It must virtually click around to trigger actions and look at different places on the map. The primary role of AlphaStar is to look around, prioritize its actions and engage in unit control in engagements.\n  What Happened - Cheeses + Mind Games   AlphaStar beat MaNa 5-0. Ok - so this was not totally unexpected. It should also be noted, that the human players were NOT playing their preferred faction in StarCraft II, because AlphaStar currently can only play Protoss v Protoss, on Catalyst LE. It can\u0026rsquo;t do anything else.\n  Cheese most often refers to an unexpected strategy that relies in large parts on lack of information and/or psychological impact on the opponent. Cheese build orders typically revolve around an early attack that, if undetected, is more difficult to defend than execute.\n  Have a look at this to find examples of more cheeses. Cheesing is most effective when mixed with mind games, most of which reflect imperfect knowledge about what your opponent is doing, relying on fog of war.\n  In this clip, (i) TLO sends over a probe to scout, (ii) AlphaStar sees the probe detect a stargate, (iii) waits until the probe no longer has visibility, and (iv) cancels the stargate.\n  AlphaStar plays mind games with LiquidTLO\n     This behavior is very human like, but why it is doing some of these things is not entirely clear. For example, seen here something interesting happens. The AI overproduces probes on the first base (that is, it saturates the base and hence the base efficiency is lower) where as a human would not do this and you would think that a machine would also not do this, seeing as the AI is likely to understand going over 100% reduces efficiency - but AlphaStar does any way.\n  AlphaStar over-saturates its main base, getting 19/16 drones\n     Conclusion  On watching the stream, and you should totally check it out, I was impressed, intrigued and a little bit terrified. Which seems like an appropriate response. AlphaStar seemed to have a lot of trouble with macro transitions. So a fairly textbook strategy for Terran would be, (i) start with bio - marines/marauders, (ii) transition to mech by mid game and, (iii) then move to air units for late game. AlphaStar cannot (from my understanding of its training regime) respond to this kind of play. AlphaStar tends to start with a composition, and then make minor changes. This makes sense when you think about how the neural network was trained. The main place where AlphaStar absolutely blew me away, was its micro control. So there were large parts of the games where the Actions Per Minute (APM) for AlphaStar was in the 60's, whereas its human opponent was at 300+. But looking at the play, the micro was amazing. AlphaStar is obviously a computer, so you would expect it to NOT make mistakes clicking around, but it is still very impressive. Will AI\u0026rsquo;s like AlphaStar dominate StarCraft II going forward - absolutely not. StarCraft maps, to provide just one example, are evolving towards allowing players to using deeper macro strategy - such as, where should my 3rd base be is less of a tactical decision and more of a strategic decision going forward, which makes it immeasurably harder for an AI to win.  However, the longer term implication is pretty clear, DeepMind took an AI and is teaching it to mimic a gestalt consciousness (Zerg is an exo-galactic hive mind in StarCraft II lore). This might not end well :)\nExtra You should totally check out the LowkoTV and WinterStarcraft channels if this was interesting. They are both good guys and would appreciate the custom.\nPlease connect with us on LinkedIn, YouTube or Facebook for any comments, questions, or just to keep up to date with the work we do!\n","permalink":"https://videotranslator.ai/news/how-deepmind-just-beat-team-liquid-at-starcraft-ii/","tags":["English"],"title":"Bleeding Edge AI: How A DeepMind Just Beat Team Liquid At StarCraft II"},{"categories":["Video Translator","Engineering","Visual Guides"],"contents":"Given we are getting super close to launch, there are a lot of conversations with prospects who are keen to use our product. We get many (welcome) questions from prospects/clients on how to use the platform. Additionally, because we are a new start up, we don't have great documentation. How to solve this problem with limited bandwidth?\nThe requirement is pretty simple, an easy way to communicate with prospects and clients, which stacks. The stacking aspect is the idea that effort today should not just be useful today, but also should compound in some way.\nA forum could meet this requirement quite nicely. First, it allows us to link a natural extension to blog posts, in a questions? comments? continue the discussion here... way. Second, it should help us provide better support to our clients as we answer complex questions on how to use the product.\nHow does a forum stack? If the forum software is relatively modern, the questions asked and answers provided become a shareable resource. These questions and answers can be indexed by search engines, can be queried, and basically turn into a very useful knowledge base which prospects, clients and staff can refer to as the need arises.\nDo We Need A Forum? We started by looking around for what a forum does? The folks at WiseGeek have an article which covers the basics, An Internet forum is a discussion area on a website. Website members can post discussions and read and respond to posts by other forum members. A forum can be focused on nearly any subject and a sense of an online community, or virtual community, tends to develop among forum members.\nClearly though, there is more to forums than just the above. Some of the complexities of running a forum can be seen from the comments below the same article. The long and short of it is: ymmv, or your mileage may vary.\n    Comments on an article about Internet Forums    So this could get exciting. However, our choice to build a forum was made with the following objectives in mind:\n Build A Community - this lets us know what prospects/clients think of our product, and what we can do to improve it. Crowd Source Service and Support - this is a cheap way to provide support from the existing user base. But, the quality of the support varies. This can be a double edged sword. Social CRM - a form of CRM where the interaction between client and vendor is mediated through a social media channel.  If you want to read more about these tradeoff\u0026rsquo;s, this article from 2010 covers some of the concerns.\nWhat Do We Need From A Forum? Okay, we are getting a forum. Which one though? Below is some of our requirements when picking a forum.\n We want a nice new piece of software. Our own stack is, React, Meteor, Node, and Mongo. So we were looking for Node JS solution\u0026rsquo;s as opposed to PHP, though we would be happy to consider a Ruby-On-Rails or some other modern software solution. We use a lot of cloud hosting, and as a startup firm, want to be conscious of cost. So in an ideal world, we can get something which is open source to start with, self host, and then later move to a hosted solution when we are happy to pay someone else to manage it. Want a nice way to manage users, mostly to ensure that trolls and other toxic commenters are kept out. Largely, ensuring the forum is focused on our technology and how it is being used, should manage most of these issues for us. Want to be able to use the forum as a knowledge base, so it should be relatively simple to add images and other hypermedia to the forum. Some gamification, because as usesrs of forums, we know how much of a difference that makes.      Interaction badges used in Forum Software    As heuristics go, we are big fans of Meteor, and their forums in terms of providing prospects and clients with answers in a timely manner. There are a number of articles we looked at like this, this and this which gave us some ideas. The key point to consider is how forums are different, in terms of the structural elements of managing the interactions between users - the last link is to a Reddit thread which covers many of these concerns.\nFor us, we decided to not get cute and stick with the Discourse forum.\nHow To Setup Discourse On A Digital Ocean Server? We added a discourse forum to the website. The people at discourse define the project as, Discourse is the 100% open source discussion platform built for the next decade of the Internet. Use it as a mailing list, discussion forum, long-form chat room, and more!\nGiven we are a new startup, the plan was to not use the hosted discourse solution, but instead build out a self hosted forum. The actual building out of the forum was very simple, and probably took a total of 2 hours from start to finish.\nSteps To Setup Digital Ocean Server, MailGun Emails And A Discourse Forum.   We are on Digital Ocean infrastructure, so we picked an off the shelf $10/month Ubuntu 18.04.1 box, with 2GB of RAM as that is the minimum requirement Discourse has - its just a Docker image. The process is detailed (here)[https://www.digitalocean.com/docs/one-clicks/discourse/], and looks like the below image - all we are doing is initialising a new droplet with a Docker image of the latest Discourse.\n    Digital Ocean 1-Click-Deploy      We also selected the Singapore data centre, extra monitoring and added an SSH key. It took a few minutes to build, and this was all pretty straightforward. We need to setup MailGun properly before we can log into our new Discourse deployment. Note: We use MailGun for our email infrastructure.\n  A bigger challenge was setting up MailGun which the Discourse forum needs for emails. The Discourse forum will need the below MailGun settings to work properly. Assume some additional time for the records to refresh and for typo\u0026rsquo;s if you are not a DevOps specialist.\n SMTP Hostname - smtp.mailgun.org SMTP Login - postmaster@forums.your-domain.com Password - your-complicated-default-password    Please note the Domain Verification and DNS settings in your MailGun. These settings will need to be put into Digital Ocean in the networking setup (or where ever you manage you DNS settings). Specifically, you will require the below records added.\n CNAME - email.forums.your-domain.com [Hostname]; mailgun.org. (value); TXT - mx._domainkey.forums.your-domain.com [Hostname]; some-large-key-autogenerated-by-mailgun (value); TXT - forums.your-domain.com [Hostname]; v=spf1 include:mailgun.org ~all (value); A - forums.your-domain.com [Hostname]; your-digitalocean-ip (value);    Once the above records have been added to your DNS settings, verify that MailGun can see this information properly. The button is shown below.\n    MailGun DNS Verification      Once the verification is happy, we will need to setup the Discourse forum on our server. We already have the droplet, so log in ssh root@your-digitalocean-ip. On successfully logging in, the droplet will run a startup script which will need the above information (and an administrator email/password). Note this will all happen in Terminal or your specific command-line tool.\n  We also need another email address, for the Let's Encrypt digital certificate. Once complete, the Docker image will run an update cycle to the latest Discourse source code, do a (re-)compile and start the process. Once complete, exit the server. Now go to the ip in your browser, specifically to http://your-ip.\n  The setup is simple from here on - this resource has some screen shots, but largely its just adding some branding information. This resource shows how to do the install without the 1-click deploy, which may also be useful. Once complete, go to your https://forums.your-domain.com and you will see something similar to the below.\n    Video Translator forum deployed successfully      Conclusion The platform is currently in closed beta, while we work out bugs in the code. Now however, you are able to post questions on our new forum, and hopefully we can start getting some useful information up. Additionally, we will be adding topics from posts into the forum, so please feel free to add your feedback, or any questions you may have on our new forum.\nPlease connect with us on LinkedIn, YouTube or Facebook for any comments, questions, or just to keep up to date with the work we do!\nWe are very grateful for your support!\nIf you are interested in trying out our technology, please drop us an email at hello@videotranslator.ai.\n","permalink":"https://videotranslator.ai/news/how-to-add-a-forum-to-your-website/","tags":["English"],"title":"How To Add A Forum To Your Website"},{"categories":["Transcription","Translation","Video"],"contents":"Today we are going to look at how to transcribe a foreign language video. But how does this work when we live in a globalised world where people are from many different places - exactly what is foreign?\nWell, Video Translator\u0026rsquo;s platform provides a client with the ability to transcribe and translate content to/from a number of languages, as discussed here.\nWhat we are looking at today, is how to transcribe a video in an language you do not know. Mostly, we will make changes to a template, and implement these changes in our items. Here, we have Hindi captions on a speech by Narendra Modi, the current Indian Prime Minister. The assumption is, we do not know Hindi.\nNote, no edits have been made to the underlying text, not after the transcription, or after the translation, hence the accuracy is low. As always, we recommend using the AI to do the heavy lifting, and using a human subject-matter expert to clean up the results.\nNo really, use a subject matter expert and do not cheap out on translators. This tool is built to increase efficiency, not short change staff/contractors.\n  Narendra Modi speech with English captions\n   Context It is important to understand what we are doing. We want to transcribe the speech, but we do NOT know Hindi, hence cannot translate this content. So we will pretend to translate our template, but actually simply set it up to expect Hindi content.\nThen we add the Hindi content, but because the original template was in English, we can bring back the content (translate back from Hindi -\u0026gt; English). Effectively a four transform process, English template -\u0026gt; Hindi template -\u0026gt; Hindi item, and lastly because the original template was in English, we can take our Hindi item -\u0026gt; English item.\nIt may be useful to also look at this post to understand the strategy we are using. We will be modifying our templates to work with multiple languages, its just that in this case we do not know the language we are trying to use. The video content is publicly available content sourced from Rajya Sabha TV.\nSteps - Template   Please direct your browser to videotranslator.ai and log into the application. Once logged in, open up a new template, or just use our old friend, myTemplate. Note, we are in a collection named Sydney - your collection is likely to be called MyTeam. Please have a look at account settings to make any changes.\n  Open up myTemplate, and check the Language Options to see something similar to the below image. In collection Sydney we have access to several languages including English, French, Hindi, Chinese, Portuguese and Hebrew. We will only be working with English (our primary language) and Hindi (one of our secondary languages) in this post.\n    Template showing Language Options - English/Hindi      Now, we are not looking to overlay any audio, so we can remove the audio component. However, we will translate it for illustration purposes, showing how to use the translation function on templates.\n  First, to translate this template into Hindi, click the Action -\u0026gt; Translate function. Now, do not select the video component, but only select the audio component. We do not need the audio component, but are translating it anyway to show what the Hindi item will look like.\n    Translate the audio, but not the video      This should give us a new Hindi template, which looks like the below. Note, the video component is NOT translated, while the audio component IS translated. We will not be using the audio component in this post, but any item of type hi_myTemplate will show the video component in English, and the audio component in Hindi.\n    Hindi Template, with Audio component translated      Note that in the Language Options above, this template shows Hindi as its primary language, and Hindi and English as secondary languages. That is, items of this template are expected to be in Hindi, and can we translated to English as required.\n  Steps - Item   We setup our Hindi template following the steps above, now we can use this to reach our goal of transcribing the Hindi video. Add a new item called modi_hindi and upload the content as required. The below image shows what our new item looks like prior to uploading the video.\n    Add a new item of type: hi_myTemplate        Item, with video in English and audio in Hindi      Again, we do not need the audio component. The only reason we translated it, is to show how we can selectively translate specific components depending on our workflow. We will only be using the video component.\n  Upload the video, and then transcribe to get the captions as required. This looks like below.\n  Narendra Modi speech with Hindi captions\n     We can now see the captions have been populated. Note, general workflow would include using a Hindi subject matter expert to clean up the captions.\n    Hindi captions with font, colour and size options      In this post, we have NOT cleaned up the Hindi transcription. This is BAD example, because as a political speech, the majority of it is using humour, in jokes etc to reach the audience - none of which is a strong point for an AI. AI works best with thing type content. The more subtle the context, the less likely an AI is to do work properly. Please use subject-matter experts with content of this nature.\n  Below, the translated version (into English) is shown, and watching it will show the errors. The error compounds, because (i) our transcript is not great, (ii) our translation was based on the same dodgy transcript.\n  Narendra Modi speech with English captions\n     Conclusion In this blog post we have covered how to transcribe a video in a foreign language. We specifically used this example, to show the limitations of AI. As always, use the AI to do the heavy lifting, but get a subject matter expert to think about your content and finesse the results to the needs of your audience.\nThe platform is currently in closed beta, while we work out bugs in the code. If you are interested in trying out our technology, please drop us an email at hello@videotranslator.ai.\nPlease connect with us on LinkedIn, YouTube or Facebook for any comments, questions, or just to keep up to date with the work we do!\nWe are very grateful for your support!\n","permalink":"https://videotranslator.ai/news/how-to-transcribe-a-foreign-language/","tags":["English","Hindi"],"title":"How To Transcribe A Foreign Language Video"},{"categories":["Translation","Enterprise"],"contents":"We live in a modern world, which means working with colleagues, internal and external stakeholder, and clients from different backgrounds. For everyday interactions, this is fine, but every now and then, it can get messy.\nDoes this resonate with you? An important client in Asia needs something, and they are not happy. However, the operations person you are speaking to does not speak great English, and so an important deal has been bungled. If you\u0026rsquo;re particularly unlucky, right now while you are reading this post, said deal IS being bungled.\nThis post is going to cover how to build multi lingual forms, so that you can get information to and from different parts of your organisation effectively. It assumes you have either (i) overseas outsourced service provider who may not have good communication skills (in English), or (ii) overseas export prospects/clients with staff who you have to deal with, who also lacks communication skills (in English).\nSpecifically, we will take a simple form in English, and translate to French (our assumed non English speaking client) and Hindi (our assumed outsourced service provider).\n    Sample form (Original)        Sample form in French        Sample form in Hindi    Steps   Please direct your browser to videotranslator.ai, and then click on the Login button. Once logged in, create a new template called myMultiLingualTemplate.\n    Add a new template: myMultiLingualTemplate      On entering myMultiLingualTemplate, click on View and select to show Language Settings. This should look like below - please note, this specific subscription is an enterprise subscription with English as the primary language, and French and Hindi as secondary languages.\n  We are simulating an organisation with English as our primary language spoken across the organisation. In this specific case, we will pretend our organisation has an external client in France, hence the French, and an outsourced back office in India, hence the Hindi. Removing any secondary language will mean items of this template cannot be translated into the unselected language. Please close Language Settings once complete.\n    Language Settings showing secondary languages - French and Hindi      We can now add different components. In this post we will stick to fields, which both retail and enterprise subscriptions have access to, but please note complex (nested) data structures can be handled with generics.\n    Building a Template: Generics        Building a Template: Fields      So we are just going to add one text field here - where are you from - in the form. Click to add a text field, and the result looks like below. Note that the Information has been changed from Please upload Text content? to Where are you from? in our example.\n    Adding a Text component: Where are you from?      Above, please also note the additional collections available. Essentially template knows its items are expected to move between collections Sydney, Mumbai and Paris. The eye icon denotes read permissions, and the pencil icon denotes write permissions.\n  The process is almost complete. Now, we simply translate the template and get the translated versions - one for French and one for Hindi. Each template can now produce items as required.\n    Translated to French        Translated to Hindi      Once complete, the forms look like below. Again, the use case for this is, (i) the French form is for a client in Paris, who wants to fill out the form in French, and (ii) the Hindi form is for the outsourced service provider in Mumbai, who wants to fill out the form in Hindi.\n    Sample form in French        Sample form in Hindi      Above, please note the transliteration option in the Hindi form - in an ideal world, your client fills in this form using a computer set to a French keyboard (or Hindi keyboard), however this might not be the case. The transliteration service allows for a user to type Hindi into a English keyboard, and the transliteration is phonetic.\n  Due to the nature of the platform, the French form or Hindi form above, when filled in can be brought back to English (using translate again), so that the English speaking staff can work with the form information.\n  Conclusion This is a fairly complex post, and largely, it is not expected that the average user will need to use this functionality. Should you have any questions, specific to enterprise subscription functionality, please talk to your account manager.\nPlease connect with us on LinkedIn, YouTube or Facebook for any comments, questions, or just to keep up to date with the work we do!\nWe are very grateful for your support!\nShould you have any questions, or just want to drop us a note saying hello, please feel free to send us an email at hello@videotranslator.ai.\n","permalink":"https://videotranslator.ai/news/multi-lingual-forms-what-black-magic-is-this/","tags":["English","Hindi","French"],"title":"Multi-Lingual Forms... What Black Magic Is This???"},{"categories":["Management","Finance","Enterprise","Visual Guides","Languages","Users"],"contents":"In today\u0026rsquo;s post we look at how to manage your account. This will cover Root and Management workspaces. The ordering reflects the navigation pane at the top right of the application. Please note, for more information covering how to add and remove languages specifically, please have a look at this post. Information about the Finance section will be covered in a later post.\nThis post is written to explain the use cases of account management, and why options are laid out as they are - if we have reached out to you for feedback, please feel free to come back with ideas on how you use/would like to use the interface. We welcome the feedback.\nRoot: Top-Right Navigation   Please direct your browser to videotranslator.ai, and then click on the Login button.\n  In the below image, the following is visible, (i) top-right navigation bar showing Root \u0026gt; MyTeam, (ii) top-left hamburger options, (ii) top-left information bar showing Root, Credit, and Help, (iv) folders and files, and (v) folder actions. Note we will talk about folders and files and their respective actions in another blog post.\n    Application Interface on Login      The top-right navigation bar, showing Root \u0026gt; MyTeam refers to a one-to-many relationship between Entity and Collection. Entity here refers to your organisation, whether for profit corporation, non profit, or government. Collection simply refers to a set of users with access to assets.\n  Clicking on Root takes us to the global, within which we can see our Entity -\u0026gt; MyCompany. If our specific user had access to multiple Entities, we would see them here. Note: don\u0026rsquo;t worry about this if you have just signed up. Additionally, we have clicked on MyCompany, showing the option to view inside this entity.\n    Root: Global view showing entity \u0026#39;MyCompany\u0026#39;      Clicking on the View, will bring us down one level, to our team MyTeam. Note: If, on Login, you have access to only one Collection, you will directly be taken to that screen. Clicking on View again will take us to the original view.\n    Root: Local view showing collection \u0026#39;MyTeam\u0026#39;      Root: Top-Left Hamburger   The top-left hamburger is an easy way to navigate around the account management. In this case, the user\u0026rsquo;s name has been set to John Smith for this tutorial. Clicking on John Smith is simply a shortcut to the Root \u0026gt; MyTeam collection.\n    Top-left navigation hamburger showing account management options      Account is personal account settings, allowing chnages to (i) user name, (ii) user email and user password reset.\n  Root: Top-Left Information   Clicking on the cloud takes you to your Root. Please note, access to multiple entities and users is available to all subscribed users, while access to multiple collections is limited to the enterprise subscription. Clicking on Root anywhere will automatically redirect you to your assets.\n    Top-left information bar showing Root, Credit and Help      The $ shows the available credit linked to this subscription. Clicking here will take you to the Finance section. Similarly, clicking Help will take you to the help section. Another valuable resource is on the documentation page.\n  Management: General Settings + Collection Settings   Please use the top-left navigation to go to the Management section. This should look something like below.\n    Management: General Settings      It is possible to change the name of your Entity here - in the below image we changed the name of our Entity from MyCompany -\u0026gt; Sample Firm, which can be seen in the Root.\n    Root: MyCompany -\u0026gt; Sample Firm      Next we look at the Collection Settings. If you have an enterprise subscription, this is where you can add multiple collections. The below image however, shows a retail subscription with the original collection only, MyTeam. On clicking MyTeam, we also see options to, (i) Update Languages, (ii) Update Access, and (iii) Properties.\n    Management: Selected \u0026#39;MyTeam\u0026#39; to manage languages, users and properties      It is possible to add and remove AI\u0026rsquo;s here - if you are looking at the enterprise subscription, please contact us for custom AI deployments and white label solutions. In the below however, we can see 3 AI\u0026rsquo;s, a Text-To-Text AI, two transcription AI\u0026rsquo;s - one for Speech-To-Text and the other for Text-To-Speech. The last option is the Human 1, which is to add specific sets of human resources to the workflow.\n    Management: Managing AI permissions on a per Collection basis      User permission management, on a permissions per collection basis, is also managed here. Our specific entity, now called Sample Firm has only one user, John Smith. Additionally, we also have only one collection, MyTeam. Mathematically (set theory), this represents a one-to-many relationship between Entities -\u0026gt; Collections, and a one-to-many relationship between Entities-\u0026gt;Users. The permissions cover the relationship between the Users and Entities, this of course is defined as a many-to-many.\n  Click the User Availability to turn on/off access to this collection. Click the specific permission to turn it on/off for the specific user in a specific collection. The permissions are fairly self explanatory, please contact the support desk for more information.\n    Management: Managing user permissions on a per Collection basis      Management: User Settings   While it is all well and good to change permissions, how do you add/remove additional users? Jump over to the user settings. We can do two things here, (i) give existing users Management and Finance permissions, and (ii) add new users from outside our entity.\n    Management: Managing user permissions on Entity basis      Click on John Smith, we as management can add/remove permissions to Management and Finance. This is effectively an equivalent of an Administrator function. Additionally, we can also reset the users password here. Please note, the user will still need to verify their email and/or work through 2FA.\n    Management: Administrator style permissions and password controls      Similarly, we can invite other users (internal or external) using the panel below. Please note, what we are doing here, is adding external users to our collection under some preferred permission set. The idea is we invite resources to our collection, so they can do some specific task as part of our workflow.\n    Management: Add an external user      Conclusion This is a fairly complex post, and largely, it is not expected that the average user will need to use this functionality. Should you have any questions, specific to enterprise subscription functionality, please talk to your account manager.\nPlease connect with us on LinkedIn, YouTube or Facebook for any comments, questions, or just to keep up to date with the work we do!\nWe are very grateful for your support!\nShould you have any questions, or just want to drop us a note saying hello, please feel free to send us an email at hello@videotranslator.ai.\n","permalink":"https://videotranslator.ai/news/tutorial-how-to-manage-your-account/","tags":["English"],"title":"Visual Guides: How To Manage Your Account"},{"categories":["Transcription","Translation","Video","Healthcare"],"contents":"Video Translator\u0026rsquo;s platform provides a client with the ability to transcribe and translate content to/from a number of languages, as discussed here. What we are going to do today is transcribe content to a different language, and use a practical example to demonstrate the technology.\nWe will be using this video, from the team at NSWHealth. The video is a simple, but effective solution for young mothers, where NSWHealth provide a useful box of household items aimed at first time mothers.\nThe idea is to (1) transcribe from English, (2) translate to German, (3) transcribe to German, with the end output being the same video in German. To illustrate using a contrast, we use a male German voice. That is, we are doing a English to German video translation. Please play the video to see the end result of the process described below.\n  Baby Bundle: English Audio Muted \u0026#43; German Audio Overlaid\n   Steps   Please direct your browser to videotranslator.ai, and then click on the Login button. On successfully logging into the application, select the template, and using the highlighted button, View Template: myTemplate.\n  For a detailed discussion of how to edit the template, have a look at this post. But the template should look similar to below, note we require both an audio component and a video component.\n  The Language Options have also been opened up, and the translation possibilities are shown. In this case, we can translate the video into French, German or Hindi.\n    Template showing Language and Structure Options      Lets quickly create an item of type myTemplate, called baby_bundle and upload the video. The voice\u0026rsquo;s are unsurprisingly, Australian female which we will switch to German male to demonstrate the multiple voices. Below is the original video from NSW Health.\n  Baby Bundle: Original\n     We do a quick transcription, and then investigate the returned Captions. The captions are pretty good, but its important to check the result. A good rule of thumb is to check when different people start talking, as the differences in how two individuals sound, can confuse the AI.\n  In this specific case, the AI missed the early part of what the gentleman was saying at the 00:30 second mark. The captions, after some manual editing look like below.\n    Captions after transcription      Now that we have the captions, we use the translation AI to produce a German version. Explicitly, we are using the AI to translate from English to German for the captions only, hence the audio component is not selected. Also note that we are creating a copy of the asset, and attaching the German translation to this copy of the asset.\n    Translation from English to German 1        Translation from English to German 2      We open up the new de_baby_bundle item, and now we do two things, (1) we add the caption into the audio component (copy/paste), and (2) trigger transcription again, but this time only on the second component (the audio component).\n    Copy/Paste Captions into Audio        Transcription using a German Male Voice      We now add the audio into the original asset as an overlay, and additionally mute the original audio to achieve the desired outcome. It should also be noted that we are still using captions all the way through - another alternative would be to remove the captions and put in a text overlay to allow us a finer level of control over the look/feel of the new asset.\n    Copy/Paste Captions into Audio      Please note that the German will be incorrect - its just an AI. After translation, it is recommend that a human subject-matter expert clean up the results. The Video Translator platform is built on the logic of AI assisting people, the recommendation is to use the AI to do the heavy lifting, and use the human to do the high value tasks.\n  Baby Bundle: Completed Video Translation\n     Conclusion In this blog post we have covered how to add an audio overlay into your sample content. Please note, Video Translator makes no representation of a relationship with NSW Health, we are simply using a publicly available content to do beta testing on our platform prior to opening up our product.\nThe platform is currently in closed beta, while we work out bugs in the code. If you are interested in trying out our technology, please drop us an email at hello@videotranslator.ai.\nExtra As the platform is still in closed beta, (1) the UI may change in the future, (2) the pricing numbers shown are indicative only.\nPlease connect with us on LinkedIn, YouTube or Facebook for any comments, questions, or just to keep up to date with the work we do!\n","permalink":"https://videotranslator.ai/news/english-to-german-video-translation-what-is-a-babyb%C3%BCndel/","tags":["English","German"],"title":"English To German Video Translation: What is a Babybündel?"},{"categories":["Transcription","Video","Languages","Visual Guides"],"contents":"Our platform provides a client with the ability to transcribe and translate content to/from a number of languages, as discussed here. Recently, we added a number of additional languages specific to Text-To-Speech transcription. These are, (a) French (Canadian), (b) Portuguese (Brazilian), (c) Spanish, (d) Swedish, and (e) Turkish.\nIn total, Text-To-Speech transcription now has the below set of languages available. Please note each language has multiple dialects, and gender specific voices are available.\n           Dutch English French German Italian   Japanese Korean Portuguese Spanish Swedish   Turkish        In the below description, we show you how to use the additional languages, by overlaying audio into a video. It should be noted, transcription can be used in two ways, (a) Speech-To-Text, and (b) Text-To-Speech. This post is focused on the second option, Text-To-Speech.\nSteps   Please direct your browser to videotranslator.ai, and then click on the Login button. On successfully logging into the application, you should see an interface similar to the below. Select Template, and using the highlighted button, Edit Template: myTemplate.\n    Select the Template, and click Edit      Originally myTemplate has only one component. This is the video component. We are going to Add Audio component. On addition, you can see the Template with both Video and Audio components. The point is to have somewhere to use our Text-To-Speech AI.\n    Add Audio component to our Template        Template with both Video and Audio components      To recap, we edited the template to have both video and audio components. Save and Exit to the file system.\n    Save and Exit the Template      Click on our now modified myTemplate, and create a new item, big_bunny_2. The next step is to upload our old friend, the sample video.\n    Create new item Big Bunny 2        Added Big Bunny Sample Video      But what about our Audio Overlay, at this point we create it and are just going to add it in shortly. Scroll down to the Audio component, and instead of uploading a *.mp3, we instead add some text (Hello! My name is Big Bunny!) and click Add Caption. We are going to get the AI to say, \u0026lsquo;Hello! My name is Big Bunny!'\n    Added Caption: Hello! My name is Big Bunny!      Now we have some text, (a) Speech-To-Text transcribe, and (b) add an Audio Overlay. As shown below, we transcribe, but only the second component as this is where we need the voices - the plan is to use a British sounding AI voice.\n    Selected AI is the English (UK) dialect      Once complete, in the video component (a) Mute Original audio, (b) add in the Audio Overlay. Please note, we have set it to play between 2 -\u0026gt; 5 seconds, and used the +.\n    Adding the Audio Overlay      This gives us the final product. Please note (a) original audio has been muted, (b) new audio has been added, in this case the robotic voice of the AI. Please note, there is no requirement to use the AI, a human recorded audio codec is often preferable, depending on the target audience - click play below to have a listen.\n  Translate Video: Sample Video\n     Conclusion In this blog post we have covered how to add an audio overlay into your underlying content. Specifically, (a) we used an AI voice to simulate a person speaking UK English, (b) muted the original audio, (c) added the new audio onto the video to produce a new piece of video content.\nThis ability to add content can be across any of the above languages. We have used the example of English to keep it simple.\nPlease connect with us on LinkedIn, YouTube or Facebook for any comments, questions, or just to keep up to date with the work we do!\nWe are very grateful for your support!\nShould you have any questions, or just want to drop us a note saying hello, please feel free to send us an email at hello@videotranslator.ai.\n","permalink":"https://videotranslator.ai/news/more-text-to-speech-transcription/","tags":["English"],"title":"More Text-To-Speech Transcription!"},{"categories":["Transcription","Translation","Transliteration","Welcome","Languages"],"contents":"We look at the number of languages which you can use with your content. Remember, each languages is potentially a new market, and care needs to be taken to properly target your preferred leads.\nThere are two kinds of transcription, the first is Speech-To-Text Transcription, the second is a Text-To-Speech Transcription. In both cases, speech is involved, hence these are referred to as transcription AI\u0026rsquo;s. Similarly, with translation, what we are actually using is a Text-To-Text Translation AI.\nYou should also know, that technically transcription is the mapping of sounds of one language into another. However, in common parlance, especially when talking in the context of using AI\u0026rsquo;s, it means using the sounds to get the AI to work out the words.\nTransliteration is a little bit different, and does not use an AI. We simply use a mapping to achieve the desired result, and as the mapping can be phonetic, it requires a human to make sure it is done correctly.\nTranscription From Wikipedia, transcription in the linguistic sense is the systematic representation of language in written form. The source can either be utterances (speech or sign language) or pre-existing text in another writing system.\nSpeech-To-Text The following languages are available within the Speech-To-Text AI. The context here is, (i) upload video, (ii) trigger transcription, (iii) select dialect as required, and the transcription AI will do the rest.\n    Select a dialect to transcribe a French video    Please remember to check the captions (play the video) and make corrections are required. The rule of thumb here is, use the AI to do the heavy lifting, and get a (human) subject matter expert to check the results for your subject matter\u0026rsquo;s (i.e. your industry) specific acronyms/words.\n           Afrikaans Aramaic Arabic Armenian Azerbaijani   Bulgarian Bengali Catalan Chinese Czech   Danish Dutch German English Spanish   Basque Filipino Finnish French Galician   Georgian Greek Gujarati Hebrew Hindi   Croatian Icelandic Indonesian Italian Japanese   Javanese Kannada Khmer Korean Lao   Latvian Lithuanian Hungarian Malay Malayalam   Marathi Nepali Norwegian Persian Polish   Portuguese Romanian Russian Serbian Sinhala   Slovak Slovenian Sundanese Swahili Swedish   Tamil Telugu Thai Turkish Urdu   Ukrainian Vietnamese Zulu       Please note, we are working on adding additional AI\u0026rsquo;s for languages not currently covered. If you require a specific language, or your firm wants to plug a custom AI into our platform, please reach out. Additionally, each language can have several dialects - Spanish for example has 20 dialects - please ensure you select the appropriate dialect.  Text-To-Speech The following languages are available within the Text-To-Speech AI. The context here is, (i) add audio, (ii) add the *.srt or simply the text, (iii) trigger the transcribe.\n           Dutch English French German Italian   Japanese Korean Portugese Spanish Swedish   Turkish         Please note, additional voices are available, but use a less advanced AI (i.e. the synthetic voices feel more robotic). Please contact us for more information.  Translation The following languages are available within the Text-To-Text AI. The context here is, (i) upload content, (ii) trigger translation, (iii) select dialect as required, and the translation AI will do the rest. Below, the Automatic is the AI, while Human 1 is a in-house or external resource.\n    Select a language to translate a French video    Again, it should be stressed, the underlying AI is only as good as its training. Depending on the information complexity of your content (i.e. legal, medical, or just complicated) it is highly recommended you use the AI to do the heavy lifting, and get a subject matter expert (i.e. a professional translator) to check the results.\nIn practise, it is likely to be a far more effective use of the translators time, allowing them to focus on the high value content, and be less involved in the simple translations.\n           Afrikaans Arabic Bengali Bosnian Bulgarian   Cantonese Catalan Chinese Croatian Czech   Creole Danish Dutch English Estonian   Fijian Filipino Finnish French German   Greek Creole Hebrew Hindi Hmong Daw   Hungarian Icelandic Indonesian Italian Japanese   Kiswahili Korean Latvian Malagasy Malay   Maltese Norwegian Persian Polish Portuguese   Romanian Russian Samoan Serbian Slovak   Slovenian Spanish Swedish Tahitian Tamil   Thai Tongan Turkish Urdu Ukrainian   Vietnamese Zulu       Transliteration Transliteration is a type of conversion of a text from one script to another that involves swapping letters in predictable ways. In the platform, this is done using a phonetic mapping.\nGenerally speaking, your subscription will provide capacity for all the required languages. The below is an image of a textbox with three language options, English, German and Hindi.\n    Text: What is your name?    Now, we are going to do the same in Hindi, first we change the language, and then select the phonetic option (फोनेटिक), and then type out tumhaara naam kya he? in the English language keyboard to get below.\n    Text: तुमहारा नाम कया हे?    This is an implementation of the work done at the Wikimedia foundation. Please contact us if you have any questions around this implementation, or for corrections.\nConclusion Please connect with us on LinkedIn, YouTube or Facebook for any comments, questions, or just to keep up to date with the work we do!\nWe are very grateful for your support!\nShould you have any questions, or just want to drop us a note saying hello, please feel free to send us an email at hello@videotranslator.ai.\n","permalink":"https://videotranslator.ai/news/what-languages-are-available/","tags":["English"],"title":"What Languages Are Available?"},{"categories":["Video Translator","Management","Retail","Enterprise","Welcome","Happy-New-Year"],"contents":"We had a very good 2018 here at Video Translator. While a challenging year, the majority of the platform was built in 2018. Oddly, doing hard things well is enormously empowering, if a little scary. Important events in 2018 included:\n Moved into Fishburners, our brilliant co-working space, in the new Sydney Start Up Hub. Brought on two fantastic developers, Vivek Kumar and Pranay Shah. Both these guys have been absolutely critical in getting our platform over the line. The original vision for the platform was to be a Content Management System (CMS) for multi-lingual websites. While the technical side of this is simple, selling the solution was hard, especially to retail (as opposed to enterprise). In July there was a pivot, changing focus from websites -\u0026gt; video, which is (a) substantially simpler than websites, (b) really easy to explain/sell.  Happy New Year Here in Sydney, we had spectacular (if humid) weather over Christmas and New Year. Some thoughts, in no specific order.\nWe are looking to put the platform into production as soon as all testing is complete. The platform is currently in closed beta, and as such not yet open. If you would like early access, please feel free to ping us at hello@videotranslator.ai.\nThank you so much for all the support through 2018. Hopefully you are reading this coming out of a good holiday season. We at Video Translator hope you and yours have nothing but wins in 2019!\nTat Banerjee\n","permalink":"https://videotranslator.ai/news/happy-new-year/","tags":["English"],"title":"Happy New Year!"},{"categories":["Video Translator","Video","Visual Guides","Languages"],"contents":"We look at how to add languages for transcription, translation and transliteration.\nThat is, assume we have a video in English. We now need to translate into French and German. We need to add French and add German into our account, before the transcription or translation will work.\nIn brief, we assume that no additional languages were selected during the sign up process, and now we are looking to add additional languages to our account.\nSteps   It is possible to sign up for upto three (3) languages during the sign up process. Additional languages can be added using the process in this visual guide. The below image shows this capability.\n    Add Language: Select Languages during Sign Up      However, assuming we did NOT add French and German during sign up, we can also add languages in other ways. That is, we are assuming we did NOT add French or German in the sign up step, and we are now going to add French and German.\n  Login and your account should look like below. We will continue with the John Smith named user, showing the right navigation menu.\n    Add Language: Right Navigation Menu      Click into Finance. Explicitly, we want more languages, so we need to increase quantity from 1 -\u0026gt; 3. Confirm, and submit. NOTE: In this example, your subscription will increase from (USD) $10/month -\u0026gt; $30/month.\n    Add Language: Increase Quantity        Add Language: Confirm Increase Quantity      Switch into the Language Settings, and add French and German. Going forward, both Templates and Items will have access to French and German.\n    Add Language: French and German      Congratualtions, you now have access to French and German, in addition to English (your primary language).\n  Addendum 1: Add French, but not German, to a Template   Given you now have access to French and German, how do we use this functionality? Each template, and its corresponding items, has a list of languages which can be used. As an example, we can see the below languages in our original template myTemplate, as shown below. Explicitly we are missing French and German.\n    Add Language: Missing French and German      Now, add French only and exit. If necessary, also remember to save.\n    Add Language: Add French to Template      Adding a new item, thisItemCanBeTranslatedToFrench, and looking at its Language Properties, shows that content can now be translated to French.\n    Add Language: Add French Item        Add Language: Language Settings of New Item      Please note, Language Settings is showing that this item has a Primary Language: English and Secondary Language: French. That is, it expects English content to be uploaded, and if translation is required, this item can be translated to French.\n  Conclusion Please connect with us on LinkedIn, YouTube or Facebook for any comments, questions, or just to keep up to date with the work we do!\nWe are very grateful for your support!\nShould you have any questions, or just want to drop us a note saying hello, please feel free to send us an email at hello@videotranslator.ai.\n","permalink":"https://videotranslator.ai/news/tutorial-how-to-add-languages/","tags":["English"],"title":"Visual Guides: How To Add Languages"},{"categories":["Translation","Video","Visual Guides"],"contents":"We look at how to translate video content. Translation is the communication of the meaning of a source-language text by means of an equivalent target-language text1. In brief, we will (i) upload a video, (ii) add text, (iii) translate the video text, (iv) download a translated video.\nSteps   We need a sample video to work with, and will use the Big Bunny video from Sample Video\u0026rsquo;s.\n  Click on the New Item button to create an item. Then, and upload the video as per the below.\n    Translate Video: Add an Item        Translate Video: Upload Video      Now, we are going to add some text. This text will be translated in the next step. Click on Text Overlays, add an overlay, and add text as per below image. It should be noted, we have used font 60, and used a yellow text colour.\n    Translate Video: Add Text Overlay      Play the video to see below. It should be noted, this is a Text Overlay, and not a Caption. We could also have used a caption here if required.\n  Translate Video: Sample Video with Overlay\n     The next step will be a translation, we will translate \u0026lsquo;Hello World\u0026rsquo; to German. Use the Action -\u0026gt; Translate, and select the required language. Note: Cost shown below is indicative, all documentation is written using our UAT environment.\n    Translate Video: Translation        Translate Video: Set Name      Once complete, the process produces the below. Congratulations, you have translated your video.\n  Translate Video: Sample Video with Translated Overlay\n     Conclusion Please connect with us on LinkedIn, YouTube or Facebook for any comments, questions, or just to keep up to date with the work we do!\nWe are very grateful for your support!\nShould you have any questions, or just want to drop us a note saying hello, please feel free to send us an email at hello@videotranslator.ai.\n","permalink":"https://videotranslator.ai/news/tutorial-how-to-translate-a-video-without-sound/","tags":["English","German"],"title":"Visual Guides: How To Translate A Video without Sound"},{"categories":["Transcription","Video","Visual Guides"],"contents":"We look at how to transcribe video content. From Wikipedia, \u0026lsquo;Transcription in the linguistic sense is the systematic representation of language in written form. The source can either be utterances (speech or sign language) or pre-existing text in another writing system.\u0026rsquo;\nIn brief, we will (i) upload our content, (ii) trigger transcription, and (iii) download a video with our embedded transcript. To transcribe your existing video content, please follow the below steps.\nSteps   Please direct your browser to videotranslator.ai, and then click on the Login button. On successfully logging into the application, you should see an interface similar to the below. Select myTemplate, and using the highlighted button, add a new item.\n    Transcribe Video: Select a Template        Transcribe Video: Add an Item      Select the item, and using the highlighted button, open it. Then, using the highlighted button in the \u0026lsquo;Upload the Video\u0026rsquo; image, upload your video.\n    Transcribe Video: Enter the Item        Transcribe Video: Upload the Video      Once your video is uploaded, please use the highlighted, Actions -\u0026gt; Transcribe, to trigger the transcription process.\n    Transcribe Video: Action -\u0026gt; Transcribe      Please select a dialect, and the preferred video. A cost estimate is also be provided. Please note, costs vary based on length of video, and which specific AI is used, a rough estimate is about 10-20 cents/minute.\n    Transcribe Video: Select Dialect      Once triggered, please allow the process to complete. This can take up to a few minutes, depending on the length of the original content. Please note, we apply a hard limit of 100mb on uploaded video to prevent abuse. Please contact our Support team, if a change is required.\n  On completion, please click the video to Play, and to view the captions. Buttons are also available to (a) download the video, (b) download the caption file (*.srt), or (c) a hosted Content Delivery Network link to the video.\n    Transcribe Video: Download the Video/Caption file, or Share      Alternatively select the Captions tab to view the transcript. Should you wish to edit, please make changes and select Add Caption to apply edits. The Sub Caption will remove the captions from the underlying asset.\n    Transcribe Video: View/Edit Captions      Congratulations, you have successfully transcribed your content.\n  Conclusion The process to transcribe a video is:\n Upload your content; Click the transcribe button, making sure to check the correct dialect/video is selected, and start the process; Once transcription is complete, please check the quality by watching the video, and make edits as required;  Please connect with us on LinkedIn, YouTube or Facebook for any comments, questions, or just to keep up to date with the work we do!\nWe are very grateful for your support!\nShould you have any questions, or just want to drop us a note saying hello, please feel free to send us an email at hello@videotranslator.ai.\n","permalink":"https://videotranslator.ai/news/tutorial-how-to-transcribe-a-video/","tags":["English"],"title":"Visual Guides: How To Transcribe a Video"},{"categories":["Translation","Internationalization Industry","Localization Industry"],"contents":"Why do we prefer to use professionals, especially in a business environment? Professionals execute the same tasks regularly, hence they know the in\u0026rsquo;s and the out\u0026rsquo;s of a problem and can solve it better, in a short amount of time and most often with improved costs. Knowledge, practice and experience is valued in all professions. The translation industry is not different and experienced translation professionals are most often preferred.\nUsing professional translation services should be your preferred default, especially when the content is aimed at business customers.\nMoreover, if you need certified translation for legal documents for example, marketing or technical translation for business or the translated version of documents that require high level of accuracy.\nWhy Businesses Require Professional Translations In our global world, with virtual infinite options of development, most companies no matter how small are considering expanding their operations abroad or going global. In such a context appears the necessity of surpassing language barriers and translate the necessary content and documents to reach that goal. And, of course, communicating efficiently with foreign audiences.\nThe first step is to make a company marketable on the foreign market, as basis for the primary goal of reaching as many new clients as possible. It is well known that clients in general prefer to consume information and content in their own language, thus the need of localization of content. To ensure a company reaches the desired success abroad, it needs to have its content translated in accordance with the local culture and profit on the chance to promote its products and services there.\nMost businesses do not have inhouse talents and capabilities to execute the translations at a highly professional level, so they outsource this task or partner with a supplier that can solve it.\nDepending on the complexity of the business, operations expansion might involve a professional translator, a team of professional translators or a specialised translation services agency. Comparing the advantages and disadvantages of language translator versus using a specialised agency will indicate the best option upon the case.\nEven if nowadays we have tools to translate automatically the content needed, they are not able to replace a translation professional and it’s not exactly an option.\nWhy? The explanation is simple: they fail with semantic words, concepts, writing styles and mix up the meaning of the context. Automatic translation tools make often some hilarious translation errors; a business that respects itself and its image will not need such failures. For international businesses relaying on automate translation may be an expensive adventure.\nSo, using just an automatic translation is not a reliable option, not for technical, marketing or otherwise sophisticated material. Unless the respective business is ready to assume the consequences of seeing their efforts damaged by such a detail. Translation errors jeopardise intellectual property and the image of the company.\nRemember the translated copy makes or breaks the success of a company on an over sea market and impacts heavily its operations. It has direct impact on the reputation, company’s projected image across borders and brand awareness.\n    A World Of Languages    Advantages and Benefits of Translation Services for Business It results that professional translation services offer a number of benefits that cannot be neglected. You can review them below. For common small to medium translation projects, a professional translator:\n Delivers a polished and accurate copy of the original document Translates the documents correctly, efficiently, consistently and in due time. Based on their experience and qualifications, professional translators detain also target industry expertise (for example medical translation) and are able to adapt style, terminology and context. Uses professional translation tools to generate high quality translated copy Based on their translation expertise will deliver a localised copy that takes into consideration the cultural influences, inspires confidence and ensures success. Saves time and money for the client company as the quality of his/her work is high and free of errors and needs no further corrections or adjustments Will choose to translate just in the areas they have expertise in, for highly specialised areas like legal, engineering or medical. Is up to date with technological trends and modifications in cultural context and language conventions. Adheres to a strict code of ethics and handles your documents with the highest level of confidentiality and impartiality.  In the case of large and complex translation projects that involve multiple languages, multiple sites/applications, partnering with a reputed translation agency is the best solution. Because for a specialised professional translation services agency, this is their core business and what they do best. Apart of the above-mentioned benefits the translation agency will also:\n Offer access to a pool of trained and tested translators, available for an extended selection of languages, ready to start the translation work in the shortest delay. Have certified translators for the required industry and accreditation. Have in place processes to check on the quality and accuracy of the translation Spear the company that needs translation the effort of interviewing individual translators, testing them or checking their references. Have wide experience and manage complex translation projects with ease, like multiple sites and applications that a company owns, and execute them in a shorter amount of time. Act like a bridge for the client-company in relation with the target culture by making the translated content culturally and regionally appropriate, while assessing cultural differences. For example, Latin American Spanish is slightly different from European Spanish. Act like a supplementary marketing tool, as the translation agency’s experience with similar businesses help target the intended market and infuses the client’s brand with confidence. Marketing and translation combined, often lead to increased sales in the target market. Free time for the client, who will have more time at its disposal to concentrate on its core business once the translation job is outsourced to a professional translation partner.      A Translation: From One Language To Another    Professional translation services provided by a reputed translation agency are a strong strategic tool to smoothly communicate with various audiences.\nIf you were wondering about advantages and disadvantages of translation in business, well there is no doubt, translation has positive impact on business expansion, reaching higher levels of turnover and profit.\nA research made by Common Sense Advisory called \u0026ldquo;Translation at Fortune 500 Companies\u0026rdquo; emphasised that translation correlates with superior business performance. Businesses which used translation to communicate with their partners were 2.67 times more likely to obtain higher revenues. The ones that translated content to comply with local legal requirements were 1.86 times more prone to experience revenue boost and 1.33 times more likely to see improved profits.\nObviously, businesses that aim for expansion and profit growth will always look for the best professionals they can get. And professionals in translation have to answer these exigencies and be up to the required standards.\nHow Do You Qualify as Translation Professional? A professional translator has the below skills:\n  Writing skills: A translator needs to have excellent writing skills, to correctly translate the content from the primary language into content in the target language. The translator must be able to adapt their writing to different styles, such as technical, marketing, casual, formal etc. To develop a great writing ability, the translator likely has strong formal education, polished with practise and experience.\n  Advanced language skills and knowledge: It goes without saying that advanced language knowledge is needed for both the source and for the target language. Native or near-native language skills are a requirement, otherwise there is a risk of missing subtle nuances and generating errors in translation.\n  Organised and detail oriented: Some other skills are necessary to qualify as a professional in translations. Attention to detail, dedication to follow methodical processes to ensure accuracy, tenacity to find the best wording version, to name just a few, are important skills.\n  Robust translation methodology and proofreading processes: Translation is quite a complex mental process, so a clear methodology should be in place in order to avoid shortcomings. To ensure high accurate translation, a professional translator should have processes in place for, (a) specific verification, (b) editing, (c) proofreading and (d) reviewing procedures.\n  Extensive experience: As in any other industry, experience has its own role and there is no substitute. Translation skills and quality will improve over time along with gaining more and more experience.\n  These are just the main skills that someone needs to succeed in the translation world and deliver high quality translations. Hence, some other competencies are needed like cultural knowledge related to both languages included in the translation process, customer service abilities, specialised knowledge in the industries for which the translations are performed. Also, having translation certifications impacts heavily on the status of professional in this area.\nConclusion There are clear differences between a professional translator and a layman translator, and a able to speak a foreign language and it’s crucial for obtaining high quality results in translation. Translation professionals have the know-how, skills and expertise to go beyond linguistic proficiency and ensure top quality for their translation work.\nPlease connect with us on LinkedIn, YouTube or Facebook for any comments, questions, or just to keep up to date with the work we do!\nWe are very grateful for your support!\nShould you have any questions, or just want to drop us a note saying hello, please feel free to send us an email at hello@videotranslator.ai.\n","permalink":"https://videotranslator.ai/news/what-are-the-benefits-of-using-professional-translators/","tags":["English"],"title":"What are the benefits of using Professional Translators?"},{"categories":["Video Translator","Transcription","Translation","Transliteration"],"contents":"Welcome to the Video Translator. We are a Sydney based, media focused technology platform provider, looking to make the world a more accessible place. Our primary value proposition is a translation platform, with a focus on video translation.\nVideo Translator\u0026rsquo;s translation platform (\u0026ldquo;the application\u0026rdquo;) is an Internet-enabled SaaS (Software as a Service) platform which assists content creators (\u0026ldquo;the client\u0026rdquo;) to engage with stakeholders (\u0026ldquo;the audience\u0026rdquo;) from different linguistic backgrounds. The application is used to convert hypermedia content from one language to another, using an Artificial Intelligence (AI) assisted process.\nUse Cases   Who: The application is aimed at content creation and marketing teams, specifically those looking to reach an audience that thinks, communicates and consumes content in multiple languages.\n  What: The application allows the creation, transcription, translation and publication of different types of hypermedia, including audio, image, video, and text based, into multiple languages, at scale.\n  Where: The application is designed to be accessed over an Internet browser, with limited mobile support.\n  When: The application is designed to be used within an ongoing content creation/marketing process, on a volume basis. This is reflected in the pricing model structure, (a) monthly per language infrastructure cost, and (b) volume weighted content cost.\n  How: The application is designed to break down the content translation process into a step wise work flow, with the ability to use scoped AI\u0026rsquo;s through the process.\n  Conclusion Please connect with us on LinkedIn, YouTube or Facebook for any comments, questions, or just to keep up to date with the work we do!\nWe are very grateful for your support!\nShould you have any questions, or just want to drop us a note saying hello, please feel free to send us an email at hello@videotranslator.ai.\n","permalink":"https://videotranslator.ai/news/welcome-to-video-translator/","tags":["English"],"title":"Welcome to Video Translator"},{"categories":["Retail","Enterprise","Welcome","Visual Guides"],"contents":"The below describes how to sign-up to the Video Translator application. Following sign-up, how to login to the platform is also covered.\nSteps To sign-up for the application, please follow the below steps:\n  Please direct your browser to videotranslator.ai, and then click on the Sign Up button.\n  Please input your email address, and select languages. Your primary language is assumed to be English, and you will be able to select an additional 2 languages (additional languages are available within the application). Please contact us for alternative primary languages.\n    Sign-Up: Select English, German and Spanish      Please enter your credit card details, and sign up. Please note card shown below is a sample credit card. On signing up, you will receive an email to enroll into the application.\n    Sign-Up: Add Credit Card      Verify your email address, add your preferred name and password, and log in to the application. Please note, the image below is from the User Acceptance Testing (UAT) application, in Production the application will simply say Video Translator.\n    Sign-Up: Enroll with Name and Password      On a successful enroll, you will be logged into the application, and you should see your account, with some default items as per below.\n    Sign-Up: Auto-Login after Enroll      Congratulations, you are now ready to translate your content!\n  Conclusion Please connect with us on LinkedIn, YouTube or Facebook for any comments, questions, or just to keep up to date with the work we do!\nWe are very grateful for your support!\nShould you have any questions, or just want to drop us a note saying hello, please feel free to send us an email at hello@videotranslator.ai.\n","permalink":"https://videotranslator.ai/news/tutorial-how-to-sign-up/","tags":["English"],"title":"Visual Guides: How To Sign-Up"},{"categories":null,"contents":"","permalink":"https://videotranslator.ai/free-trial/","tags":null,"title":"AI Transcription and Translation"},{"categories":null,"contents":" SECTION 1 - PERSONAL INFORMATION WE COLLECT When you visit the Site, we automatically collect certain information about your device, including information about your web browser, IP address, time zone, and some of the cookies that are installed on your device. Additionally, as you browse the Site, we collect information about the individual web pages or products that you view, what websites or search terms referred you to the Site, and information about how you interact with the Site. We refer to this automatically-collected information as “Device Information.”\nWe collect Device Information using the following technologies:\n(1) “Cookies” are data files that are placed on your device or computer and often include an anonymous unique identifier. For more information about cookies, and how to disable cookies, visit http://www.allaboutcookies.org. (2) “Log files” track actions occurring on the Site, and collect data including your IP address, browser type, Internet service provider, referring/exit pages, and date/time stamps. (3) “Web beacons,” “tags,” and “pixels” are electronic files used to record information about how you browse the Site.  Additionally when you make a purchase or attempt to make a purchase through the Site, we collect certain information from you, including your name, billing address, shipping address, payment information (including credit card numbers), email address, and phone number. We refer to this information as “Order Information.”\nWhen we talk about “Personal Information” in this Privacy Policy, we are talking both about Device Information and Order Information.\nSECTION 2 - HOW DO WE USE YOUR PERSONAL INFORMATION? We use the Order Information that we collect generally to fulfill any orders placed through the Site (including processing your payment information, arranging for shipping, and providing you with invoices and/or order confirmations). Additionally, we use this Order Information to: Communicate with you; Screen our orders for potential risk or fraud; and When in line with the preferences you have shared with us, provide you with information or advertising relating to our products or services. We use the Device Information that we collect to help us screen for potential risk and fraud (in particular, your IP address), and more generally to improve and optimize our Site (for example, by generating analytics about how our customers browse and interact with the Site, and to assess the success of our marketing and advertising campaigns).\nSECTION 3 - SHARING YOUR PERSONAL INFORMATION We share your Personal Information with third parties to help us use your Personal Information, as described above. For example, we use Shopify to power our online store\u0026ndash;you can read more about how Shopify uses your Personal Information here: https://www.shopify.com/legal/privacy. We also use Google Analytics to help us understand how our customers use the Site\u0026ndash;you can read more about how Google uses your Personal Information here: https://www.google.com/intl/en/policies/privacy/. You can also opt-out of Google Analytics here: https://tools.google.com/dlpage/gaoptout.\nFinally, we may also share your Personal Information to comply with applicable laws and regulations, to respond to a subpoena, search warrant or other lawful request for information we receive, or to otherwise protect our rights.\nSECTION 4 - BEHAVIOURAL ADVERTISING As described above, we use your Personal Information to provide you with targeted advertisements or marketing communications we believe may be of interest to you. For more information about how targeted advertising works, you can visit the Network Advertising Initiative’s (“NAI”) educational page at http://www.networkadvertising.org/understanding-online-advertising/how-does-it-work.\nYou can opt out of targeted advertising by:\n(1) FACEBOOK: https://www.facebook.com/settings/?tab=ads (2) GOOGLE: https://www.google.com/settings/ads/anonymous (3) BING: https://advertise.bingads.microsoft.com/en-us/resources/policies/personalized-ads  Additionally, you can opt out of some of these services by visiting the Digital Advertising Alliance’s opt-out portal at: http://optout.aboutads.info/.\nSECTION 5 - DO NOT TRACK Please note that we do not alter our Site’s data collection and use practices when we see a Do Not Track signal from your browser.\nSECTION 6 - YOUR RIGHTS If you are a European resident, you have the right to access personal information we hold about you and to ask that your personal information be corrected, updated, or deleted. If you would like to exercise this right, please contact us through the contact information below.\nAdditionally, if you are a European resident we note that we are processing your information in order to fulfill contracts we might have with you (for example if you make an order through the Site), or otherwise to pursue our legitimate business interests listed above. Additionally, please note that your information will be transferred outside of Europe, including to Canada and the United States.\nSECTION 7 - DATA RETENTION When you place an order through the Site, we will maintain your Order Information for our records unless and until you ask us to delete this information.\nSECTION 8 - CHANGES We may update this privacy policy from time to time in order to reflect, for example, changes to our practices or for other operational, legal or regulatory reasons.\nSECTION 9 - CONTACT US For more information about our Privacy Policy, if you have questions, or if you would like to make a complaint, please contact us by e-mail or by mail using the details provided.\nE: hello@videotranslator.ai A: Suite 4, 71 Balfour Street, Chippendale 2008, Australia  ","permalink":"https://videotranslator.ai/privacy-policy/","tags":null,"title":"Privacy Policy"},{"categories":null,"contents":"OVERVIEW These terms and conditions govern your use of the website and services enabled on that website (together referred to as the Video Translator Platform, the Platform) made available by QBL Media Pty Ltd.\nThe Platform is provided by QBL Media Pty Ltd (ABN: 73 602 663 141) (QBL, QBLM, Video Translator, we, us and our) to users (you and your and the Client).\nThe Platform is a managed software service hosted in a ‘cloud-style’ online environment. The Platform functions to receive certain digital video data files (“Client Video” or “CV”) from you (in response to prompts from the Platform) and then performs certain calculations and deploys third party artificial intelligence (AI) and machine learning (ML) services in order to create a Translated Client Video (“TCV”) which, as the name suggests, is a version of the Client Video in which the spoken words have been translated into a different language (as chosen by you, the Client).\nVideo Translator’s processing of the Client Video involves the use of third party AI and ML services (Third Party Tools) in addition to, potentially, human authored language translation services.\nThese terms and conditions govern use of the Platform and the Services by you, the Client. You agree to comply with these Terms and any supplemental terms which may be applicable.\nBY ACCESSING, USING OR UPLOADING OR DOWNLOADING ANY INFORMATION OR MATERIALS (INCLUDING A CV OR A TCV) TO OR FROM THE PLATFORM, OR BY INDICATING YOUR ASSENT TO THESE TERMS BY CREATING AN ACCOUNT, CLICKING “SIGN UP” OR ANY SIMILAR MECHANISM, YOU ARE AGREEING TO THE THESE TERMS.\nIF YOU DO NOT AGREE TO THESE TERMS, DO NOT ACCESS OR USE THE PLATFORM.\n SECTION 1: DEFINITIONS 1.1 Set out in the table below are certain terms used in this Agreement and the meaning of that term:\n        Agreement These terms and conditions, in addition to the Order Form where you specified the Services you require and we quoted the Fees, and any other details which are linked to your transaction, including our Pricing page.   Business Day Monday to Friday in a given week, excluding a day which is a gazetted public holiday in the jurisdiction at which:  (a) (for service of notice) the address of the recipient party is located;  (b) or (for performance of some action) the person is located who is to perform the action.   Business Hours 8am to 6pm Australian Eastern Standard Time (AEST).   Client Trademark A trademark owned by the Client, whether registered or not.   Client Video (CV) Video in digital file format which is owned or controlled by Client and transmitted by Client to the Platform and received by Video Translator into the Platform.   Confidential Information All or any information concerning the business or affairs of a party, whether or not recorded in a material form, which is marked as being confidential or which, from its content or format, ought to reasonably be treated as being confidential and is not generally made available to the public.   Data Centre The data centre(s) operated by a third party at which the virtual servers, on which the Platform and Third Party Tools are hosted, are located. Note that these Services are made available “in the cloud”.   Fees The fees payable by the Client to Video Translator specified in our pricing page and quoted to you in your Order Form.   Insolvency Event (a) if the Client is located in Australia, being in liquidation or provisional liquidation or under administration, having a controller (as defined in the Corporations Act) or analogous person appointed to it or any of its property, being taken under section 459F(1) of the Corporations Act to have failed to comply with a statutory demand, being unable to pay its debts or otherwise insolvent, dying, ceasing to be of full legal capacity or otherwise becoming incapable of managing its own affairs for any reason, taking any step that could result in the person becoming an insolvent under administration (as defined in section 9 of the Corporations Act), entering into a compromise or arrangement with, or assignment for the benefit of, any of its members or creditors, or any analogous event; and  (b)\tif the Client is located outside Australia – any act analogous to the acts or circumstances described in paragraph (a).   Intellectual Property Rights Any and all intellectual and industrial property rights throughout the world and includes, without limitation all rights in copyright (including future copyright and rights in the nature of or analogous to copyright), inventions (including patents), trademarks, and know-how, irrespective of whether such rights are registered or capable of registration.   Order Form The document which describes the language translation attributes desired by Client (including the quantified usage of the various features and functionality of the Services and the Platform) and the pricing structure and the final price for that deployment of the Services with respect to the Client Video.   Personal Information Has the meaning given to it in the Privacy Act 1988 (Cth)   Personnel In the case of the Client: Any officers, employees or contractors of the Client.  In the case of Video Translator: Any officers, employees or contractors of Video Translator.   Platform The software platform through which Video Translator receives and analyses Client Video (using proprietary data science and, algorithms and potentially, human review), applies third party AI and machine learning services (Third Party Tools) to Client Video and then provides outputs which are Translated Client Video back to the Client (but not necessarily in that order).   Policies Policies, including procedures and other protocols relating to the use of the Platform and other aspects of Video Translator’s operations.   Video Translator Data Data derived by Video Translator from Client Video during operation and usage of all aspects of the Platform and provision of the Services. Video Translator Data does not include Client Video or Translated Client Video.   Service Documentation Technical documentation describing the Platform and providing instructions for use.   Services Operating Video Translator’s Platform which includes receiving and analysing a Client Video (using proprietary data science and algorithms), applying Third Party Tools to the Client Video, applying human review and editing to the Client Video and then providing a final output to the Client which is a Translated Client Video.   Support Services Services performed by Video Translator in relation to the customisation, if any, installation and support of the Platform.  Includes advice to Client about setup and bugs detection.   Tax Any tax, including consumption tax and withholding tax unless otherwise specified, but excluding a tax on income.   Term The term of this Agreement which commences when Client accepts these terms and continues until determined in accordance with clause 15.   Third Party Tools Video Translator’s business service tools (typically a software service) provided by a third party to Video Translator as a service and which performs language translation services using AI and/or machine learning techniques to the Client Video via an online service which is operated by a third party after which the result is transmitted back to Video Translator for further processing which could include human review and clean up of the result. Third Party Tools are: (a) Microsoft Cognitive Services, and (b) Google Cloud AI and ML Services   Transaction Fee A merchant or like fee charged by an intermediary to process a credit card or electronic payment.   Translated Client Video (TCV) Video Translator’s Platform applies third party AI and machine learning services to Client Video by performing the Services which may additionally include human review and editing.  The final output of the Services is a Translated Client Video.   User The Personnel of the Client and related parties of the Client who are authorised by the Client to use the Platform and for whom the Client has supplied user identifications and passwords.     SECTION 2: SCOPE AND OPERATION OF THE PLATFORM 2.1 This Agreement governs the commercial arrangement between Video Translator and the Client under which:\n Client has the right, through the Users, to access the Platform and utilise the features and functionality of the Platform; Client grants to Video Translator permission to receive Client Video from Client and to provide the Client Video to third parties strictly for the limited purpose of applying Third Party Tools; and Video Translator, with consent of Client, operates and enables the Platform in order to provide the Services including a Translated Client Video to the Client.  2.2 The Client warrants that it enters into this Agreement having had the opportunity to evaluate and satisfy itself about the features and functionality of the Platform and the Service and the terms in this Agreement on which Video Translator makes those available to the Client.\n2.3 Video Translator may, at its discretion, upgrade, amend, add, remove, redesign, improve or otherwise alter the features of the Platform so long as it does not materially and adversely reduce the core functionality of the Platform or otherwise interfere with use of the Platform as contemplated by this Agreement.\n2.4 Video Translator will during the Term provide a Translated Client Video to Client within a reasonable time after a Client video is uploaded to the Platform (provided that User’s account is sufficiently in credit). The TCV will be made available on the Platform for download transmission from Video Translator’s platform by the Client. Video Translator will retain a secure backup copy of the TCV while Client’s account is active however backup copies will be deleted within 30 days after closing of Client’s account. A Client may request a longer period of backup storage if required and Video Translator will consider all reasonable requests.\n SECTION 3: PLATFORM AVAILABILITY AND SECURITY 3.1 The Platform is hosted on virtual servers located at and managed through the Data Centre. The availability of the Platform (including business continuity and data recovery measures) is under the control of the Data Centre.\n3.2 From time to time Video Translator will conduct preventative and remedial maintenance on the Platform and in respect of the infrastructure it deploys in the provision of the Platform (Scheduled Maintenance).\n3.3 Video Translator will endeavour to carry out all Scheduled Maintenance outside usual Business Hours and to give reasonable notice of any planned downtime for the Platform. In the event of an emergency, Video Translator may carry out maintenance during usual Business Hours and without first notifying the Client.\n3.4 Subject to Video Translator’s obligations under this Agreement in respect of Privacy Obligations and confidentiality and compliance with other relevant laws, Video Translator reserves the right to monitor the operation of the Platform and the flow of Client Video to the Platform in order to enable Video Translator to perform its obligations and exercise its rights under this Agreement.\n3.5 The Client acknowledges and accepts that, notwithstanding any business continuity and disaster recovery policy of the Data Centre:\n a Client Video may be lost and not capable of being recovered; if Video Translator’s access to Third Party Tools is reduced or interrupted then Video Translator’s ability to perform the Services and provide Translated Client Video may be interrupted; the Client must ensure that it has taken all appropriate measures to implement a duplicate or a back-up copy of any Client Video (including requiring Users to do so) which is independent of the Client Video supplied to Video Translator;   SECTION 4: INTELLECTUAL PROPERTY RIGHTS 4.1 The Intellectual Property Rights subsisting in the Client Video and any other documentation, information or materials that are supplied to Video Translator by Client during Term of this Agreement remain the exclusive property of Client or its third-party licensors, subject to the rights (if any) expressly granted to Video Translator under this Agreement.\n4.2 Client grants to Video Translator a non-exclusive, royalty-free, worldwide, irrevocable license to use Client Video during the Term in order to provide the Services and create the TCV and create Video Translator Data. Video Translator will not use or retain any Client Video other than for the purpose of providing the Services and creating the TCV and creating Video Translator Data.\n4.3 Client grants to Video Translator a non-exclusive, royalty-free, worldwide perpetual licence to display the Client Trademark on, and in association with Video Translator\u0026rsquo;s promotional materials (including the Video Translator website). Use of the Client Trademark is strictly limited in its prominence and location so as to convey only that Client is, or has been a user of the Platform and shall comply with branding guidelines or other reasonable instructions advised by the Client.\n4.4 Client assigns absolutely to Video Translator, from the date of its creation, all of the Intellectual Property Rights subsisting in any inventions which may be conceived or implemented arising from suggestions, enhancements, improvements, customisation requests, recommendations or other feedback provided by the Client to Video Translator with regard to the Service, the Platform or the Translated Client Video.\n4.5 The Intellectual Property Rights subsisting in the Platform, (including the user interface and the software comprising the Platform), the Video Translator Data (derived in part from use of the Platform with the Client Video and from performing the Services), and any other documentation, information or materials that are supplied by Video Translator to the Client, (but excluding the TCV) remain the exclusive property of Video Translator or its third party licensors.\n4.6 To the extent that Video Translator owns or controls the copyright subsisting in a TCV, Video Translator assigns to Client all copyright subsisting in the TCV including the right to use copy, distribute and exploit the Translated Client Video with effect from the date on which the Translated Client Video is transmitted to Client.\n SECTION 5: SUPPORT SERVICES 5.1 During the Term Video Translator will provide Support Services to the Client in accordance with timetable and other resource commitments described in Schedule A.\n5.2 Video Translator may, at its discretion, agree to provide other services to the Client at its request. Other services may be conditional upon the payment of additional fees by the Client to Video Translator and in that event Video Translator and Client record the agreed payment and a description of the other services in advance and Video Translator will invoice the Client for the other services separately.\n SECTION 6: FEES 6.1 In return for access to the Platform and receipt of the Services under the terms of this agreement, Client shall pay the Fees to Video Translator.\n6.2 Fees are calculated in accordance with our pricing structure. Video Translator reserves the right to change our pricing structure at any time during the Term for any reason, subject to reasonable notice to Client. Notwithstanding the foregoing, the Fees payable in respect of any specific Services for a specific CV will always be quoted to Client in advance of performing the Services and Client is able to accept or decline that quotation.\n6.3 All Fees and charges payable to Video Translator are non-cancellable and non-refundable, subject to Client’s rights under any non-excludable terms. 6.4 If the Client elects to make payment to Video Translator using a method that results in Video Translator having to pay a Transaction Fee, the Client will pay the Transaction Fee to Video Translator at the same time as it makes payment of the invoice in respect of which the Transaction Fee is charged.\n6.5 Payment processing services for the Services are provided to Video Translator by Stripe and are subject to Stripe’s own Terms of Service and Security Policies and Procedures, (collectively, the Stripe Services Agreement). The Client must read the Stripe Terms because those terms will be binding on the Client if they accept these Terms and Conditions. By agreeing to these Terms and Conditions or continuing to use the Services you (the Client) agree to be bound by the Stripe Terms, as the same may be modified by Stripe from time to time. As a condition of Video Translator enabling payment processing services through Stripe, Client agrees to provide Video Translator accurate and complete information about Client and Client’s business (if applicable), and Client authorises Video Translator to share it and transaction information related to Client’s use of the payment processing services provided by Stripe.\n SECTION 7: CLIENT ACKNOWLEDGEMENT - ASSUMPTIONS AND USE OF TCV 7.1 The Client acknowledges and agrees that:\n the Platform has been configured and will process a Client Video in reliance upon certain industry conventions and assumptions which will inevitably affect the quality and accuracy and reliability of the resulting TCV which is generated by the Platform; the accuracy, reliability and quality of the Client Video will inevitably affect the accuracy, reliability and quality of the resulting TCV which is generated by the Services; Client is solely and exclusively responsible and will check and validate the accuracy, reliability and quality of Client Video which is input to the Platform; the Platform is an automated assistive tool and is not intended to replace human judgement therefore, prior to relying on the TCV for any purpose (including without limitation any purpose which could lead to death, personal injury, or severe physical, environmental or financial damage), Client is solely and exclusively responsible and must check and validate those outputs including the contents of any TCV prior to use or publication. This is very important because the quality of the TCV is affected by the complexity of the underlying content contained in the CV. If the underlying content in your CV is complex, then the Third Party Tools may struggle to provide a good outcome in the TCV; and The use of, and reliance upon a TCV is entirely at the discretion and risk of the Client.   SECTION 8: Video Translator OBLIGATIONS 8.1 Video Translator must\n comply with the requirements of the Privacy Laws, relevant data security standards and Video Translator’s security and data integrity policies; notify the Client immediately if Video Translator becomes aware or suspects there has been: 1. a material breach of its data security measures; or 1. unauthorised disclosure or use of personal information (including any suspected or actual unauthorised access to Client Video via cyber-attack or otherwise).   SECTION 9: CLIENT OBLIGATIONS 9.1 If the consent of a third party is required in order for any Client Video to be processed in the Platform or in connection with the Services then Client is solely and exclusively responsible to obtain that consent from the third party.\n9.2 The Client is primarily responsible for responding to a claim or query from a customer of Client (or any third party, including a regulatory authority) with respect to the specific content, quality, meaning or message of a TCV and Client accepts that Video Translator will refer any such claim or query to Client.\n9.3 Unless otherwise permitted by law, the Client must not:\n resell, reframe, distribute or on-sell the Platform; include the Platform in any service bureau or outsourcing or managed service offering; transfer, sub-license or assign its rights under this Agreement to any third party unless Video Translator gives its prior written consent (not to be unreasonably withheld); modify or adapt or create derivative works of the functionality of the Platform; reverse engineer, decompile, decrypt, disassemble or otherwise attempt to derive the source code for the Platform; build a competitive service; or copy any features, functions or graphics of the Platform.  9.4 The Client must not assign or novate this Agreement without the prior written consent of Video Translator, such consent not to be unreasonably withheld.\n9.5 The Client must use reasonable endeavours to comply with Policies as notified in writing to the Client by Video Translator, and promptly advise Video Translator in writing where it is not able or willing to comply with those Policies.\n9.6 The Client acknowledges and agrees that it is responsible for the following:\n Nominating which Users will be as authorised on behalf of Client to submit Client Video to be processed by the Platform and to receive the TCV; Using reasonable efforts to resolve technical issues to enable the Client Video to be accessible to the Platform; revoking or adjusting the access of any Users; how and where a TCV is used, published or distributed, if at all; deciding whether to share a TCV with any third party; and providing adequate security for the computer network and Client’s account login details in conjunction with which the Platform is used; and checking and reviewing the TCV in accordance with clause 7.  9.7 Client acknowledges that Video Translator cannot provide the Services unless Video Translator and Third Party Tools are given access to a Client Video and Client Video is in a form which is technically compatible with the Platform and the Third Party tools. It is Clients responsibility to obtain any necessary permissions from third parties to enable Video Translator and the Third Party Tools to access the Client Video.\n9.8 Client must not:\n use the Platform in any manner that could disable, overburden, damage, or impair the Platform or interfere with any other user’s use of the Platform; use any robot, spider or other automatic device, process or means to access the Platform for any purpose, including monitoring or copying any of the material on the Platform; use any manual process to monitor or copy any of the material on the Platform or for any other unauthorised purpose without Video Translator’s prior written consent; use any device, software or routine that interferes with the proper working of the Platform; introduce any viruses, trojan horses, worms, logic bombs or other material which is malicious or technologically harmful; attempt to gain unauthorised access to, interfere with, damage or disrupt any parts of the Platform or any server, computer or database connected to the Platform, including the Third Party Tools; attack the Platform via a denial-of-service attack or a distributed denial-of-service attack; or otherwise attempt to interfere with the proper working of the Platform.  9.9 Video Translator may report any of the activities above to the relevant law enforcement authorities and reserves the right to cooperate with those authorities by disclosing Clients identity to them.\n SECTION 10: CONFIDENTIALITY 10.1 Each party must treat, and ensure that its Personnel treat, as confidential, the Confidential Information of the other party.\n10.2 The party who receives (the recipient) Confidential Information from the other party (discloser) must not without the prior written consent of the other party:\n use it except in performing its obligations under this Agreement or as otherwise specified in this Agreement; or disclose it to any person except those of its Personnel and then only to those Personnel who need to know the same and who agree to be bound by these obligations of confidentiality.  10.3 The exceptions are where:\n disclosure is required by law; Confidential Information is in the public domain through no fault or action of the recipient or its Personnel; Confidential Information was received by the recipient on a non-confidential basis from a third party who is entitled to disclose it; or The same or similar information was independently developed by recipient without reference to the Confidential Information of the discloser.   SECTION 11: WARRANTIES BY CLIENT 11.1 Client warrants that:\n It has the authority to enter into and perform its obligations under this Agreement, it has the ability to perform its obligations under this Agreement, and that this Agreement has been duly executed and is a legal, valid and binding Agreement enforceable against it. It is responsible for complying with all applicable laws (including, without limitation, privacy laws) affecting the Personal Information or other content which it may provide to Video Translator and will also comply with, and consent to our Privacy Policy. In particular, Client must ensure that it has all relevant licences and consents from people or entities who are depicted, or whose intellectual property is depicted or represented in the Client Video. Client owns the Client Video and applicable intellectual property rights in the Client Video or otherwise has the right to grant Video Translator access to the Client Video for the purpose of providing the Services which includes making a derivative work based upon the Client Video.   SECTION 12: WARRANTIES BY Video Translator 12.1 Video Translator warrants that:\n it has the authority to enter into and perform its obligations under this Agreement and that this Agreement has been duly executed and is a legal, valid and binding Agreement enforceable against it. except with respect to Third Party Tools (which are excluded from this warranty), Video Translator will not share or divulge Client Video, or Translated Client Video with any third party without prior written consent of Client.  12.2 Video Translator does not warrant that a TCV will be suitable to qualify for approval from any third party (including, without limitation, any government or industry regulator or academic or other institution) or will be sufficiently accurate and comprehensive to implement any plan or commercial undertaking. This is very important because the quality of the TCV is affected by the complexity of the underlying content contained in the CV. If the underlying content in your CV is complex, then the Third Party Tools may struggle to provide a good outcome in the TCV. The use of, and reliance upon a TCV is entirely at the discretion and risk of the Client.\n SECTION 13: INDEMNITY BY CLIENT 13.1 Client agrees to indemnify, defend and hold harmless Video Translator and its officers, directors, employees, agents, licensors and suppliers from and against all losses, expenses, damages and costs, including reasonable solicitor’s fees, resulting from:\n violation of this Agreement or a warranty given by Client or any activity conducted on Client’s Account by Client or by a User accessing the Platform using Client’s Account; a claim made against Video Translator by a third party (including, without imitation a customer of Client or an operator of Third Party Tools) alleging that Video Translator\u0026rsquo;s access to Client Video is not authorised; a claim made against Video Translator arising from Client’s failure to comply with relevant and applicable legislation (including applicable data protection laws) when Client uses the Platform and the Services and the TCV; a claim made against Video Translator by a third party (including, without imitation a customer of Client or an operator of Third Party Tools) alleging that a TCV contains incorrect, false or misleading information or is malicious, defamatory or offensive in its content.   SECTION 14: LIMITATION OF LIABILITY 14.1 Terms, conditions, warranties and guarantees implied by law, which cannot be excluded, restricted or modified apply to this Agreement to the extent required by that law.\n14.2 Except for liability in relation to any non-excludable Term, the Platform, the Services and the TCV are provided on an “as is” basis, and without any warranty or condition, express or implied, including any implied warranties of title, merchantability, fitness for a particular purpose and non-infringement of third party Intellectual Property Rights to the extent allowed by law.\n14.3 To the extent permitted by law, Video Translator’s sole liability for breach of contract, breach of statutory duty, negligence or other tort is limited, at its option, to:\n the supplying of the Services again; or the payment of the cost of having the Services supplied again.  14.4 The Client does not rely on any representation, warranty or other provision made by Video Translator or on its behalf which is not expressly stated in these terms.\n14.5 Video Translator is not liable for loss or corruption of a Client Video, loss of revenue, loss of goodwill loss of anticipated sales, loss of savings, loss of business opportunity, interruption to business, or wasted management/administrative time. This exclusion of liability includes loss or damage Client might suffer as a result of failure of performance, error, omission, interruption, deletion, defect, failure to correct defects, delay in operation or transmission, computer virus or other harmful component, loss of data, communication line failure, unlawful third-party conduct, or theft, destruction, alteration or unauthorised access to records.\n14.6 Video Translator is not liable for any loss or claim incurred by or against Client or any third party arising from:\n Client’s or any third party’s use of or reliance upon a TCV; and Client’s use of any third party embedded content or plugins that are not hosted on the Platform.   SECTION 15: TERM AND RENEWAL 15.1 The Term of the Agreement continues indefinitely on a month to month rolling basis unless validly terminated in accordance with this Agreement. Client may suspend their access to the Services in whole or in during the Term and, although that suspension may suspend charges incurred on Client’s account, all of these terms remain in effect. If Client wishes to terminate this Agreement they will notify Video Translator in writing with 30 days notice.\n15.2 Video Translator does not provide a refund if Client decides to stop using the Services prior to the expiration date of the current monthly billing cycle or does not terminate in accordance with the requirements of this clause 15.\n SECTION 16: SUSPENSION FOR PROHIBITED ACTS 16.1 Video Translator may reject a Client Video or suspend Client’s or any User’s access to the Platform without notice if Client’s use of the Platform:\n violates applicable local, state, federal, or foreign laws or regulations or the terms of this Agreement; or is being subjected to denial of service attacks or other disruptive activity; is being used to engage in denial of service attacks or other disruptive activity; is creating a security vulnerability for the Platform or others; is consuming excessive bandwidth; is causing or is likely, in the reasonable opinion of Video Translator to harm to Video Translator or others; involves the creation, promotion or processing of sexually explicit materials, violence, discrimination or vilification based on race, sex, religion, nationality, disability, sexual orientation or age, and/or any illegal or objectionable activities; or violates any intellectual property or other proprietary rights of any third party.  16.2 Video Translator will try to limit the suspension to the affected portion of the Platform and promptly resolve the issues causing the suspension of the Platform. Nothing in this clause limits Video Translator\u0026rsquo;s right to terminate for cause as described in this Agreement, if Video Translator determines that Client is acting, or has acted, in a way that has or may negatively reflect on or affect Video Translator, our prospects, or our customers.\n16.3 Video Translator may, without notice, review, edit and delete any Client Video, Translated Client Video or other user content that we determine in good faith violates these terms, however Video Translator has no duty to pre-screen, control, monitor or edit a Client Video, Translated Client Video or other user content.\n16.4 Video Translator will provide Client with notice of non-payment of any amount due. Unless the full amount has been paid, Video Translator may suspend Client’s access to the Platform and/or withhold access to a TCV. If Client’s access to the Platform is suspended for non-payment, we may charge a re-activation fee to reinstate your access to the Platform.\n SECTION 17: TERMINATION FOR CAUSE 17.1 If an Insolvency Event occurs in relation to the Client or any other event occurs which gives Video Translator reasonable grounds for doubting the credit of the Client (including, the Client’s failure to make any payment when due under this Agreement), Video Translator may by notice to the Client, at Video Translator’s option and without prejudice to any other right it may have:\n require the Client to make payment of the balance of the Fees unpaid in full before or on delivery of the Services; or suspend or terminate this Agreement or cancel any undelivered or uncompleted Services under this Agreement.  17.2 If the Client:\n fails to make any payment when due; breaches a clause of this Agreement which is not capable of remedy; breaches a clause of this Agreement which is capable of remedy and fails to remedy the breach within 14 days of the date of a notice issued by Video Translator which identifies the breach and requests remedy; or acts, or has acted, in a way that has or may negatively reflect on or affect Video Translator, our prospects, or our customers;  then Video Translator may terminate this Agreement by written notice to the Client effective immediately or from a later date specified in the notice.\n17.3 If Video Translator:\n breaches a clause of this Agreement which is not capable of remedy; or breaches a clause of this Agreement which is capable of remedy and fails to remedy the breach within 14 days of the date of a notice issued by the Client which identifies the breach and requests remedy;  the Client may terminate this Agreement by written notice to Video Translator effective immediately or from a later date specified in the notice.\n17.4 On termination of this Agreement Video Translator has no obligation to provide Services to the Client or to maintain Client’s access to the Platform.\n17.5 If this Agreement is terminated, then the Client will remain liable to pay to Video Translator and Video Translator is entitled to recover from the Client all Fees that are or were due for payment before termination and have not been paid.\n SECTION 18: FEEDBACK AND CONSULTATION 18.1 Video Translator welcomes feedback and suggestions on how the Platform and the Services and the Translated Client Video could be improved and we invite your consultation with us for that purpose. Feedback provided by Client to Video Translator shall be the Confidential Information of Video Translator.\n SECTION 19: GENERAL 19.1 In this Agreement:\n Headings are for convenience only and do not affect the interpretation of this Agreement. A reference to the singular includes the plural and references to the masculine include the feminine and vice versa. An expression importing a natural person includes any company, partnership, joint venture, association, corporation or other body corporate and any governmental agency. A reference to any statute, regulation, proclamation, ordinance or by-law includes all statutes, regulations, proclamations, ordinances or by laws amending, consolidating or replacing them, and a reference to a statute includes all regulations, proclamations, ordinances and by-laws issued under that statute. A reference to a document includes an amendment or supplement to, or replacement or novation of, that document. A reference to a party to a document includes that party’s successors and permitted assigns. All amounts payable under this Agreement are to be calculated and paid in United States dollars.  19.2 Notices under this Agreement must be in writing. A notice may be delivered to a party by hand or by email to that party at the address shown at the start of this Agreement or to an alternate email address notified to the party giving the notice. A notice given to a person in accordance with this clause is treated as having been given and received:\n if delivered to a person\u0026rsquo;s address, on the day of delivery; or if delivered by email, on the Business Day after it is despatched provided that the sender does not receive a message to the effect that the sender is out of office or that delivery has failed.  19.3 This Agreement contains all the terms and conditions agreed on by the parties. No oral agreements or representations will be valid or binding on the parties unless expressly contained in this Agreement or by a written amendment to this Agreement.\n19.4 This Agreement may only be amended by a further written agreement signed by the authorised representatives of the Client and Video Translator.\n19.5 Any failure by either party to insist upon strict performance by the other party of any provision in this Agreement will not be taken to be a waiver of any existing or future rights of that party in relation to the provision.\n19.6 If any provision of this Agreement is invalid, illegal or unenforceable, this Agreement takes effect (where possible) as if it did not include that provision.\n19.7 The provisions of clauses 4, 10, 11, 12, 13, 14 and 19 survive termination or expiry of this Agreement.\n19.8 This Agreement is not to be interpreted against the interests of a party merely because that party proposed this Agreement or some provision of it or because that party relies on a provision of this Agreement to protect itself.\n19.9 Neither party is liable for any delay or failure to perform its obligations under this agreement if the delay is due to natural disaster or other event beyond its reasonable control, including without limitation, acts of God, acts of government, floods, fires, earthquakes, civil unrest, acts of terror, or strikes or other labour problems.\n19.10 This Agreement is governed by the laws of the State of New South Wales, Australia. Each party submits to the non-exclusive jurisdiction of courts exercising jurisdiction there in connection with all matters concerning this Agreement.\n SCHEDULE A SUPPORT SERVICES are comprised of:\n Email Support requests should be addressed to hello@videotranslator.ai. Video Translator will respond to email requests promptly and in the order in which they are received however Video Translator makes no guarantee as to when a response or a fix (if required) will be provided to Client.  ","permalink":"https://videotranslator.ai/terms-of-service/","tags":null,"title":"Terms Of Service"},{"categories":null,"contents":"","permalink":"https://videotranslator.ai/thanks/","tags":null,"title":"Thank You"},{"categories":null,"contents":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```\nSearching additional fileds To search additional fields defined in front matter, you must add it in 2 places.\nEdit layouts/_default/index.JSON This exposes the values in /index.json i.e. add category ``` \u0026hellip; \u0026ldquo;contents\u0026rdquo;:{{ .Content | plainify | jsonify }} {{ if .Params.tags }}, \u0026ldquo;tags\u0026rdquo;:{{ .Params.tags | jsonify }}{{end}}, \u0026ldquo;categories\u0026rdquo; : {{ .Params.categories | jsonify }}, \u0026hellip; ```\nEdit fuse.js options to Search static/js/search.js ``` keys: [ \u0026ldquo;title\u0026rdquo;, \u0026ldquo;contents\u0026rdquo;, \u0026ldquo;tags\u0026rdquo;, \u0026ldquo;categories\u0026rdquo; ] ```\n","permalink":"https://videotranslator.ai/search/","tags":null,"title":"Search Results"}]